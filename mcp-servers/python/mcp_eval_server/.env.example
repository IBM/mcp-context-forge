# MCP Evaluation Server Environment Configuration
# Copy this file to .env and configure your settings

# OpenAI Configuration
OPENAI_API_KEY=sk-your-openai-api-key-here
# OPENAI_ORG_ID=org-your-organization-id  # Optional

# Azure OpenAI Configuration
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
# AZURE_OPENAI_KEY=your-azure-openai-key
# AZURE_OPENAI_API_VERSION=2024-02-01

# Anthropic Configuration (for future support)
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-key

# Default Judge Model Selection
DEFAULT_JUDGE_MODEL=gpt-4
# Alternative options: gpt-3.5-turbo, gpt-4-turbo, gpt-4-azure, rule-based

# Cache Configuration
MCP_EVAL_CACHE_DIR=/app/data/cache
MCP_EVAL_CACHE_TTL=3600  # Cache TTL in seconds (1 hour)
MCP_EVAL_CACHE_SIZE=1000  # Maximum cached items

# Database Configuration
MCP_EVAL_RESULTS_DB=/app/data/results/evaluation_results.db

# Logging Configuration
LOG_LEVEL=INFO
PYTHONUNBUFFERED=1

# Performance Configuration
MAX_CONCURRENT_EVALUATIONS=3
EVALUATION_TIMEOUT=300  # seconds

# Development Configuration
# DEVELOPMENT_MODE=true  # Enable for development features

# Model-specific settings
GPT4_TEMPERATURE=0.3
GPT4_MAX_TOKENS=2000
GPT35_TEMPERATURE=0.2
GPT35_MAX_TOKENS=2000

# Evaluation defaults
DEFAULT_CONSISTENCY_RUNS=3
DEFAULT_TEMPERATURE_RANGE=0.1,0.5,0.9
DEFAULT_RELEVANCE_THRESHOLD=0.7
DEFAULT_CONFIDENCE_THRESHOLD=0.8

# Security settings
RATE_LIMIT_REQUESTS=100  # per hour
RATE_LIMIT_TOKENS=50000  # per hour
