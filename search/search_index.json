{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"MCP Gateway","text":"<p>A flexible FastAPI-based gateway and router for Model Context Protocol (MCP) with support for virtual servers. It acts as a unified interface for tools, resources, prompts, virtual servers, and federated gateways \u2014 all accessible via rich multi-transport APIs and an interactive web-based Admin UI.</p>"},{"location":"#_1","title":"\ud83c\udfe0 Home","text":""},{"location":"#what-it-does","title":"What it Does","text":"<ul> <li>\ud83d\udeaa Acts as a gateway layer in front of MCP servers or APIs</li> <li>\ud83d\udd17 Connects and federates multiple MCP backends (auto-discovery, failover, merging)</li> <li>\ud83d\udd04 Adapts any REST API into an MCP-compliant tool or server</li> <li>\ud83d\udee0\ufe0f Centralizes registration and management of tools, prompts, and resources</li> <li>\ud83d\udce1 Exposes all endpoints over HTTP/JSON-RPC, WebSocket, Server-Sent Events (SSE), and stdio</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Multi-Transport Support: HTTP, WebSocket, SSE, and stdio support with auto-negotiation</li> <li>Federation &amp; Health Checks: Auto-discovery, syncing, and monitoring of peer gateways</li> <li>Admin UI: Visual management of servers, tools, prompts, and resources (HTMX + Tailwind)</li> <li>Tool Wrapping: Expose REST, CLI, or local functions as JSON-RPC tools</li> <li>Security: JWT and Basic Auth, rate limits, SSL validation</li> <li>Caching &amp; Observability: In-memory or Redis/database-backed LRU+TTL caching, structured logs</li> </ul> <pre><code>graph TD\n    subgraph UI_and_Auth\n        UI[\ud83d\udda5\ufe0f Admin UI]\n        Auth[\ud83d\udd10 Auth - JWT and Basic]\n        UI --&gt; Core\n        Auth --&gt; Core\n    end\n\n    subgraph Gateway_Core\n        Core[\ud83d\udeaa MCP Gateway Core]\n        Protocol[\ud83d\udce1 Protocol - Init Ping Completion]\n        Federation[\ud83c\udf10 Federation Manager]\n        Transports[\ud83d\udd00 Transports - HTTP WS SSE Stdio]\n\n        Core --&gt; Protocol\n        Core --&gt; Federation\n        Core --&gt; Transports\n    end\n\n    subgraph Services\n        Tools[\ud83e\uddf0 Tool Service]\n        Resources[\ud83d\udcc1 Resource Service]\n        Prompts[\ud83d\udcdd Prompt Service]\n        Servers[\ud83e\udde9 Server Service]\n\n        Core --&gt; Tools\n        Core --&gt; Resources\n        Core --&gt; Prompts\n        Core --&gt; Servers\n    end\n\n    subgraph Persistence\n        DB[\ud83d\udcbe Database - SQLAlchemy]\n        Tools --&gt; DB\n        Resources --&gt; DB\n        Prompts --&gt; DB\n        Servers --&gt; DB\n    end\n\n    subgraph Caching\n        Cache[\u26a1 Cache - Redis or Memory]\n        Core --&gt; Cache\n    end</code></pre>"},{"location":"#audience","title":"Audience","text":"<p>MCP Gateway is designed for:</p> <ul> <li>AI Platform Teams that want to securely expose a variety of tools and models behind a consistent protocol</li> <li>DevOps Engineers looking for self-hostable control planes</li> <li>Open-source contributors building agents, clients, and adapters against MCP</li> <li>Cloud Architects deploying on Kubernetes, IBM Code Engine, AWS, or Azure</li> </ul>"},{"location":"#get-started","title":"Get Started","text":"<p>Check out the Quick Start for installation and usage, or go straight to:</p> <ul> <li>Features Overview</li> <li>Admin UI Walkthrough</li> <li>Deployment Options</li> <li>Using the <code>mcpgateway-wrapper</code></li> </ul> <p>The latest version can always be found here: https://pages.github.com/ibm/mcp-context-forge/</p>"},{"location":"#authors-and-contributors","title":"Authors and Contributors","text":"<ul> <li>Mihai Criveti - IBM Distinguished Engineer, Agentic AI</li> </ul>"},{"location":"architecture/","title":"Architecture Overview","text":"<p>The MCP Gateway acts as a unified entry point for tools, resources, prompts, and servers, federating local and remote nodes into a coherent MCP-compliant interface.</p> <p>This gateway:</p> <ul> <li>Wraps REST/MCP tools and resources under JSON-RPC and streaming protocols</li> <li>Offers a pluggable backend (cache, auth, storage)</li> <li>Exposes multiple transports (HTTP, WS, SSE, stdio)</li> <li>Automatically discovers and merges federated peers</li> </ul>"},{"location":"architecture/#system-architecture","title":"System Architecture","text":"<pre><code>graph TD\n    subgraph Clients\n        ui[\"Admin UI (Browser)\"]\n        cli[\"CLI Tools\"]\n        sdk[\"SDK / Scripts\"]\n    end\n\n    subgraph Gateway\n        app[\"FastAPI App\"]\n        auth[\"Auth Middleware&lt;br/&gt;(JWT + Basic)\"]\n        router[\"Transport Router&lt;br/&gt;(HTTP / WS / SSE / STDIO)\"]\n        services[\"Service Layer&lt;br/&gt;(Tool / Resource / Prompt / Server)\"]\n        db[\"Async DB&lt;br/&gt;(SQLAlchemy + Alembic)\"]\n        cache[\"Cache Backend&lt;br/&gt;(memory / redis / db)\"]\n        metrics[\"Metrics Exporter&lt;br/&gt;(/metrics Prometheus)\"]\n    end\n\n    subgraph Federation\n        discovery[\"Discovery Service&lt;br/&gt;(DNS-SD + Static Peers)\"]\n        peers[\"Remote Gateways\"]\n    end\n\n    ui --&gt; app\n    cli --&gt; router\n    sdk --&gt; router\n    app --&gt; auth --&gt; router\n    router --&gt; services\n    services --&gt; db\n    services --&gt; cache\n    services --&gt; metrics\n    services --&gt; discovery\n    discovery --&gt; peers\n</code></pre> <p>Each service (ToolService, ResourceService, etc.) operates independently with unified auth/session/context layers.</p>"},{"location":"architecture/#adrs-and-design-decisions","title":"ADRs and Design Decisions","text":"<p>We maintain a formal set of Architecture Decision Records documenting all major design tradeoffs and rationale.</p> <p>\ud83d\udcdc See the full ADR Index \u2192</p>"},{"location":"architecture/adr/","title":"Architecture Decision Records","text":"<p>This page tracks all significant design decisions made for the MCP Gateway project, using the ADR format.</p> ID Title Status Section Date 0001 Adopt FastAPI + Pydantic Accepted Framework 2025-02-01 0002 Use Async SQLAlchemy ORM Accepted Persistence 2025-02-01 0003 Expose Multi-Transport Endpoints Accepted Transport 2025-02-01 0004 Combine JWT &amp; Basic Auth Accepted Security 2025-02-01 0005 Structured JSON Logging Accepted Observability 2025-02-21 0006 Gateway &amp; Tool-Level Rate Limiting Accepted Performance 2025-02-21 0007 Pluggable Cache Backend (memory / Redis / DB) Accepted Caching 2025-02-21 0008 Federation &amp; Auto-Discovery via DNS-SD Accepted Federation 2025-02-21 0009 Built-in Health Checks &amp; Self-Monitoring Accepted Operations 2025-02-21 0010 Observability via Prometheus, Structured Logs Accepted Observability 2025-02-21 <p>\u2733\ufe0f Add new decisions chronologically and link to them from this table.</p>"},{"location":"architecture/adr/001-adopt-fastapi-pydantic/","title":"ADR-0001: Adopt FastAPI + Pydantic","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-01</li> <li>Deciders: Mihai Criveti</li> </ul>"},{"location":"architecture/adr/001-adopt-fastapi-pydantic/#context","title":"Context","text":"<p>The MCP Gateway must serve both human and machine clients with low-latency HTTP and WebSocket endpoints. Payloads require runtime validation and schema documentation, while internal data types must align with environment-driven settings and JSON models.</p> <p>We explored Python-native frameworks that support async-first operation, data validation, OpenAPI generation, and modular service layout.</p>"},{"location":"architecture/adr/001-adopt-fastapi-pydantic/#decision","title":"Decision","text":"<p>We will adopt:</p> <ul> <li>FastAPI as the core web framework for routing HTTP, WebSocket, and streaming endpoints.</li> <li>Pydantic v2 for all settings, schemas, and typed data models (e.g., <code>Tool</code>, <code>Resource</code>, <code>GatewayMetadata</code>, etc.).</li> </ul> <p>These will form the foundation for the application layer and public API.</p>"},{"location":"architecture/adr/001-adopt-fastapi-pydantic/#consequences","title":"Consequences","text":"<ul> <li>\u2728 Strong typing, runtime validation, and auto-generated OpenAPI specs.</li> <li>\ud83e\udde9 Unified model structure across internal logic, external APIs, and config parsing.</li> <li>\ud83d\ude80 Excellent async performance with Uvicorn and Starlette compatibility.</li> <li>\ud83d\udd12 Tight coupling to Pydantic means future transitions (e.g., to dataclasses or attrs) would be non-trivial.</li> </ul>"},{"location":"architecture/adr/001-adopt-fastapi-pydantic/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not Flask + Marshmallow Sync-first architecture, weak async support, manual OpenAPI generation. Django REST Framework Heavyweight, monolithic, tightly bound to Django ORM, not async-native. Tornado or Starlette alone More boilerplate to assemble middlewares, validators, and routing. Node.js + Fastify Excellent performance but requires a split language/runtime and loss of shared model code. Pure <code>httpx</code> + <code>uvicorn</code> + <code>pydantic-core</code> Too low-level; duplicating FastAPI features manually."},{"location":"architecture/adr/001-adopt-fastapi-pydantic/#status","title":"Status","text":"<p>This decision has been implemented in the current architecture.</p>"},{"location":"architecture/adr/002-use-async-sqlalchemy-orm/","title":"ADR-0002: Use Async SQLAlchemy ORM","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-01</li> <li>Deciders: Mihai Criveti</li> </ul>"},{"location":"architecture/adr/002-use-async-sqlalchemy-orm/#context","title":"Context","text":"<p>The gateway must persist:</p> <ul> <li>Tool metadata</li> <li>Resource configurations</li> <li>Usage metrics</li> <li>Peer discovery and federation state</li> </ul> <p>We require a relational database with schema evolution, strong typing, and async support. The current codebase already uses SQLAlchemy ORM models with an async engine and declarative mapping style.</p>"},{"location":"architecture/adr/002-use-async-sqlalchemy-orm/#decision","title":"Decision","text":"<p>We will use:</p> <ul> <li>SQLAlchemy 2.x (async) for all data persistence.</li> <li>AsyncSession and <code>async with</code> scoped transactions.</li> <li>Alembic for migrations, with autogeneration and CLI support.</li> <li>SQLite for development; PostgreSQL or MySQL for production via <code>DATABASE_URL</code>.</li> </ul> <p>This provides consistent, well-understood relational behavior and integrates cleanly with FastAPI.</p>"},{"location":"architecture/adr/002-use-async-sqlalchemy-orm/#consequences","title":"Consequences","text":"<ul> <li>\ud83e\uddf1 Mature and reliable ORM with a wide developer base.</li> <li>\ud83d\udd04 Fully async I/O stack without thread-pools or blocking.</li> <li>\ud83d\udd27 Migrations handled declaratively using Alembic.</li> <li>\ud83d\udcc4 Pydantic models can be derived from or synchronized with SQLAlchemy models if needed.</li> </ul>"},{"location":"architecture/adr/002-use-async-sqlalchemy-orm/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not Raw asyncpg / aiosqlite Manual query strings, error-prone joins, no built-in migrations. Tortoise ORM / GINO Less widely used, more magic, lower confidence in long-term maintainability. Django ORM Not async-native, tightly coupled to Django ecosystem, too heavyweight. NoSQL (e.g., MongoDB) No relational guarantees, weaker query language, major refactor from current SQL-based model."},{"location":"architecture/adr/002-use-async-sqlalchemy-orm/#status","title":"Status","text":"<p>This decision is in place and all gateway persistence uses SQLAlchemy 2.x with async support.</p>"},{"location":"architecture/adr/003-expose-multi-transport-endpoints/","title":"ADR-0003: Expose Multi-Transport Endpoints (HTTP / WebSocket / SSE / STDIO)","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-01</li> <li>Deciders: Mihai Criveti</li> </ul>"},{"location":"architecture/adr/003-expose-multi-transport-endpoints/#context","title":"Context","text":"<p>The MCP Gateway must serve diverse clients: web browsers, CLIs, language-specific SDKs, and headless daemons. Different use cases require support for both request/response and streaming interactions.</p> <p>Requirements:</p> <ul> <li>Human-readable RPC over HTTP for developers</li> <li>Low-latency streaming for long-running tools</li> <li>IPC-style invocations for local CLI integration</li> <li>Unified business logic regardless of transport</li> </ul>"},{"location":"architecture/adr/003-expose-multi-transport-endpoints/#decision","title":"Decision","text":"<p>The gateway will support the following built-in transports:</p> <ul> <li>HTTP JSON-RPC (primary RPC interface)</li> <li>WebSocket (bidirectional messaging)</li> <li>SSE (Server-Sent Events) (for push-only event streaming)</li> <li>STDIO (optional local CLI / subprocess transport)</li> </ul> <p>Transport selection is dynamic, based on environment (<code>TRANSPORT_TYPE</code>) and route grouping. All transports share the same service layer and authentication mechanisms.</p>"},{"location":"architecture/adr/003-expose-multi-transport-endpoints/#consequences","title":"Consequences","text":"<ul> <li>\u2705 Maximum client flexibility, supporting modern browsers and legacy CLI tools.</li> <li>\ud83d\udd04 Business logic remains decoupled from transport implementation.</li> <li>\ud83d\udcf6 Streaming transports (WS, SSE) require timeout, reconnection, and back-pressure handling. Easy expansion with new MCP standards</li> </ul>"},{"location":"architecture/adr/003-expose-multi-transport-endpoints/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not HTTP-only JSON API Poor fit for long-lived streaming tasks; requires polling. gRPC (HTTP/2) Not browser-friendly; requires generated stubs; less discoverable. Separate microservices per transport Code duplication, diverging implementations, and operational complexity. Single transport abstraction Reduces explicitness; transport-specific needs get buried in generic interfaces."},{"location":"architecture/adr/003-expose-multi-transport-endpoints/#status","title":"Status","text":"<p>All four transports are implemented in the current FastAPI application and are toggleable via configuration.</p>"},{"location":"architecture/adr/004-combine-jwt-and-basic-auth/","title":"ADR-0004: Combine JWT &amp; Basic Auth","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-01</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/004-combine-jwt-and-basic-auth/#context","title":"Context","text":"<p>The gateway needs to support two types of clients:</p> <ul> <li>Browser-based users using the Admin UI</li> <li>Headless clients such as scripts, services, and tools</li> </ul> <p>These use cases require different authentication workflows:</p> <ul> <li>Browsers prefer form-based login and session cookies.</li> <li>Automation prefers stateless, token-based access.</li> </ul> <p>The current config exposes both:</p> <ul> <li><code>BASIC_AUTH_USER</code> and <code>BASIC_AUTH_PASSWORD</code></li> <li><code>JWT_SECRET_KEY</code>, <code>JWT_EXPIRY_SECONDS</code>, and cookie settings</li> </ul>"},{"location":"architecture/adr/004-combine-jwt-and-basic-auth/#decision","title":"Decision","text":"<p>We will combine both authentication modes as follows:</p> <ul> <li>Basic Auth secures access to <code>/admin</code>. Upon success, a short-lived JWT cookie is issued.</li> <li>JWT Bearer token (via header or cookie) is required for all API, WebSocket, and SSE requests.</li> <li>Tokens are signed using the shared <code>JWT_SECRET_KEY</code> and include standard claims (sub, exp, scopes).</li> <li>When <code>AUTH_REQUIRED=false</code>, the gateway allows unauthenticated access (dev only).</li> </ul>"},{"location":"architecture/adr/004-combine-jwt-and-basic-auth/#consequences","title":"Consequences","text":"<ul> <li>\u2705 Developers can log in once via browser and obtain an authenticated session.</li> <li>\u2705 Scripts can use a generated JWT directly, with no credential storage.</li> <li>\u274c Tokens must be signed, rotated, and verified securely (TLS required).</li> <li>\ud83d\udd04 JWTs expire and must be refreshed periodically by clients.</li> </ul>"},{"location":"architecture/adr/004-combine-jwt-and-basic-auth/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not JWT only CLI tools need a pre-acquired token; not friendly for interactive login. Basic only Password sent on every request; cannot easily revoke or expire credentials. OAuth2 / OpenID Connect Too complex for self-hosted setups; requires external identity provider. mTLS client auth Secure but heavy; not usable in browsers or simple HTTP clients."},{"location":"architecture/adr/004-combine-jwt-and-basic-auth/#status","title":"Status","text":"<p>This combined authentication mechanism is implemented and enabled by default in the gateway.</p>"},{"location":"architecture/adr/005-structured-json-logging/","title":"ADR-0005: Structured JSON Logging","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-21</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/005-structured-json-logging/#context","title":"Context","text":"<p>The gateway must emit logs that:</p> <ul> <li>Are machine-readable and parseable by tools like ELK, Loki, or Datadog</li> <li>Include rich context (e.g., request ID, auth user, duration)</li> <li>Can be viewed in plaintext locally and JSON in production</li> </ul> <p>Our configuration supports:</p> <ul> <li><code>LOG_FORMAT</code>: <code>json</code> or <code>plain</code></li> <li><code>LOG_LEVEL</code>: standard Python levels</li> <li><code>LOG_FILE</code>: optional log file destination</li> </ul> <p>Logs are initialized at startup via <code>LoggingService</code>.</p>"},{"location":"architecture/adr/005-structured-json-logging/#decision","title":"Decision","text":"<p>Use the Python standard <code>logging</code> module with:</p> <ul> <li>A custom JSON formatter for structured logs (e.g. <code>{\"level\": \"INFO\", \"msg\": ..., \"request_id\": ...}</code>)</li> <li>Plain text output when <code>LOG_FORMAT=plain</code></li> <li>Per-request context via filters or middleware</li> <li>Global setup at app startup to avoid late binding issues</li> </ul>"},{"location":"architecture/adr/005-structured-json-logging/#consequences","title":"Consequences","text":"<ul> <li>\ud83d\udccb Easily parsed logs suitable for production observability pipelines</li> <li>\u2699\ufe0f Compatible with <code>stdout</code>, file, or syslog targets</li> <li>\ud83e\uddea Local development uses plain logs for readability</li> <li>\ud83e\uddf1 Minimal dependency footprint (no third-party logging libraries)</li> </ul>"},{"location":"architecture/adr/005-structured-json-logging/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not loguru Elegant syntax, but non-standard; poor compatibility with Python ecosystem. structlog Adds context pipeline complexity; not needed for current log volume. External sidecar (e.g. Fluent Bit) Useful downstream but doesn't solve app-side structure. Raw print() statements Unstructured, difficult to manage at scale."},{"location":"architecture/adr/005-structured-json-logging/#status","title":"Status","text":"<p>Structured logging is implemented in <code>LoggingService</code>, configurable via environment variables.</p>"},{"location":"architecture/adr/006-gateway-tool-rate-limiting/","title":"ADR-0006: Gateway &amp; Tool-Level Rate Limiting","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-21</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/006-gateway-tool-rate-limiting/#context","title":"Context","text":"<p>The MCP Gateway may serve hundreds of concurrent clients accessing multiple tools. Without protection, a single client or misbehaving tool could monopolize resources or overwhelm upstream services.</p> <p>The configuration includes:</p> <ul> <li><code>TOOL_RATE_LIMIT</code>: default limit in requests/min per tool/client</li> <li>Planned support for Redis-based or database-backed counters</li> </ul> <p>Current implementation is an in-memory token bucket.</p>"},{"location":"architecture/adr/006-gateway-tool-rate-limiting/#decision","title":"Decision","text":"<p>Implement a rate limiter at the tool invocation level, keyed by:</p> <ul> <li>Tool name</li> <li>Authenticated user / client identity (JWT or Basic)</li> <li>Time window (per-minute by default)</li> </ul> <p>Backend options:</p> <ul> <li>Memory (default for dev / single instance)</li> <li>Redis (planned for clustering / shared limits)</li> <li>Database (eventually consistent fallback)</li> </ul>"},{"location":"architecture/adr/006-gateway-tool-rate-limiting/#consequences","title":"Consequences","text":"<ul> <li>\u2705 Prevents abuse, controls cost, and provides predictable fairness</li> <li>\ud83d\udcc9 Failed requests return <code>429 Too Many Requests</code> with retry headers</li> <li>\u274c Memory backend does not scale across instances; Redis required for HA</li> <li>\ud83d\udd04 Optional override of limits via config/env for testing</li> </ul>"},{"location":"architecture/adr/006-gateway-tool-rate-limiting/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not No rate limiting Leaves gateway and tools vulnerable to overload or accidental DoS. Global rate limit only Heavy tools can starve lightweight tools; no fine-grained control. Proxy-level throttling (e.g. NGINX, Envoy) Can't distinguish tools or users inside payload; lacks granularity."},{"location":"architecture/adr/006-gateway-tool-rate-limiting/#status","title":"Status","text":"<p>Rate limiting is implemented for tool routes, with <code>TOOL_RATE_LIMIT</code> as the default policy.</p>"},{"location":"architecture/adr/007-pluggable-cache-backend/","title":"ADR-0007: Pluggable Cache Backend (memory / Redis / database)","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-21</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/007-pluggable-cache-backend/#context","title":"Context","text":"<p>The MCP Gateway uses short-lived caching for:</p> <ul> <li>Tool responses and resource lookups</li> <li>Peer discovery metadata</li> <li>Temporary session state and rate-limiting</li> </ul> <p>Different deployments require different caching characteristics:</p> <ul> <li>Dev mode: no external services (in-memory only)</li> <li>Production: clustered and persistent (Redis)</li> <li>Air-gapped: embedded fallback (database table)</li> </ul> <p>The config exposes <code>CACHE_TYPE=memory|redis|database</code>.</p>"},{"location":"architecture/adr/007-pluggable-cache-backend/#decision","title":"Decision","text":"<p>Abstract the caching system via a <code>CacheBackend</code> interface and support the following pluggable backends:</p> <ul> <li><code>MemoryCacheBackend</code>: simple <code>dict</code> with TTL, for dev and unit tests</li> <li><code>RedisCacheBackend</code>: shared, centralized cache for multi-node clusters</li> <li><code>DatabaseCacheBackend</code>: uses SQLAlchemy ORM to persist TTL-based records</li> </ul> <p>Selection is driven by the <code>CACHE_TYPE</code> environment variable. Code paths use a consistent interface regardless of backend.</p>"},{"location":"architecture/adr/007-pluggable-cache-backend/#consequences","title":"Consequences","text":"<ul> <li>\ud83d\udd04 Easy to switch cache backend per environment or load profile</li> <li>\ud83d\ude80 Redis allows horizontal scaling and persistent shared state</li> <li>\u274c Memory cache does not survive restarts or share state</li> <li>\ud83d\udc22 Database cache is slower, but useful in restricted networks</li> </ul>"},{"location":"architecture/adr/007-pluggable-cache-backend/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not Hardcoded Redis Adds operational overhead and single point of failure for dev. Memory-only cache Incompatible with horizontal scale or restart resilience. External CDN or HTTP cache Doesn't address in-process sessions, discovery, or tool state. Disk-based cache (e.g., shelve, pickle) Complex invalidation and concurrency issues; not cloud-ready."},{"location":"architecture/adr/007-pluggable-cache-backend/#status","title":"Status","text":"<p>All three cache backends are implemented and the gateway selects one dynamically based on configuration.</p>"},{"location":"architecture/adr/008-federation-discovery/","title":"ADR-0008: Federation &amp; Auto-Discovery via DNS-SD","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-21</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/008-federation-discovery/#context","title":"Context","text":"<p>The MCP Gateway must support federated operation, where multiple gateway instances:</p> <ul> <li>Automatically discover each other on a shared network</li> <li>Exchange metadata and tool/service availability</li> <li>Merge registries and route calls to remote nodes</li> </ul> <p>Manual configuration (e.g. hardcoded peer IPs) is error-prone and brittle in dynamic environments like laptops or Kubernetes.</p> <p>The codebase includes a <code>DiscoveryService</code> and federation settings such as:</p> <ul> <li><code>FEDERATION_ENABLED</code></li> <li><code>FEDERATION_DISCOVERY</code></li> <li><code>DISCOVERY_INTERVAL_SECONDS</code></li> </ul>"},{"location":"architecture/adr/008-federation-discovery/#decision","title":"Decision","text":"<p>We enable auto-discovery via DNS-SD (mDNS/zeroconf) by default. Each gateway:</p> <ul> <li>Publishes itself using <code>_mcp._tcp.local.</code> with TXT records</li> <li>Periodically probes for peers using <code>zeroconf</code> or a fallback registry</li> <li>Merges discovered gateways into its internal routing map</li> <li>Sends periodic liveness pings to verify peer health</li> </ul> <p>Static peer configuration is still supported for restricted networks.</p>"},{"location":"architecture/adr/008-federation-discovery/#consequences","title":"Consequences","text":"<ul> <li>\ud83d\udd0c Gateways connect seamlessly on the same local network or overlay mesh</li> <li>\ud83d\udd75\ufe0f\u200d\u2642\ufe0f DNS-SD adds moderate background network traffic, tunable via TTL</li> <li>\u26a0\ufe0f Firewalls or environments without multicast must use static peer config</li> <li>\u267b\ufe0f Federated topologies are self-healing and require no orchestration</li> </ul>"},{"location":"architecture/adr/008-federation-discovery/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not Static peer list only Manual entry, error-prone, not zero-config. Central registry (e.g. etcd, Consul) Adds external infrastructure and tight coordination. Cloud DNS-based discovery Requires cloud provider integration and persistent internet access. gRPC service registry Less transparent, requires protobuf tooling and internal coordination layer."},{"location":"architecture/adr/008-federation-discovery/#status","title":"Status","text":"<p>Auto-discovery is implemented using <code>zeroconf</code>, and federation is active when <code>FEDERATION_ENABLED=true</code>.</p> <p>Current feature is early pre-alpha and may not work correctly.</p>"},{"location":"architecture/adr/009-built-in-health-checks/","title":"ADR-0009: Built-in Health Checks &amp; Self-Monitoring","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-21</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/009-built-in-health-checks/#context","title":"Context","text":"<p>MCP Gateways must participate in mesh/federated deployments. Faulty nodes must be detected and removed automatically. Additionally, cloud-native infrastructure (like Kubernetes, Docker Swarm, or systemd watchdogs) needs a way to check local health.</p> <p>The gateway config supports health-related settings:</p> <ul> <li><code>HEALTH_CHECK_INTERVAL</code>: frequency of peer checks</li> <li><code>HEALTH_CHECK_TIMEOUT</code>: request timeout per probe</li> <li><code>UNHEALTHY_THRESHOLD</code>: number of failures before a peer is marked unhealthy</li> </ul> <p>The README and architecture describe <code>/health</code> and <code>/metrics</code> endpoints as built-in features</p>"},{"location":"architecture/adr/009-built-in-health-checks/#decision","title":"Decision","text":"<p>Implement two health-check levels:</p> <ol> <li>Local health endpoint at <code>/health</code>:</li> <li>Verifies database connectivity and response time</li> <li> <p>Optionally checks cache (e.g. Redis ping or in-memory status)</p> </li> <li> <p>Federated peer liveness:</p> </li> <li>Every <code>HEALTH_CHECK_INTERVAL</code>, we ping all registered peers via HTTP</li> <li>If a peer fails <code>UNHEALTHY_THRESHOLD</code> times consecutively, it's temporarily deactivated</li> <li>A separate background task handles this (see <code>FederationManager</code>)</li> </ol> <p>Health info is also published to <code>/metrics</code> in Prometheus format.</p>"},{"location":"architecture/adr/009-built-in-health-checks/#consequences","title":"Consequences","text":"<ul> <li>\u2705 Federated topologies can eject bad nodes quickly and re-accept them later</li> <li>\u2705 Local health can be used by Kubernetes probes, HAProxy, etc.</li> <li>\ud83d\udd04 Gateways that go offline briefly won't be removed immediately (tunable)</li> <li>\ud83d\udd0d Metrics include last check time, RTT, and result status</li> </ul>"},{"location":"architecture/adr/009-built-in-health-checks/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not No health checks Delayed or no reaction to failures; requires manual debugging Rely on Kubernetes probes Only detects local process health, not remote peers External APM agent (Datadog) Complex setup, costly for small/self-hosted use cases Central heartbeat server Single point of failure, requires extra infra"},{"location":"architecture/adr/009-built-in-health-checks/#status","title":"Status","text":"<p>This is implemented as part of the <code>FederationManager</code> and exposed via <code>/health</code> and <code>/metrics</code> endpoints.</p>"},{"location":"architecture/adr/010-observability-prometheus/","title":"ADR-0010: Observability via Prometheus, Structured Logs, and Metrics","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-21</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/010-observability-prometheus/#context","title":"Context","text":"<p>The MCP Gateway is a long-running service that executes tools, processes requests, and federates with remote peers. Operators and developers must be able to observe:</p> <ul> <li>Overall system health</li> <li>Request throughput and latency</li> <li>Tool and resource usage</li> <li>Error rates and failure patterns</li> <li>Federation behavior and peer availability</li> </ul> <p>The gateway needs to surface this without requiring external instrumentation or agents.</p>"},{"location":"architecture/adr/010-observability-prometheus/#decision","title":"Decision","text":"<p>We will implement native observability features using:</p> <ol> <li>Structured JSON logs with optional plaintext fallback:</li> <li>Controlled by <code>LOG_FORMAT=json|text</code> and <code>LOG_LEVEL</code></li> <li> <p>Includes fields: timestamp, level, logger name, request ID, route, auth user, latency</p> </li> <li> <p>Prometheus-compatible <code>/metrics</code> endpoint:</p> </li> <li>Exposes key counters and histograms: tool invocations, failures, resource loads, peer syncs, etc.</li> <li> <p>Uses plain <code>text/plain; version=0.0.4</code> exposition format</p> </li> <li> <p>Latency decorators and in-code timing for critical paths:</p> </li> <li>Completion requests</li> <li>Resource resolution</li> <li> <p>Federation sync/health probes</p> </li> <li> <p>Per-request IDs and correlation:</p> </li> <li>Middleware attaches <code>X-Request-ID</code> if present or generates a new one</li> <li>Request ID propagates through logs and errors</li> </ol>"},{"location":"architecture/adr/010-observability-prometheus/#consequences","title":"Consequences","text":"<ul> <li>\ud83d\udcca Metrics can be scraped by Prometheus and visualized in Grafana</li> <li>\ud83d\udd0d Developers can trace logs by request or user</li> <li>\ud83d\udee0\ufe0f No external sidecars required for basic visibility</li> <li>\ud83d\udce6 Docker image contains <code>/metrics</code> by default and logs to <code>stdout</code> (JSON)</li> </ul>"},{"location":"architecture/adr/010-observability-prometheus/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not No structured logging Difficult to parse or filter logs; weak correlation per request Third-party APM (e.g., Datadog) Adds vendor lock-in, overhead, and cost Syslog or Fluentd only Requires extra deployment layers; still needs JSON emitters StatsD / Telegraf metrics Less common today than Prometheus; harder to self-host"},{"location":"architecture/adr/010-observability-prometheus/#status","title":"Status","text":"<p>Implemented in <code>LoggingService</code> and <code>metrics_router</code>. Observability is active by default for all transports and routes.</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"deployment/","title":"Deployment Overview","text":"<p>This section explains how to deploy MCP Gateway in various environments \u2014 from local development to cloud-native platforms like Kubernetes, IBM Code Engine, AWS, and Azure.</p>"},{"location":"deployment/#deployment-options","title":"\ud83d\uddfa Deployment Options","text":"<p>MCP Gateway supports multiple deployment strategies:</p> Method Description Local Run directly on your dev machine using <code>make</code>, <code>uvicorn</code>, or a virtual-env Container Package and run as a single container image using Podman or Docker Compose Stack Bring up Gateway + Postgres + Redis (and optional MPC servers) with Podman/Docker Compose Minikube Launch a local single-node Kubernetes cluster and deploy the Gateway stack Kubernetes Generic manifests or Helm chart for any K8s-compliant platform OpenShift OpenShift-specific deployment using Routes, SCCs, and Operator-managed back-ends IBM Code Engine Serverless container build &amp; run on IBM Cloud AWS Deploy on ECS Fargate, EKS, or EC2-hosted containers Azure Run on Azure Container Apps, App Service, or AKS"},{"location":"deployment/#runtime-configuration","title":"\ud83d\udee0 Runtime Configuration","text":"<p>MCP Gateway loads configuration from:</p> <ul> <li><code>.env</code> file (in project root or mounted at <code>/app/.env</code>)</li> <li>Environment variables (overrides <code>.env</code>)</li> <li>CLI flags (e.g., via <code>run.sh</code>)</li> </ul>"},{"location":"deployment/#health-checks","title":"\ud83e\uddea Health Checks","text":"<p>All deployments should expose:</p> <pre><code>GET /health\n</code></pre> <p>This returns basic system latency metrics and can be used with cloud provider readiness probes.</p>"},{"location":"deployment/#container-basics","title":"\ud83d\udce6 Container Basics","text":"<p>The default container image:</p> <ul> <li>Uses the Red Hat Universal Base image running as a non-root user</li> <li>Exposes port <code>4444</code></li> <li>Runs <code>gunicorn</code> with Uvicorn workers</li> <li>Uses <code>.env</code> for all settings</li> </ul> <p>For Kubernetes, you can mount a ConfigMap or Secret as <code>.env</code>.</p>"},{"location":"deployment/aws/","title":"\ud83d\udfe7 AWS","text":"<p>MCP Gateway can be deployed to AWS using multiple container-based services:</p> <ul> <li>ECS (Fargate or EC2-backed)</li> <li>EKS (Elastic Kubernetes Service)</li> <li>EC2 (direct VM hosting with Docker)</li> </ul>"},{"location":"deployment/aws/#option-1-ecs-fargate","title":"\ud83d\ude80 Option 1: ECS (Fargate)","text":"<p>ECS is a fully managed container orchestration service. Use it to deploy MCP Gateway without managing servers.</p>"},{"location":"deployment/aws/#steps","title":"Steps","text":"<ol> <li>Build and push your image:</li> </ol> <pre><code>docker build -t YOUR_ECR_URI/mcpgateway .\naws ecr get-login-password | docker login --username AWS --password-stdin YOUR_ECR_URI\ndocker push YOUR_ECR_URI/mcpgateway\n</code></pre> <ol> <li> <p>Create an ECS Task Definition:</p> </li> <li> <p>Use port <code>4444</code></p> </li> <li> <p>Mount a secret or config for your <code>.env</code> (or set environment variables manually)</p> </li> <li> <p>Create a Service:</p> </li> <li> <p>Use a Load Balancer (Application LB)</p> </li> <li>Map <code>/</code> or <code>/admin</code> to port <code>4444</code></li> </ol>"},{"location":"deployment/aws/#option-2-eks","title":"\ud83d\ude80 Option 2: EKS","text":"<p>Use the same Kubernetes deployment guide and run on Amazon EKS.</p> <p>You can:</p> <ul> <li>Use <code>kubectl</code> + <code>eksctl</code></li> <li>Store <code>.env</code> as a Secret or ConfigMap</li> <li>Use AWS Load Balancer Controller or NGINX Ingress</li> </ul>"},{"location":"deployment/aws/#option-3-ec2-docker","title":"\ud83d\ude80 Option 3: EC2 (Docker)","text":"<ol> <li>Launch a VM (e.g., Ubuntu)</li> <li>Install Docker</li> <li>Copy your <code>.env</code> file and build the container:</li> </ol> <pre><code>scp .env ec2-user@host:/home/ec2-user\nssh ec2-user@host\ndocker build -t mcpgateway .\ndocker run -p 80:4444 --env-file .env mcpgateway\n</code></pre>"},{"location":"deployment/aws/#security-tips","title":"\ud83d\udee1\ufe0f Security Tips","text":"<ul> <li>Set <code>AUTH_REQUIRED=true</code> in production</li> <li>Use <code>JWT_SECRET_KEY</code> and <code>AUTH_ENCRYPTION_SECRET</code></li> <li>Terminate TLS at the ELB level, or use Caddy/Nginx in-container if needed</li> </ul>"},{"location":"deployment/aws/#dns-access","title":"\ud83d\udce1 DNS &amp; Access","text":"<p>You can point Route53 or your DNS provider to the Load Balancer hostname.</p> <p>Example:</p> <pre><code>gateway.example.com -&gt; my-elb-1234.us-west-2.elb.amazonaws.com\n</code></pre>"},{"location":"deployment/azure/","title":"\ud83d\udd37 Azure","text":"<p>MCP Gateway can be deployed on Azure in multiple ways:</p> <ul> <li>Azure Container Apps (serverless)</li> <li>Azure App Service (PaaS for containers)</li> <li>Azure Kubernetes Service (AKS) (fully managed K8s)</li> </ul>"},{"location":"deployment/azure/#option-1-azure-container-apps-recommended","title":"\ud83d\ude80 Option 1: Azure Container Apps (Recommended)","text":"<p>Azure Container Apps is ideal for lightweight container-based workloads.</p>"},{"location":"deployment/azure/#steps","title":"Steps","text":"<ol> <li>Build and push your image to Azure Container Registry (ACR):</li> </ol> <pre><code>az acr login --name yourregistry\ndocker tag mcpgateway yourregistry.azurecr.io/mcpgateway\ndocker push yourregistry.azurecr.io/mcpgateway\n</code></pre> <ol> <li>Create the container app:</li> </ol> <pre><code>az containerapp create \\\n  --name mcpgateway \\\n  --resource-group my-rg \\\n  --image yourregistry.azurecr.io/mcpgateway \\\n  --target-port 4444 \\\n  --environment my-container-env \\\n  --registry-server yourregistry.azurecr.io \\\n  --env-vars-from-secrets .env\n</code></pre> <p>You can mount <code>.env</code> via Key Vault or inject environment variables directly.</p>"},{"location":"deployment/azure/#option-2-azure-app-service","title":"\ud83d\ude80 Option 2: Azure App Service","text":"<ol> <li>Push your image to ACR</li> <li>Create an App Service plan and container-based Web App</li> <li>Set <code>PORT=4444</code> and other env vars in Configuration \u2192 Application settings</li> <li>Map your custom domain (optional)</li> </ol>"},{"location":"deployment/azure/#option-3-azure-kubernetes-service-aks","title":"\ud83d\ude80 Option 3: Azure Kubernetes Service (AKS)","text":"<p>Use your existing Kubernetes deployment instructions, but deploy to AKS.</p> <ul> <li>Deploy with Helm or <code>kubectl</code></li> <li>Use Azure Load Balancer or Application Gateway</li> <li>Store secrets in Azure Key Vault (optional)</li> </ul>"},{"location":"deployment/azure/#secrets-config","title":"\ud83d\udd10 Secrets &amp; Config","text":"<p>Use Azure CLI to upload your <code>.env</code> values to App Config or Key Vault:</p> <pre><code>az keyvault secret set --vault-name my-kv --name JWT-SECRET --value \"super-secret\"\n</code></pre> <p>Then reference in App Service / Container App using environment variables.</p>"},{"location":"deployment/azure/#dns-tls","title":"\ud83d\udce1 DNS &amp; TLS","text":"<ul> <li>Use Azure Front Door or Application Gateway to handle TLS</li> <li>Point your domain to the public IP or hostname of the service</li> </ul> <p>Example:</p> <pre><code>gateway.example.com \u2192 mygateway.eastus.azurecontainerapps.io\n</code></pre>"},{"location":"deployment/compose/","title":"\ud83e\udde9 Docker Compose","text":"<p>Running MCP Gateway with Compose spins up a full stack (Gateway, Postgres, Redis, optional MPC servers) behind a single YAML file. The Makefile detects Podman or Docker automatically, and you can override it with <code>COMPOSE_ENGINE=</code>. Health-checks (<code>service_healthy</code>) gate the Gateway until the database is ready, preventing race conditions.</p>"},{"location":"deployment/compose/#build-the-images","title":"\ud83d\udc33/\ud83e\uddad Build the images","text":""},{"location":"deployment/compose/#using-make-preferred","title":"Using Make (preferred)","text":"Target Image Dockerfile Notes <code>make podman</code> <code>mcpgateway:latest</code> Containerfile Rootless Podman, dev-oriented <code>make podman-prod</code> <code>mcpgateway:latest</code> Containerfile.lite Ultra-slim UBI 9-micro build <code>make docker</code> <code>mcpgateway:latest</code> Containerfile Docker Desktop / CI runners <code>make docker-prod</code> <code>mcpgateway:latest</code> Containerfile.lite Same multi-stage \"lite\" build"},{"location":"deployment/compose/#manual-equivalents","title":"Manual equivalents","text":"<pre><code># Podman (dev image)\npodman build -t mcpgateway-dev:latest -f Containerfile .\n\n# Podman (prod image, AMD64, squash layers)\npodman build --platform=linux/amd64 --squash \\\n  -t mcpgateway:latest -f Containerfile.lite .\n\n# Docker (dev image)\ndocker build -t mcpgateway-dev:latest -f Containerfile .\n\n# Docker (prod image)\ndocker build -t mcpgateway:latest -f Containerfile.lite .\n</code></pre> <p>Apple Silicon caveat <code>Containerfile.lite</code> derives from ubi9-micro. Running it via QEMU emulation on M-series Macs often fails with a <code>glibc x86-64-v2</code> error. Use the regular image or build a native <code>linux/arm64</code> variant on Mac.</p>"},{"location":"deployment/compose/#start-the-compose-stack","title":"\ud83c\udfc3 Start the Compose stack","text":""},{"location":"deployment/compose/#with-make","title":"With Make","text":"<pre><code>make compose-up                   # auto-detects engine\nCOMPOSE_ENGINE=docker make compose-up   # force Docker\nCOMPOSE_ENGINE=podman make compose-up   # force Podman\n</code></pre>"},{"location":"deployment/compose/#without-make","title":"Without Make","text":"Make target Docker CLI Podman built-in podman-compose <code>compose-up</code> <code>docker compose -f podman-compose.yml up -d</code> <code>podman compose -f podman-compose.yml up -d</code> <code>podman-compose -f podman-compose.yml up -d</code> <code>compose-restart</code> <code>docker compose up -d --pull=missing --build</code> idem idem <code>compose-logs</code> <code>docker compose logs -f</code> <code>podman compose logs -f</code> <code>podman-compose logs -f</code> <code>compose-ps</code> <code>docker compose ps</code> <code>podman compose ps</code> <code>podman-compose ps</code> <code>compose-stop</code> <code>docker compose stop</code> <code>podman compose stop</code> <code>podman-compose stop</code> <code>compose-down</code> <code>docker compose down</code> <code>podman compose down</code> <code>podman-compose down</code> <code>compose-clean</code> <code>docker compose down -v</code> (removes volumes) <code>podman compose down -v</code> <code>podman-compose down -v</code>"},{"location":"deployment/compose/#access-and-verify","title":"\ud83c\udf10 Access and verify","text":"<ul> <li>Gateway URL: http://localhost:4444   (Bound to <code>0.0.0.0</code> inside the container so port-forwarding works.)</li> </ul> <pre><code>curl http://localhost:4444/health    # {\"status\":\"ok\"}\n</code></pre> <ul> <li>Logs: <code>make compose-logs</code> or raw <code>docker compose logs -f gateway</code>.</li> </ul>"},{"location":"deployment/compose/#selecting-a-database","title":"\ud83d\uddc4 Selecting a database","text":"<p>Uncomment one service block in <code>podman-compose.yml</code> and align <code>DATABASE_URL</code>:</p> Service block Connection string <code>postgres:</code> (default) <code>postgresql://postgres:...@postgres:5432/mcp</code> <code>mariadb:</code> <code>mysql+pymysql://admin:...@mariadb:3306/mcp</code> <code>mysql:</code> <code>mysql+pymysql://mysql:...@mysql:3306/mcp</code> <code>mongodb:</code> <code>mongodb://admin:...@mongodb:27017/mcp</code> <p>Named volumes (<code>pgdata</code>, <code>mariadbdata</code>, <code>mysqldata</code>, <code>mongodata</code>) isolate persistent data.</p>"},{"location":"deployment/compose/#lifecycle-cheatsheet","title":"\ud83d\udd04 Lifecycle cheatsheet","text":"Task Make Manual (engine-agnostic) Start / create <code>make compose-up</code> <code>&lt;engine&gt; compose up -d</code> Re-create changed <code>make compose-restart</code> <code>&lt;engine&gt; compose up -d --pull=missing --build</code> Tail logs <code>make compose-logs</code> <code>&lt;engine&gt; compose logs -f</code> Shell into gateway <code>make compose-shell</code> <code>&lt;engine&gt; compose exec gateway /bin/sh</code> Stop <code>make compose-stop</code> <code>&lt;engine&gt; compose stop</code> Remove containers <code>make compose-down</code> <code>&lt;engine&gt; compose down</code> Nuke volumes <code>make compose-clean</code> <code>&lt;engine&gt; compose down -v</code> <p><code>&lt;engine&gt;</code> = <code>docker</code>, <code>podman</code>, or <code>podman-compose</code> as shown earlier.</p>"},{"location":"deployment/compose/#troubleshooting-port-publishing-on-wsl2-rootless-podman","title":"\ud83d\udd0d Troubleshooting port publishing on WSL2 (rootless Podman)","text":"<pre><code># Verify the port is listening (dual-stack)\nss -tlnp | grep 4444        # modern tool\nnetstat -anp | grep 4444    # legacy fallback\n</code></pre> <p>A line like <code>LISTEN rootlessport</code> is normal \u2013 the IPv6 wildcard socket (<code>::</code>) also accepts IPv4 when <code>net.ipv6.bindv6only=0</code> (the default on Linux).</p> <p>WSL2 quirk</p> <p>WSL's NAT maps only the IPv6 side, so <code>http://127.0.0.1:4444</code> fails from Windows. Tell Podman you are inside WSL and restart your containers:</p> <pre><code># inside the WSL distro\necho \"wsl\" | sudo tee /etc/containers/podman-machine\n</code></pre> <p><code>ss</code> should now show an explicit <code>0.0.0.0:4444</code> listener, making the service reachable from Windows and the LAN.</p>"},{"location":"deployment/compose/#references","title":"\ud83d\udcda References","text":"<ul> <li>Docker Compose CLI (<code>up</code>, <code>logs</code>, <code>down</code>) \u2013 official docs</li> <li>Podman's integrated compose wrapper \u2013 man page</li> <li><code>podman-compose</code> rootless implementation \u2013 GitHub project</li> <li>Health-check gating with <code>depends_on: condition: service_healthy</code></li> <li>UBI9 runtime on Apple Silicon limitations (<code>x86_64-v2</code> glibc)</li> <li>General Containerfile build guidance (Fedora/Red Hat)</li> </ul>"},{"location":"deployment/container/","title":"\ud83d\udce6 Container Deployment","text":"<p>You can run MCP Gateway as a fully self-contained container. This is the recommended method for production or platform-agnostic deployments.</p>"},{"location":"deployment/container/#build-the-container","title":"\ud83d\udc33 Build the Container","text":""},{"location":"deployment/container/#using-podman-recommended","title":"Using Podman (recommended)","text":"<pre><code>make podman\n</code></pre>"},{"location":"deployment/container/#using-docker-manual-alternative","title":"Using Docker (manual alternative)","text":"<pre><code>docker build -t mcpgateway:latest -f Containerfile .\n</code></pre> <p>The base image uses <code>python:3.11-slim</code> with Gunicorn and Uvicorn workers.</p>"},{"location":"deployment/container/#run-the-container","title":"\ud83c\udfc3 Run the Container","text":""},{"location":"deployment/container/#with-http-no-tls","title":"With HTTP (no TLS)","text":"<pre><code>make podman-run\n</code></pre> <p>This starts the app at <code>http://localhost:4444</code>.</p>"},{"location":"deployment/container/#with-self-signed-tls-https","title":"With Self-Signed TLS (HTTPS)","text":"<pre><code>make podman-run-ssl\n</code></pre> <p>Runs the gateway using certs from <code>./certs/</code>, available at:</p> <pre><code>https://localhost:4444\n</code></pre>"},{"location":"deployment/container/#runtime-configuration","title":"\u2699 Runtime Configuration","text":"<p>All environment variables can be passed via:</p> <ul> <li><code>docker run -e KEY=value</code></li> <li>A mounted <code>.env</code> file (<code>--env-file .env</code>)</li> </ul>"},{"location":"deployment/container/#test-the-running-container","title":"\ud83e\uddea Test the Running Container","text":"<pre><code>curl http://localhost:4444/health\ncurl http://localhost:4444/tools\n</code></pre> <p>Use <code>curl -k</code> if running with self-signed TLS</p>"},{"location":"deployment/container/#stop-clean-up","title":"\ud83e\uddfc Stop &amp; Clean Up","text":"<pre><code>podman stop mcpgateway\npodman rm mcpgateway\n</code></pre> <p>Or with Docker:</p> <pre><code>docker stop mcpgateway\ndocker rm mcpgateway\n</code></pre>"},{"location":"deployment/google-cloud-run/","title":"\u2601\ufe0f Deploying MCP Gateway on Google Cloud Run","text":"<p>MCP Gateway can be deployed to Google Cloud Run, a fully managed, autoscaling platform for containerized applications. This guide provides step-by-step instructions to provision PostgreSQL and Redis backends, deploy the container, configure environment variables, authenticate using JWT, and monitor logs\u2014all optimized for cost-efficiency.</p>"},{"location":"deployment/google-cloud-run/#overview","title":"\u2705 Overview","text":"<p>Google Cloud Run is an ideal platform for MCP Gateway due to its:</p> <ul> <li>Serverless and cost-efficient model with scale-to-zero capability.</li> <li>Public HTTPS endpoints with automatic TLS configuration.</li> <li>Seamless integration with Cloud SQL (PostgreSQL) and Memorystore (Redis).</li> <li>Compatibility with public container registries like GitHub's <code>ghcr.io</code>.</li> </ul> <p>You can deploy the public image directly:</p> <pre><code>ghcr.io/ibm/mcp-context-forge:latest\n</code></pre>"},{"location":"deployment/google-cloud-run/#prerequisites","title":"\ud83d\udee0 Prerequisites","text":""},{"location":"deployment/google-cloud-run/#1-install-and-initialize-google-cloud-cli-gcloud","title":"1. Install and Initialize Google Cloud CLI (<code>gcloud</code>)","text":"<p>Install the Google Cloud SDK:</p> <ul> <li>macOS (Homebrew):</li> </ul> <pre><code>brew install --cask google-cloud-sdk\n</code></pre> <ul> <li>Debian/Ubuntu:</li> </ul> <p>These steps also apply to WSL2 running Ubuntu.</p> <pre><code># Update package lists and install necessary utilities\nsudo apt-get update\nsudo apt-get install -y apt-transport-https ca-certificates gnupg curl\n\n# Import the Google Cloud public key securely\n# This is for newer distributions (Debian 9+ or Ubuntu 18.04+).\ncurl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg\n\n# Add the Google Cloud SDK distribution URI as a package source\n# This is for newer distributions, ensuring packages are signed by the key we just added.\necho \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main\" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list\n\n# Update your package lists again to recognize the new repository\nsudo apt-get update\n\n# Install the Google Cloud CLI\nsudo apt-get install -y google-cloud-cli\n</code></pre> <ul> <li>Windows (PowerShell):</li> </ul> <pre><code>winget install --id Google.CloudSDK\n</code></pre> <p>After installation, initialize the CLI:</p> <pre><code>gcloud init\n</code></pre> <p>Authenticate with your Google Cloud account:</p> <pre><code>gcloud auth login\n</code></pre> <p>Set a project ID:</p> <pre><code>gcloud config set project PROJECT_ID\n</code></pre>"},{"location":"deployment/google-cloud-run/#2-enable-required-apis","title":"2. Enable Required APIs","text":"<p>Enable the necessary Google Cloud APIs:</p> <pre><code># This might take a minute..\ngcloud services enable \\\n  run.googleapis.com \\\n  sqladmin.googleapis.com \\\n  redis.googleapis.com\n</code></pre>"},{"location":"deployment/google-cloud-run/#3-install-docker","title":"3. Install Docker","text":"<p>Ensure Docker is installed for local testing and JWT token generation. Visit Docker's official website for installation instructions.</p>"},{"location":"deployment/google-cloud-run/#4-set-environment-variables","title":"4. Set Environment Variables","text":"<p>Prepare the following environment variables:</p> Variable Description <code>JWT_SECRET_KEY</code> Secret key for signing JWT tokens <code>BASIC_AUTH_USER</code> Username for HTTP Basic Authentication <code>BASIC_AUTH_PASSWORD</code> Password for HTTP Basic Authentication <code>AUTH_REQUIRED</code> Set to <code>true</code> to enforce authentication <code>DATABASE_URL</code> PostgreSQL connection string <code>REDIS_URL</code> Redis connection string <code>CACHE_TYPE</code> Set to <code>redis</code> for production environments <code>PORT</code> Port number the application listens on (e.g., <code>4444</code>) <p>Consider creating a <code>.env.gcr</code> file where you will record the various settings used during deployment.</p> <pre><code># \u2500\u2500\u2500 Google Cloud project \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nPROJECT_ID=\nREGION=us-central1\nSERVICE_NAME=mcpgateway\n\n# \u2500\u2500\u2500 Authentication \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nJWT_SECRET_KEY=\nBASIC_AUTH_USER=\nBASIC_AUTH_PASSWORD=\nAUTH_REQUIRED=true\n\n# \u2500\u2500\u2500 Cloud SQL (PostgreSQL) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nSQL_INSTANCE=mcpgw-db\nSQL_REGION=us-central1\nDATABASE_URL=postgresql://postgres:&lt;PASSWORD&gt;@&lt;SQL_IP&gt;:5432/mcpgw\n\n# \u2500\u2500\u2500 Memorystore (Redis) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nREDIS_INSTANCE=mcpgw-redis\nREDIS_REGION=us-central1\nREDIS_URL=redis://&lt;REDIS_IP&gt;:6379/0\nCACHE_TYPE=redis\n\n# \u2500\u2500\u2500 Application \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nPORT=4444\n</code></pre>"},{"location":"deployment/google-cloud-run/#setup-steps","title":"\u2699\ufe0f Setup Steps","text":""},{"location":"deployment/google-cloud-run/#1-provision-cloud-sql-postgresql","title":"1. Provision Cloud SQL (PostgreSQL)","text":"<p>Create a PostgreSQL instance using the <code>db-f1-micro</code> tier for cost efficiency:</p> <pre><code># POSTGRES_16 and POSTGRES_17 default to Enterprise Plus; adding --edition=ENTERPRISE lets you pick db-f1-micro\ngcloud sql instances create mcpgw-db \\\n  --database-version=POSTGRES_17 \\\n  --edition=ENTERPRISE \\\n  --tier=db-f1-micro \\\n  --region=us-central1\n</code></pre> <p>Set the password for the <code>postgres</code> user:</p> <pre><code>gcloud sql users set-password postgres \\\n  --instance=mcpgw-db \\\n  --password=mysecretpassword\n</code></pre> <p>Create the <code>mcpgw</code> database:</p> <pre><code>gcloud sql databases create mcpgw --instance=mcpgw-db\n</code></pre> <p>Retrieve the IP address of the instance:</p> <pre><code>gcloud sql instances describe mcpgw-db \\\n  --format=\"value(ipAddresses.ipAddress)\"\n</code></pre> <p>Note: The <code>db-f1-micro</code> tier is a shared-core instance designed for low-cost development and testing environments. It is not covered by the Cloud SQL SLA.</p>"},{"location":"deployment/google-cloud-run/#2-provision-memorystore-redis","title":"2. Provision Memorystore (Redis)","text":"<p>Create a Redis instance using the Basic Tier with 1 GiB capacity:</p> <pre><code>gcloud redis instances create mcpgw-redis \\\n  --region=us-central1 \\\n  --tier=BASIC \\\n  --size=1\n</code></pre> <p>Retrieve the host IP address:</p> <pre><code>gcloud redis instances describe mcpgw-redis \\\n  --region=us-central1 \\\n  --format=\"value(host)\"\n</code></pre> <p>Note: The Basic Tier provides a standalone Redis instance suitable for applications that can tolerate potential data loss during failures.</p>"},{"location":"deployment/google-cloud-run/#3-deploy-to-google-cloud-run","title":"3. Deploy to Google Cloud Run","text":"<p>Cloud Run only accepts container images that live in Artifact Registry or the older Container Registry endpoints; anything pulled from the public internet (for example ghcr.io) must first be proxied or copied into Artifact Registry.</p>"},{"location":"deployment/google-cloud-run/#set-your-project-id","title":"Set Your Project ID","text":"<p>Begin by setting your Google Cloud project ID as an environment variable:</p> <pre><code>export PROJECT_ID=\"your-project-id\"\n</code></pre> <p>Replace <code>\"your-project-id\"</code> with your actual Google Cloud project ID.</p>"},{"location":"deployment/google-cloud-run/#enable-required-apis","title":"Enable Required APIs","text":"<p>Ensure that the necessary Google Cloud APIs are enabled:</p> <pre><code>gcloud services enable artifactregistry.googleapis.com\n</code></pre>"},{"location":"deployment/google-cloud-run/#create-a-remote-repository","title":"Create a Remote Repository","text":"<p>Set up a remote repository in Artifact Registry that proxies GitHub Container Registry (GHCR):</p> <pre><code>gcloud artifacts repositories create ghcr-remote \\\n  --project=$PROJECT_ID \\\n  --repository-format=docker \\\n  --location=us-central1 \\\n  --description=\"Proxy for GitHub Container Registry\" \\\n  --mode=remote-repository \\\n  --remote-docker-repo=https://ghcr.io\n</code></pre>"},{"location":"deployment/google-cloud-run/#retrieve-cloud-sql-instance-connection-name","title":"Retrieve Cloud SQL Instance Connection Name","text":"<pre><code>gcloud sql instances describe mcpgw-db \\\n  --format=\"value(connectionName)\"\n</code></pre> <p>It will output something like this:</p> <pre><code>your-project-id:us-central1:mcpgw-db\n</code></pre>"},{"location":"deployment/google-cloud-run/#allow-ingress-to-your-database","title":"Allow ingress to your database.","text":"<p>Consider only allowing the Cloud Run IP range.</p> <pre><code>gcloud sql instances patch mcpgw-db \\\n  --authorized-networks=0.0.0.0/0\n</code></pre>"},{"location":"deployment/google-cloud-run/#deploy-the-mcp-gateway-container-with-minimal-resource-allocation","title":"Deploy the MCP Gateway container with minimal resource allocation:","text":"<pre><code>gcloud run deploy mcpgateway \\\n  --image=us-central1-docker.pkg.dev/$PROJECT_ID/ghcr-remote/ibm/mcp-context-forge:latest\n  --region=us-central1 \\\n  --platform=managed \\\n  --allow-unauthenticated \\\n  --port=4444 \\\n  --cpu=1 \\\n  --memory=512i \\\n  --max-instances=1 \\\n  --set-env-vars=\\\nJWT_SECRET_KEY=jwt-secret-key,\\\nBASIC_AUTH_USER=admin,\\\nBASIC_AUTH_PASSWORD=changeme,\\\nAUTH_REQUIRED=true,\\\nDATABASE_URL=postgresql://postgres:mysecretpassword@&lt;SQL_IP&gt;:5432/mcpgw,\\\nREDIS_URL=redis://&lt;REDIS_IP&gt;:6379/0,\\\nCACHE_TYPE=redis,\\\nHOST=0.0.0.0,\\\nGUNICORN_WORKERS=1\n</code></pre> <p>Replace <code>&lt;SQL_IP&gt;</code> and <code>&lt;REDIS_IP&gt;</code> with the actual IP addresses obtained from the previous steps. Do not leave out the HOST=0.0.0.0 to ensure the container listens on all ports, or the container engine won't be able to reach the container. Setting the number of GUNICORN_WORKERS lets you control how much memory the service consumes.</p>"},{"location":"deployment/google-cloud-run/#check-the-logs","title":"Check the logs","text":""},{"location":"deployment/google-cloud-run/#gcloud-run-services-logs-read-mcpgateway-regionus-central1","title":"<pre><code>gcloud run services logs read mcpgateway --region=us-central1\n</code></pre>","text":""},{"location":"deployment/google-cloud-run/#check-that-the-database-is-created","title":"Check that the database is created:","text":"<p>You can use any PostgreSQL client, such as <code>psql</code>. You should see the list of tables when using <code>dt;</code></p> <pre><code>psql postgresql://postgres:mysecretpassword@&lt;SQL_IP&gt;:5432/mcpgw\n\nmcpgw=&gt; \\dt;\n                    List of relations\n Schema |             Name             | Type  |  Owner\n--------+------------------------------+-------+----------\n public | gateways                     | table | postgres\n public | mcp_messages                 | table | postgres\n public | mcp_sessions                 | table | postgres\n public | prompt_gateway_association   | table | postgres\n public | prompt_metrics               | table | postgres\n public | prompts                      | table | postgres\n public | resource_gateway_association | table | postgres\n public | resource_metrics             | table | postgres\n public | resource_subscriptions       | table | postgres\n public | resources                    | table | postgres\n public | server_metrics               | table | postgres\n public | server_prompt_association    | table | postgres\n public | server_resource_association  | table | postgres\n public | server_tool_association      | table | postgres\n public | servers                      | table | postgres\n public | tool_gateway_association     | table | postgres\n public | tool_metrics                 | table | postgres\n public | tools                        | table | postgres\n(18 rows)\n</code></pre>"},{"location":"deployment/google-cloud-run/#authentication-and-access","title":"\ud83d\udd12 Authentication and Access","text":""},{"location":"deployment/google-cloud-run/#generate-a-jwt-bearer-token","title":"Generate a JWT Bearer Token","text":"<p>Use the MCP Gateway container to generate a JWT token:</p> <pre><code>docker run -it --rm ghcr.io/ibm/mcp-context-forge:latest \\\n  python3 -m mcpgateway.utils.create_jwt_token -u admin --secret jwt-secret-key\n</code></pre> <p>Export the token as an environment variable:</p> <pre><code>export MCPGATEWAY_BEARER_TOKEN=&lt;paste-token-here&gt;\n</code></pre>"},{"location":"deployment/google-cloud-run/#perform-smoke-tests","title":"Perform Smoke Tests","text":"<p>Test the <code>/health</code>, <code>/version</code>, and <code>/tools</code> endpoints:</p> <pre><code># Check that the service is healthy\ncurl -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     https://&lt;your-cloud-run-url&gt;/health\n\n# Check that version reports the version and show Postgres/Redis as connected\ncurl -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     https://&lt;your-cloud-run-url&gt;/health\n\n# Check that tools return an empty list []\ncurl -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     https://&lt;your-cloud-run-url&gt;/tools\n</code></pre> <p>Replace <code>&lt;your-cloud-run-url&gt;</code> with the URL provided after deploying the service.</p>"},{"location":"deployment/google-cloud-run/#logs-and-monitoring","title":"\ud83d\udcca Logs and Monitoring","text":""},{"location":"deployment/google-cloud-run/#view-logs-via-cli","title":"View Logs via CLI","text":"<p>Tailing real-time logs requires <code>google-cloud-cli-log-streaming</code>. Ex: <code>sudo apt-get install google-cloud-cli-log-streaming</code>:</p> <pre><code>gcloud beta run services logs tail mcpgateway --region=us-central1\n</code></pre>"},{"location":"deployment/google-cloud-run/#access-logs-via-console","title":"Access Logs via Console","text":"<p>Navigate to the Cloud Run Console and select your service to view logs and metrics.</p>"},{"location":"deployment/google-cloud-run/#github-actions-deployment-optional","title":"\ud83d\udce6 GitHub Actions Deployment (Optional)","text":"<p>Automate builds and deployments using GitHub Actions. Refer to the workflow file:</p> <pre><code>.github/workflows/google-cloud-run.yml\n</code></pre> <p>This workflow:</p> <ul> <li>Restores and updates a local BuildKit layer cache.</li> <li>Builds the Docker image from <code>Containerfile.lite</code>.</li> <li>Pushes the image to Google Artifact Registry.</li> <li>Deploys to Google Cloud Run with <code>--max-instances=1</code>.</li> </ul>"},{"location":"deployment/google-cloud-run/#notes-and-tips","title":"\ud83d\udcd8 Notes and Tips","text":"<ul> <li> <p>HTTPS by Default: Cloud Run services are accessible over HTTPS without additional configuration.</p> </li> <li> <p>Custom Domains: You can map custom domains via the Cloud Run settings.</p> </li> <li> <p>Secret Management: Consider using Secret Manager for managing sensitive environment variables.</p> </li> <li> <p>Cold Starts: To reduce cold start latency, set a minimum number of instances:</p> </li> </ul> <pre><code>--min-instances=1\n</code></pre> <ul> <li>Monitoring: Utilize Cloud Monitoring for detailed metrics and alerts.</li> </ul>"},{"location":"deployment/google-cloud-run/#feature-summary","title":"\ud83e\udde9 Feature Summary","text":"Feature Supported HTTPS (built-in) \u2705 Custom domains \u2705 PostgreSQL (Cloud SQL) \u2705 Redis (Memorystore) \u2705 Auto-scaling \u2705 Scale-to-zero \u2705 Max instance limit \u2705"},{"location":"deployment/google-cloud-run/#additional-resources","title":"\ud83e\udde0 Additional Resources","text":"<ul> <li>Cloud Run Documentation</li> <li>Cloud SQL for PostgreSQL Documentation</li> <li>Memorystore for Redis Documentation</li> <li>Google Cloud SDK Installation Guide</li> <li>Cloud Run Pricing</li> <li>Cloud SQL Pricing</li> <li>Memorystore Pricing</li> </ul> <p>By following this guide, you can deploy MCP Gateway on Google Cloud Run using the most cost-effective configurations, ensuring efficient resource utilization and seamless scalability.</p>"},{"location":"deployment/ibm-code-engine/","title":"\u2699\ufe0f IBM Code Engine","text":"<p>This guide covers two supported deployment paths for the MCP Gateway:</p> <ol> <li>Makefile automation \u2013 a single-command workflow that wraps <code>ibmcloud</code> CLI.</li> <li>Manual IBM Cloud CLI \u2013 the raw commands the Makefile executes, for fine-grained control.</li> </ol>"},{"location":"deployment/ibm-code-engine/#1-prerequisites","title":"1 \u00b7 Prerequisites","text":"Requirement Details IBM Cloud account Create one if needed Docker or Podman Builds the production container image locally IBM Cloud CLI \u2265 2.16 Installed automatically with <code>make ibmcloud-cli-install</code> Code Engine project Create or select one in the IBM Cloud console <code>.env</code> file Runtime secrets &amp; config for the gateway <code>.env.ce</code> file Deployment credentials &amp; metadata for Code Engine / Container Reg."},{"location":"deployment/ibm-code-engine/#2-environment-files","title":"2 \u00b7 Environment files","text":"<p>Both files are already in <code>.gitignore</code>. Template named <code>.env.example</code> <code>.env.ce.example</code> and are included; copy them:</p> <pre><code>cp .env.example .env         # runtime settings (inside the container)\ncp .env.ce.example .env.ce   # deployment credentials (CLI only)\n</code></pre>"},{"location":"deployment/ibm-code-engine/#env-runtime-settings","title":"<code>.env</code> \u2013 runtime settings","text":"<p>This file is mounted into the container (via <code>--env-file=.env</code>), so its keys live inside Code Engine at runtime. Treat it as an application secret store.</p> <pre><code># \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n#  Core gateway settings\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nAUTH_REQUIRED=true\n# Generate once:  openssl rand -hex 32\nJWT_SECRET_KEY=eef5e9f70ca7fe6f9677ad2acaf4d32c55e9d98e9cb74299b33f5c5d1a3c8ef\n\nHOST=0.0.0.0\nPORT=4444\n\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n#  Database configuration  \u2013 choose ONE block\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n## (A) Local SQLite  (good for smoke-tests / CI only)\n## --------------------------------------------------\n## \u2022 SQLite lives on the container's ephemeral file system.\n## \u2022 On Code Engine every new instance starts fresh; scale-out, restarts or\n##   deploys will wipe data.  **Not suitable for production.**\n## \u2022 If you still need file persistence, attach Code Engine's file-system\n##   mount or an external filesystem / COS bucket.\n#CACHE_TYPE=database\n#DATABASE_URL=sqlite:////tmp/mcp.db\n\n\n## (B) Managed PostgreSQL on IBM Cloud  (recommended for staging/production)\n## --------------------------------------------------------------------------\n## \u2022 Provision an IBM Cloud Databases for PostgreSQL instance (see below).\n## \u2022 Use the service credentials to build the URL.\n## \u2022 sslmode=require is mandatory for IBM Cloud databases.\nCACHE_TYPE=database\nDATABASE_URL=postgresql://pguser:pgpass@my-pg-host.databases.appdomain.cloud:32727/mcpgwdb?sslmode=require\n#            \u2502 \u2502      \u2502                                   \u2502           \u2502\n#            \u2502 \u2502      \u2502                                   \u2502           \u2514\u2500 database name\n#            \u2502 \u2502      \u2502                                   \u2514\u2500 hostname:port\n#            \u2502 \u2502      \u2514\u2500 password\n#            \u2502 \u2514\u2500 username\n#            \u2514\u2500 scheme\n</code></pre> <p>The <code>JWT_SECRET_KEY</code> variable is used to generate a Bearer token used to access the APIs. To access the APIs you need to generate your JWT token using the same <code>JWT_SECRET_KEY</code>, for example:</p> <pre><code># Generate a one-off token for the default admin user\nexport MCPGATEWAY_BEARER_TOKEN=$(python -m mcpgateway.utils.create_jwt_token -u admin)\necho ${MCPGATEWAY_BEARER_TOKEN} # Check that the key was generated\n</code></pre>"},{"location":"deployment/ibm-code-engine/#envce-code-engine-deployment-settings","title":"<code>.env.ce</code> \u2013 Code Engine deployment settings","text":"<p>These keys are only consumed by Makefile / CLI. They never reach the running container.</p> <pre><code># \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n#  IBM Cloud / Code Engine deployment variables\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nIBMCLOUD_REGION=us-south\nIBMCLOUD_RESOURCE_GROUP=default\nIBMCLOUD_PROJECT=my-codeengine-project\nIBMCLOUD_CODE_ENGINE_APP=mcpgateway\n\n# Image details\nIBMCLOUD_IMAGE_NAME=us.icr.io/myspace/mcpgateway:latest  # target in IBM Container Registry\nIBMCLOUD_IMG_PROD=mcpgateway/mcpgateway                  # local tag produced by Make\n\n# Authentication\nIBMCLOUD_API_KEY=***your-api-key***    # leave blank to use SSO flow at login\n\n# Resource combo \u2013 see https://cloud.ibm.com/docs/codeengine?topic=codeengine-mem-cpu-combo\nIBMCLOUD_CPU=1                         # vCPU for the container\nIBMCLOUD_MEMORY=4G                     # Memory (must match a valid CPU/MEM pair)\n\n# Registry secret in Code Engine (first-time creation is automated)\nIBMCLOUD_REGISTRY_SECRET=my-regcred\n</code></pre> <p>Tip: run <code>make ibmcloud-check-env</code> to verify every required <code>IBMCLOUD_*</code> key is present in <code>.env.ce</code>.</p>"},{"location":"deployment/ibm-code-engine/#3-workflow-a-makefile-targets","title":"3 \u00b7 Workflow A \u2013 Makefile targets","text":"Target Action it performs <code>podman</code> / <code>docker</code> Build the production image (<code>$IBMCLOUD_IMG_PROD</code>). <code>ibmcloud-cli-install</code> Install IBM Cloud CLI + container-registry and code-engine plugins. <code>ibmcloud-check-env</code> Ensure all <code>IBMCLOUD_*</code> vars exist in <code>.env.ce</code>; abort if any are missing. <code>ibmcloud-login</code> <code>ibmcloud login</code> \u2013 uses API key or interactive SSO. <code>ibmcloud-ce-login</code> <code>ibmcloud ce project select --name $IBMCLOUD_PROJECT</code>. <code>ibmcloud-list-containers</code> Show ICR images and existing Code Engine apps. <code>ibmcloud-tag</code> <code>podman tag $IBMCLOUD_IMG_PROD $IBMCLOUD_IMAGE_NAME</code>. <code>ibmcloud-push</code> <code>ibmcloud cr login</code> + <code>podman push</code> to ICR. <code>ibmcloud-deploy</code> Create or update the app, set CPU/MEM, attach registry secret, expose port 4444. <code>ibmcloud-ce-status</code> <code>ibmcloud ce application get</code> \u2013 see route URL, revisions, health. <code>ibmcloud-ce-logs</code> <code>ibmcloud ce application logs --follow</code> \u2013 live log stream. <code>ibmcloud-ce-rm</code> Delete the application entirely. <p>Typical first deploy</p> <pre><code>make ibmcloud-check-env\nmake ibmcloud-cli-install\nmake ibmcloud-login\nmake ibmcloud-ce-login\nmake podman            # or: make docker\nmake ibmcloud-tag\nmake ibmcloud-push\nmake ibmcloud-deploy\n</code></pre> <p>Redeploy after code changes</p> <pre><code>make podman ibmcloud-tag ibmcloud-push ibmcloud-deploy\n</code></pre>"},{"location":"deployment/ibm-code-engine/#4-workflow-b-manual-ibm-cloud-cli","title":"4 \u00b7 Workflow B \u2013 Manual IBM Cloud CLI","text":"<pre><code># 1 \u00b7 Install CLI + plugins\ncurl -fsSL https://clis.cloud.ibm.com/install/linux | sh\nibmcloud plugin install container-registry -f\nibmcloud plugin install code-engine      -f\n\n# 2 \u00b7 Login\nibmcloud login --apikey \"$IBMCLOUD_API_KEY\" -r \"$IBMCLOUD_REGION\" -g \"$IBMCLOUD_RESOURCE_GROUP\"\nibmcloud resource groups # list resource groups\n\n# 3 \u00b7 Target Code Engine project\nibmcloud ce project list # list current projects\nibmcloud ce project select --name \"$IBMCLOUD_PROJECT\"\n\n# 4 \u00b7 Build + tag image\npodman build -t \"$IBMCLOUD_IMG_PROD\" .\npodman tag \"$IBMCLOUD_IMG_PROD\" \"$IBMCLOUD_IMAGE_NAME\"\n\n# 5 \u00b7 Push image to ICR\nibmcloud cr login\nibmcloud cr namespaces       # Ensure your namespace exists\npodman push \"$IBMCLOUD_IMAGE_NAME\"\nibmcloud cr images # list images\n\n# 6 \u00b7 Create registry secret (first time)\nibmcloud ce registry create-secret --name \"$IBMCLOUD_REGISTRY_SECRET\" \\\n    --server \"$(echo \"$IBMCLOUD_IMAGE_NAME\" | cut -d/ -f1)\" \\\n    --username iamapikey --password \"$IBMCLOUD_API_KEY\"\nibmcloud ce secret list # list every secret (generic, registry, SSH, TLS, etc.)\nibmcloud ce secret get --name \"$IBMCLOUD_REGISTRY_SECRET\"         # add --decode to see clear-text values\n\n# 7 \u00b7 Deploy / update\nif ibmcloud ce application get --name \"$IBMCLOUD_CODE_ENGINE_APP\" &gt;/dev/null 2&gt;&amp;1; then\n  ibmcloud ce application update --name \"$IBMCLOUD_CODE_ENGINE_APP\" \\\n      --image \"$IBMCLOUD_IMAGE_NAME\" \\\n      --cpu \"$IBMCLOUD_CPU\" --memory \"$IBMCLOUD_MEMORY\" \\\n      --registry-secret \"$IBMCLOUD_REGISTRY_SECRET\"\nelse\n  ibmcloud ce application create --name \"$IBMCLOUD_CODE_ENGINE_APP\" \\\n      --image \"$IBMCLOUD_IMAGE_NAME\" \\\n      --cpu \"$IBMCLOUD_CPU\" --memory \"$IBMCLOUD_MEMORY\" \\\n      --port 4444 \\\n      --registry-secret \"$IBMCLOUD_REGISTRY_SECRET\"\nfi\n\n# 8 \u00b7 Status &amp; logs\nibmcloud ce application get --name \"$IBMCLOUD_CODE_ENGINE_APP\"\nibmcloud ce application events --name \"$IBMCLOUD_CODE_ENGINE_APP\"\nibmcloud ce application get   --name \"$IBMCLOUD_CODE_ENGINE_APP\"\nibmcloud ce application logs  --name \"$IBMCLOUD_CODE_ENGINE_APP\" --follow\n</code></pre>"},{"location":"deployment/ibm-code-engine/#5-accessing-the-gateway","title":"5 \u00b7 Accessing the gateway","text":"<pre><code>ibmcloud ce application get --name \"$IBMCLOUD_CODE_ENGINE_APP\" --output url\n</code></pre> <p>Open the returned URL (e.g. <code>https://mcpgateway.us-south.codeengine.appdomain.cloud/admin</code>) and log in with the basic-auth credentials from <code>.env</code>.</p> <p>Test the API endpoints with the generated <code>MCPGATEWAY_BEARER_TOKEN</code>:</p> <pre><code># Generate a one-off token for the default admin user\nexport MCPGATEWAY_BEARER_TOKEN=$(python -m mcpgateway.utils.create_jwt_token -u admin)\n\n# Call a protected endpoint. Since there are not tools, initially this just returns `[]`\ncurl -H \"Authorization: Bearer ${MCPGATEWAY_BEARER_TOKEN}\" \\\n     https://mcpgateway.us-south.codeengine.appdomain.cloud/tools\n\n# Check the logs\nmake ibmcloud-ce-logs\n</code></pre>"},{"location":"deployment/ibm-code-engine/#6-cleanup","title":"6 \u00b7 Cleanup","text":"<pre><code># via Makefile\nmake ibmcloud-ce-rm\n\n# or directly\nibmcloud ce application delete --name \"$IBMCLOUD_CODE_ENGINE_APP\" -f\n</code></pre>"},{"location":"deployment/ibm-code-engine/#7-using-ibm-cloud-databases-for-postgresql","title":"7 \u00b7 Using IBM Cloud Databases for PostgreSQL","text":"<p>Need durable data, high availability, and automated backups? Provision IBM Cloud Databases for PostgreSQL and connect MCP Gateway to it.</p> <pre><code>###############################################################################\n# 1 \u00b7 Provision PostgreSQL\n###############################################################################\n# Choose a plan:  standard (shared) or enterprise (dedicated). For small\n# workloads start with: standard / 1 member / 4 GB RAM.\nibmcloud resource service-instance-create mcpgw-db \\\n    databases-for-postgresql standard $IBMCLOUD_REGION\n\n###############################################################################\n# 2 \u00b7 Create service credentials\n###############################################################################\nibmcloud resource service-key-create mcpgw-db-creds Administrator \\\n    --instance-name mcpgw-db\n\n###############################################################################\n# 3 \u00b7 Retrieve credentials &amp; craft DATABASE_URL\n###############################################################################\ncreds_json=$(ibmcloud resource service-key mcpgw-db-creds --output json)\nhost=$(echo \"$creds_json\" | jq -r '.[0].credentials.connection.postgres.hosts[0].hostname')\nport=$(echo \"$creds_json\" | jq -r '.[0].credentials.connection.postgres.hosts[0].port')\nuser=$(echo \"$creds_json\" | jq -r '.[0].credentials.connection.postgres.authentication.username')\npass=$(echo \"$creds_json\" | jq -r '.[0].credentials.connection.postgres.authentication.password')\ndb=$(echo \"$creds_json\"   | jq -r '.[0].credentials.connection.postgres.database')\n\nDATABASE_URL=\"postgresql://${user}:${pass}@${host}:${port}/${db}?sslmode=require\"\n\n###############################################################################\n# 4 \u00b7 Store DATABASE_URL as a Code Engine secret\n###############################################################################\nibmcloud ce secret create --name mcpgw-db-url \\\n    --from-literal DATABASE_URL=\"$DATABASE_URL\"\n\n###############################################################################\n# 5 \u00b7 Mount the secret into the application\n###############################################################################\nibmcloud ce application update --name \"$IBMCLOUD_CODE_ENGINE_APP\" \\\n    --env-from-secret mcpgw-db-url\n</code></pre>"},{"location":"deployment/ibm-code-engine/#choosing-the-right-postgresql-size","title":"Choosing the right PostgreSQL size","text":"Workload profile Suggested plan Members \u00d7 RAM Notes Dev / PoC <code>standard</code> 1 \u00d7 4 GB Cheapest; no HA; easy to scale later Prod small <code>standard</code> 2 \u00d7 8 GB Two members enable HA &amp; automatic fail-over Prod heavy <code>enterprise</code> 3 \u00d7 16 GB Dedicated bare-metal; highest performance &amp; isolation <p>Scale up at any time with:</p> <pre><code>ibmcloud cdb deployment-scaling-set mcpgw-db \\\n    --members 3 --memory-gb 16\n\n# Update the number of maximum connections:\nibmcloud cdb deployment-configuration YOUR_DB_CRN '{\"configuration\":{\"max_connections\":215}}'\n\n# show max_connections;\n</code></pre> <p>The gateway will reconnect transparently because the host name remains stable. See the documentation for more details.</p>"},{"location":"deployment/ibm-code-engine/#local-sqlite-vs-managed-postgresql","title":"Local SQLite vs. Managed PostgreSQL","text":"Aspect Local SQLite (<code>sqlite:////tmp/mcp.db</code>) Managed PostgreSQL Persistence None \u2013 lost on restarts / scale-out Durable &amp; backed-up Concurrency Single-writer lock Multiple writers Scale-out ready No - state is per-pod Yes Best for Unit tests, CI pipelines Staging &amp; production <p>For production workloads you must switch to a managed database or mount a persistent file system.</p>"},{"location":"deployment/ibm-code-engine/#8-adding-ibm-cloud-databases-for-redis-optional-cache-layer","title":"8 \u00b7 Adding IBM Cloud Databases for Redis (optional cache layer)","text":"<p>Need a high-performance shared cache? Provision IBM Cloud Databases for Redis and point MCP Gateway at it.</p> <pre><code>###############################################################################\n# 1 \u00b7 Provision Redis\n###############################################################################\n# Choose a plan: standard (shared) or enterprise (dedicated).\nibmcloud resource service-instance-create mcpgw-redis \\\n    databases-for-redis standard $IBMCLOUD_REGION\n\n###############################################################################\n# 2 \u00b7 Create service credentials\n###############################################################################\nibmcloud resource service-key-create mcpgw-redis-creds Administrator \\\n    --instance-name mcpgw-redis\n\n###############################################################################\n# 3 \u00b7 Retrieve credentials &amp; craft REDIS_URL\n###############################################################################\ncreds_json=$(ibmcloud resource service-key mcpgw-redis-creds --output json)\nhost=$(echo \"$creds_json\" | jq -r '.[0].credentials.connection.rediss.hosts[0].hostname')\nport=$(echo \"$creds_json\" | jq -r '.[0].credentials.connection.rediss.hosts[0].port')\npass=$(echo \"$creds_json\" | jq -r '.[0].credentials.connection.rediss.authentication.password')\n\nREDIS_URL=\"rediss://:${pass}@${host}:${port}/0\"   # rediss = TLS-secured Redis\n\n###############################################################################\n# 4 \u00b7 Store REDIS_URL as a Code Engine secret\n###############################################################################\nibmcloud ce secret create --name mcpgw-redis-url \\\n    --from-literal REDIS_URL=\"$REDIS_URL\"\n\n###############################################################################\n# 5 \u00b7 Mount the secret and switch cache backend\n###############################################################################\nibmcloud ce application update --name \"$IBMCLOUD_CODE_ENGINE_APP\" \\\n    --env-from-secret mcpgw-redis-url \\\n    --env CACHE_TYPE=redis\n</code></pre>"},{"location":"deployment/ibm-code-engine/#choosing-the-right-redis-size","title":"Choosing the right Redis size","text":"Use-case Plan Memory Notes Dev / CI <code>standard</code> 256 MB Minimum footprint, single member Small production <code>standard</code> 1 GB Two-member HA cluster High-throughput <code>enterprise</code> \u22654 GB Dedicated nodes, persistence, AOF <p>Scale later with:</p> <pre><code>ibmcloud cdb deployment-scaling-set mcpgw-redis --memory-gb 4\n</code></pre> <p>Once redeployed, the gateway will use Redis for request-level caching, reducing latency and database load.</p>"},{"location":"deployment/ibm-code-engine/#9-gunicorn-configuration-optional-tuning","title":"9. Gunicorn configuration (optional tuning)","text":"<p>The container starts <code>gunicorn</code> with the settings defined in <code>gunicorn.conf.py</code> found at the project root. If you need to change worker counts, ports, or time-outs, edit this file before you build the image (<code>make podman</code> or <code>make docker</code>). The settings are baked into the container at build time.</p> <pre><code># -*- coding: utf-8 -*-\n\"\"\"\nGunicorn configuration\nDocs: https://docs.gunicorn.org/en/stable/settings.html\n\"\"\"\n\n# Network interface / port \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nbind = \"0.0.0.0:4444\"        # Listen on all interfaces, port 4444\n\n# Worker processes \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nworkers = 8                  # Rule of thumb: 2\u20134 \u00d7 NUM_CPU_CORES\n\n# Request/worker life-cycle \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ntimeout = 600                # Kill a worker after 600 s of no response\nmax_requests = 10000         # Restart worker after N requests\nmax_requests_jitter = 100    # Add randomness to avoid synchronized restarts\n\n# Logging &amp; verbosity \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nloglevel = \"info\"            # \"debug\", \"info\", \"warning\", \"error\", \"critical\"\n\n# Optimisations \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\npreload_app = True           # Load app code once in parent, fork workers (saves RAM)\nreuse_port  = True           # SO_REUSEPORT for quicker restarts\n\n# Alternative worker models (uncomment ONE and install extras) ----------\n# worker_class = \"gevent\"     # pip install \"gunicorn[gevent]\"\n# worker_class = \"eventlet\"   # pip install \"gunicorn[eventlet]\"\n# worker_class = \"tornado\"    # pip install \"gunicorn[tornado]\"\n# threads = 2                 # If using the 'sync' worker with threads\n\n# TLS certificates (if you terminate HTTPS inside the container)\n# certfile = 'certs/cert.pem'\n# keyfile  = 'certs/key.pem'\n\n# Server hooks (logging examples) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef when_ready(server):\n    server.log.info(\"Server is ready. Spawning workers\")\n\ndef post_fork(server, worker):\n    server.log.info(\"Worker spawned (pid: %s)\", worker.pid)\n\ndef worker_exit(server, worker):\n    server.log.info(\"Worker exit (pid: %s)\", worker.pid)\n</code></pre> <p>Typical tweaks</p> Scenario Setting(s) to adjust High-latency model calls \u2192 time-outs <code>timeout</code> (e.g. 1200 s) CPU-bound workload on 4-core instance <code>workers = 8</code> \u2192 <code>workers = 16</code> Memory-limited instance Reduce <code>workers</code> or disable <code>preload_app</code> Websocket / async traffic Switch <code>worker_class</code> to <code>gevent</code> or <code>eventlet</code> <p>After changing the file, rebuild and redeploy:</p> <pre><code>make podman ibmcloud-tag ibmcloud-push ibmcloud-deploy\n</code></pre>"},{"location":"deployment/kubernetes/","title":"\u2638\ufe0f Kubernetes / OpenShift Deployment","text":"<p>You can deploy MCP Gateway to any K8s-compliant platform \u2014 including vanilla Kubernetes, OpenShift, and managed clouds like GKE, AKS, and EKS.</p>"},{"location":"deployment/kubernetes/#quick-start-with-manifest-yaml","title":"\ud83d\ude80 Quick Start with Manifest (YAML)","text":"<p>A basic Kubernetes deployment might look like:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mcpgateway\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mcpgateway\n  template:\n    metadata:\n      labels:\n        app: mcpgateway\n    spec:\n      containers:\n        - name: gateway\n          image: ghcr.io/YOUR_ORG/mcpgateway:latest\n          ports:\n            - containerPort: 4444\n          envFrom:\n            - configMapRef:\n                name: mcpgateway-env\n          volumeMounts:\n            - mountPath: /app/.env\n              name: env-volume\n              subPath: .env\n      volumes:\n        - name: env-volume\n          configMap:\n            name: mcpgateway-env\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: mcpgateway\nspec:\n  selector:\n    app: mcpgateway\n  ports:\n    - port: 80\n      targetPort: 4444\n</code></pre> <p>Replace <code>ghcr.io/YOUR_ORG/mcpgateway</code> with your built image.</p>"},{"location":"deployment/kubernetes/#tls-ingress","title":"\ud83d\udd10 TLS &amp; Ingress","text":"<p>You can add:</p> <ul> <li>Cert-manager with TLS secrets</li> <li>An Ingress resource that routes to <code>/admin</code>, <code>/tools</code>, etc.</li> </ul> <p>Example Ingress snippet:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: mcpgateway\n  annotations:\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\nspec:\n  rules:\n    - host: gateway.example.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: mcpgateway\n                port:\n                  number: 80\n  tls:\n    - hosts:\n        - gateway.example.com\n      secretName: mcpgateway-tls\n</code></pre>"},{"location":"deployment/kubernetes/#configuration-via-configmap","title":"\ud83d\udce6 Configuration via ConfigMap","text":"<p>You can load your <code>.env</code> as a ConfigMap:</p> <pre><code>kubectl create configmap mcpgateway-env --from-env-file=.env\n</code></pre> <p>Make sure it includes <code>JWT_SECRET_KEY</code>, <code>AUTH_REQUIRED</code>, etc.</p>"},{"location":"deployment/kubernetes/#openshift-considerations","title":"\ud83d\udca1 OpenShift Considerations","text":"<ul> <li>Use <code>Route</code> instead of Ingress</li> <li>You may need to run the container as an unprivileged user</li> <li>Set <code>SECURITY_CONTEXT_RUNASUSER</code> if needed</li> </ul>"},{"location":"deployment/kubernetes/#health-check-probes","title":"\ud83e\uddea Health Check Probes","text":"<pre><code>livenessProbe:\n  httpGet:\n    path: /health\n    port: 4444\n  initialDelaySeconds: 10\n  periodSeconds: 15\n</code></pre>"},{"location":"deployment/local/","title":"\ud83d\udc0d Local Deployment","text":"<p>This guide walks you through running MCP Gateway on your local machine using a virtual environment or directly via Python.</p>"},{"location":"deployment/local/#one-liner-setup","title":"\ud83d\ude80 One-Liner Setup","text":"<p>The easiest way to start the server in development mode:</p> <pre><code>make venv install serve\n</code></pre> <p>This does the following:</p> <ol> <li>Creates a <code>.venv/</code> virtual environment</li> <li>Installs all dependencies (including dev tools)</li> <li>Launches Gunicorn on <code>http://localhost:4444</code></li> </ol>"},{"location":"deployment/local/#development-mode-with-live-reload","title":"\ud83e\uddea Development Mode with Live Reload","text":"<p>If you want auto-reload on code changes:</p> <pre><code>make run        # or:\n./run.sh --reload --log debug\n</code></pre> <p>Ensure your <code>.env</code> file includes:</p> <pre><code>DEV_MODE=true\nRELOAD=true\nDEBUG=true\n</code></pre>"},{"location":"deployment/local/#health-test","title":"\ud83e\uddea Health Test","text":"<pre><code>curl http://localhost:4444/health\n</code></pre> <p>Expected output:</p> <pre><code>{\"status\": \"healthy\"}\n</code></pre>"},{"location":"deployment/local/#admin-ui","title":"\ud83d\udd10 Admin UI","text":"<p>Visit http://localhost:4444/admin and login using your <code>BASIC_AUTH_USER</code> and <code>BASIC_AUTH_PASSWORD</code> from <code>.env</code>.</p>"},{"location":"deployment/local/#quick-jwt-setup","title":"\ud83d\udd01 Quick JWT Setup","text":"<pre><code>export MCPGATEWAY_BEARER_TOKEN=$(python -m mcpgateway.utils.create_jwt_token -u admin)\ncurl -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" http://localhost:4444/tools\n</code></pre>"},{"location":"deployment/minikube/","title":"\u26a1\ufe0f Minikube","text":"<ol> <li>Install Minikube and a container driver (Docker or Podman).</li> <li>Start a local cluster with enough CPU/RAM and the Ingress addon enabled.</li> <li>Load or build the <code>mcpgateway</code> image into the cluster.</li> <li>Apply the same Kubernetes manifests you use in other environments.</li> <li>Access the Gateway at http://gateway.local (or <code>127.0.0.1:80</code>) via NGINX Ingress.</li> </ol> <p>Minikube is self-contained: one command spins up the control-plane, container runtime, CNI, and a registry\u2010mirroring image loader. You can therefore replicate almost any production feature\u2014including persistent volumes and TLS\u2014entirely on your laptop.</p>"},{"location":"deployment/minikube/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"Requirement Notes CPU/RAM Minikube recommends 2 CPUs + 2 GiB at minimum. For smooth builds: 4 CPUs / 6 GiB. Disk \u226520 GiB free space. Container driver Docker 20.10+ or Podman 4.7+; Docker driver is simplest on macOS/Windows. kubectl Automatically configured by <code>minikube start</code>; or use <code>minikube kubectl -- \u2026</code> if kubectl isn't installed."},{"location":"deployment/minikube/#step-1-install-minikube","title":"\ud83d\ude80 Step 1 \u2013 Install Minikube","text":""},{"location":"deployment/minikube/#macos","title":"macOS","text":"<pre><code>brew install minikube\n</code></pre>"},{"location":"deployment/minikube/#linux","title":"Linux","text":"<pre><code>curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64\nsudo install minikube-linux-amd64 /usr/local/bin/minikube\n</code></pre>"},{"location":"deployment/minikube/#windows-powershell","title":"Windows (PowerShell)","text":"<pre><code>choco install minikube\n</code></pre> <p>A detailed Windows walkthrough (including WSL 2) is available from Ambassador Labs.</p>"},{"location":"deployment/minikube/#step-2-start-the-cluster","title":"\u2699\ufe0f Step 2 \u2013 Start the cluster","text":"<p>Make target</p> <pre><code>make minikube-start\n</code></pre> Manual command (Docker driver) <pre><code>minikube start \\\n  --driver=docker \\\n  --cpus=4 --memory=6g \\\n  --addons=ingress,ingress-dns \\\n  --profile=mcpgw\n</code></pre> <ul> <li><code>--driver=docker</code> avoids nested virtualization on macOS and Windows Home.</li> <li><code>ingress</code> addon gives you NGINX with LoadBalancer semantics on localhost.</li> <li><code>ingress-dns</code> resolves <code>*.local</code> hostnames automatically when you add Minikube's IP to your OS DNS list.</li> <li>Flags <code>--cpus</code> and <code>--memory</code> accept <code>max</code> to use everything available.</li> </ul> <p>Check everything is healthy:</p> <pre><code>minikube status\nkubectl get pods -n ingress-nginx\n</code></pre>"},{"location":"deployment/minikube/#step-3-load-the-gateway-image","title":"\ud83c\udfd7 Step 3 \u2013 Load the Gateway image","text":""},{"location":"deployment/minikube/#option-a-build-inside-the-docker-driver","title":"Option A \u2013 Build inside the Docker driver","text":"<p>The Docker engine used by Minikube is your host Docker daemon, so <code>docker build</code> automatically makes the image visible.</p> <pre><code>make docker            # or docker build -t mcpgateway:latest -f Containerfile .\n</code></pre>"},{"location":"deployment/minikube/#option-b-push-pre-built-images-into-minikube-cache","title":"Option B \u2013 Push pre-built images into Minikube cache","text":"<pre><code>minikube cache add quay.io/your_ns/mcpgateway:latest   # stores &amp; pre-loads next boot\nminikube cache reload                                  # run if you rebuilt the tag\n</code></pre>"},{"location":"deployment/minikube/#option-c-load-a-local-tarball","title":"Option C \u2013 Load a local tarball","text":"<pre><code>docker save mcpgateway:latest | \\\n  minikube image load -                                     # alt: minikube image load mcpgateway:latest\n</code></pre> <p>Stack Overflow documents both <code>image load</code> and <code>cache add</code> patterns.</p>"},{"location":"deployment/minikube/#step-4-apply-kubernetes-manifests","title":"\ud83d\udcc4 Step 4 \u2013 Apply Kubernetes manifests","text":"<p>Reuse the YAML from <code>docs/kubernetes.md</code> (Deployment + Service + Ingress). If you enable <code>ingress-dns</code>, define an Ingress host such as <code>gateway.local</code>; otherwise omit the <code>host:</code> and access via NodePort.</p> <pre><code>kubectl apply -f k8s/postgres.yaml      # or Helm chart for Postgres\nkubectl apply -f k8s/redis.yaml\nkubectl apply -f k8s/mcpgateway.yaml\nkubectl apply -f k8s/mcpgateway-ingress.yaml\n</code></pre> <p>Minikube auto-configures <code>kubectl</code> context on cluster creation; if not, run:</p> <pre><code>kubectl config use-context minikube    # or: minikube kubectl -- apply -f \u2026\n</code></pre>"},{"location":"deployment/minikube/#step-5-test-access","title":"\ud83c\udf10 Step 5 \u2013 Test access","text":"<pre><code># IP-based\nminikube service mcpgateway --url        # prints http://127.0.0.1:xxxx\ncurl $(minikube service mcpgateway --url)/health\n\n# Ingress DNS (after editing system DNS =&gt; minikube ip)\ncurl http://gateway.local/health\n</code></pre>"},{"location":"deployment/minikube/#cleaning-up","title":"\ud83e\uddf9 Cleaning up","text":"Action Make Manual Pause cluster <code>make minikube-stop</code> <code>minikube stop -p mcpgw</code> Delete cluster <code>make minikube-delete</code> <code>minikube delete -p mcpgw</code> Remove cached images \u2014 <code>minikube cache delete mcpgateway:latest</code>"},{"location":"deployment/minikube/#non-make-cheatsheet","title":"\ud83d\udee0 Non-Make cheatsheet","text":"Task Command Start with Podman driver <code>minikube start --driver=podman --network-plugin=cni</code> View dashboard <code>minikube dashboard</code> SSH into node <code>minikube ssh</code> Enable metrics-server <code>minikube addons enable metrics-server</code> Upgrade Minikube <code>minikube delete &amp;&amp; brew upgrade minikube</code>"},{"location":"deployment/minikube/#further-reading","title":"\ud83d\udcda Further reading","text":"<ol> <li> <p>Minikube Quick Start guide (official)    https://minikube.sigs.k8s.io/docs/start/</p> </li> <li> <p>Minikube Docker driver docs    https://minikube.sigs.k8s.io/docs/drivers/docker/</p> </li> <li> <p>Enable NGINX Ingress in Minikube    https://kubernetes.io/docs/tasks/access-application-cluster/ingress-minikube/</p> </li> <li> <p>Load / cache images inside Minikube    https://minikube.sigs.k8s.io/docs/handbook/pushing/</p> </li> <li> <p>Using Minikube's built-in kubectl    https://minikube.sigs.k8s.io/docs/handbook/kubectl/</p> </li> <li> <p>Allocate max CPU/RAM flags    https://minikube.sigs.k8s.io/docs/faq/#how-can-i-allocate-maximum-resources-to-minikube</p> </li> <li> <p>Ingress-DNS addon overview    https://minikube.sigs.k8s.io/docs/handbook/addons/ingress-dns/</p> </li> <li> <p>Stack Overflow: loading local images into Minikube    https://stackoverflow.com/questions/42564058/how-can-i-use-local-docker-images-with-minikube</p> </li> </ol> <p>Minikube gives you the fastest, vendor-neutral sandbox for experimenting with MCP Gateway\u2014and everything above doubles as CI instructions for self-hosted GitHub runners or ephemeral integration tests.</p>"},{"location":"deployment/openshift/","title":"\u2728 Red Hat OpenShift","text":"<p>OpenShift (both OKD and Red Hat OpenShift Container Platform) adds opinionated security (SCC), integrated routing, and optional build pipelines on top of Kubernetes.  Deploying MCP Gateway therefore means (1) building or pulling a compatible image, (2) wiring database + cache back-ends, (3) obeying the default restricted-v2 SCC, and (4) exposing the service through a Route instead of an Ingress.  This guide walks through each step, offers ready-made YAML snippets, and explains the differences from the vanilla Kubernetes.</p>"},{"location":"deployment/openshift/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"<ul> <li><code>oc</code> CLI \u2014 log in as a developer to a project/namespace you can create objects in.</li> <li>A storage class for PVCs (or local PVs) to back the Postgres template.</li> <li>Either Podman or Docker on your workstation if you build locally.</li> <li>Access to an image registry that your cluster can pull from (e.g. <code>quay.io</code>).</li> </ul>"},{"location":"deployment/openshift/#build-push-images","title":"\ud83d\udee0\ufe0f Build &amp; push images","text":""},{"location":"deployment/openshift/#option-a-use-make","title":"Option A \u2014 Use Make","text":"Target Builds Dockerfile Notes <code>make podman</code> <code>mcpgateway-dev:latest</code> Containerfile Rootless Podman build <code>make podman-prod</code> <code>mcpgateway:latest</code> Containerfile.lite UBI 9-micro, multi-stage <code>make docker</code> <code>mcpgateway-dev:latest</code> Containerfile Docker Desktop <code>make docker-prod</code> <code>mcpgateway:latest</code> Containerfile.lite Same slim image <p>Push afterwards, for example:</p> <pre><code>podman tag mcpgateway:latest quay.io/YOUR_NS/mcpgateway:latest\npodman push quay.io/YOUR_NS/mcpgateway:latest\n</code></pre> <p>Apple-silicon note \u2013 <code>Containerfile.lite</code> uses <code>ubi9-micro</code> (x86_64). Buildx/QEMU works, but the image will run under emulation on macOS. If you need native arm64 choose the dev image or add <code>--platform linux/arm64</code>.</p>"},{"location":"deployment/openshift/#option-b-raw-cli-equivalents","title":"Option B \u2014 Raw CLI equivalents","text":"<pre><code># Dev (Containerfile)\npodman build -t mcpgateway-dev:latest -f Containerfile .\n\n# Prod (UBI micro, AMD64, squashed layers)\ndocker build --platform=linux/amd64 --squash \\\n  -t mcpgateway:latest -f Containerfile.lite .\n</code></pre>"},{"location":"deployment/openshift/#secrets-configmaps","title":"\ud83d\udd11 Secrets &amp; ConfigMaps","text":"<p>Create a ConfigMap from your <code>.env</code> file:</p> <pre><code>oc create configmap mcpgateway-env --from-env-file=.env   # Populates envFrom\n</code></pre> <p>OpenShift lets you inject all keys via <code>envFrom:</code> in the pod template.</p> <p>If you keep sensitive values (e.g. <code>JWT_SECRET_KEY</code>) separate, store them in a Secret and reference both resources under <code>envFrom:</code>.</p>"},{"location":"deployment/openshift/#postgresql-redis-back-ends","title":"\ud83d\uddc4 PostgreSQL &amp; Redis back-ends","text":""},{"location":"deployment/openshift/#postgresql-persistent-template","title":"PostgreSQL (persistent template)","text":"<pre><code>oc new-app -f https://raw.githubusercontent.com/openshift/origin/master/examples/db-templates/postgresql-persistent-template.json \\\n  -p POSTGRESQL_USER=postgres,POSTGRESQL_PASSWORD=secret,POSTGRESQL_DATABASE=mcp\n</code></pre> <p>The template creates a DeploymentConfig, Service and a 1 Gi PVC bound to the cluster's default storage class.</p>"},{"location":"deployment/openshift/#redis","title":"Redis","text":"<p>On OpenShift 4.x use the Redis Enterprise Operator from OperatorHub (UI or CLI) then create a RedisEnterpriseCluster CR; it provisions StatefulSets plus PVCs out-of-the-box.</p>"},{"location":"deployment/openshift/#deployment-service-gateway","title":"\ud83d\udce6 Deployment &amp; Service (gateway)","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mcpgateway\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mcpgateway\n  template:\n    metadata:\n      labels:\n        app: mcpgateway\n    spec:\n      securityContext:            # Must satisfy restricted-v2 SCC\n        runAsNonRoot: true\n      containers:\n      - name: gateway\n        image: quay.io/YOUR_NS/mcpgateway:latest\n        ports:\n        - containerPort: 4444\n        envFrom:\n        - configMapRef:\n            name: mcpgateway-env\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 4444\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 4444\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        securityContext:\n          allowPrivilegeEscalation: false\n          runAsUser: 1001        # UBI non-root UID works with restricted SCC\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: mcpgateway\nspec:\n  selector:\n    app: mcpgateway\n  ports:\n  - port: 80\n    targetPort: 4444\n</code></pre> <p>The readiness/liveness probes follow OpenShift's health-check guidance.</p>"},{"location":"deployment/openshift/#route-public-url","title":"\ud83c\udf0d Route (public URL)","text":"<pre><code>apiVersion: route.openshift.io/v1\nkind: Route\nmetadata:\n  name: mcpgateway\nspec:\n  to:\n    kind: Service\n    name: mcpgateway\n  port:\n    targetPort: 80\n  tls:\n    termination: edge\n</code></pre> <p>Routes are OpenShift's native form of ingress; the router automatically provisions a hostname such as <code>mcpgateway-myproj.apps.cluster.example.com</code>.</p>"},{"location":"deployment/openshift/#putting-it-together","title":"\ud83d\udcd1 Putting it together","text":"<pre><code># Apply manifests\noc apply -f postgres-template.yaml        # or Operator YAML\noc apply -f redis-operator.yaml           # if using Redis Operator\noc apply -f mcpgateway-deployment.yaml\noc apply -f mcpgateway-route.yaml\n</code></pre> <p>Verify:</p> <pre><code>oc get pods\noc get route mcpgateway -o jsonpath='{.spec.host}{\"\\n\"}'\ncurl https://$(oc get route mcpgateway -o jsonpath='{.spec.host}')/health\n</code></pre>"},{"location":"deployment/openshift/#openshift-buildconfig-optional","title":"\ud83d\udd04 OpenShift BuildConfig (optional)","text":"<p>If you prefer in-cluster builds, create a <code>BuildConfig</code> with the docker strategy. You can override the Dockerfile path via <code>spec.strategy.dockerStrategy.dockerfilePath</code>. Then trigger:</p> <pre><code>oc start-build mcpgateway --from-dir=.\n</code></pre> <p>The resulting image lands in an internal ImageStream, and the Deployment can auto-deploy the new tag.</p>"},{"location":"deployment/openshift/#persistence-pvcs","title":"\ud83d\uddc3 Persistence &amp; PVCs","text":"<p>The Postgres template already generates a PVC; you can create extra PVCs manually or via the web console. A general PVC manifest is shown in OpenShift Storage docs.</p>"},{"location":"deployment/openshift/#non-make-cheat-sheet","title":"\ud83d\udea6 Non-Make cheat-sheet","text":"Action Command Build dev image (local) <code>podman build -t mcpgateway-dev -f Containerfile .</code> Build prod (UBI lite) <code>docker build -t mcpgateway -f Containerfile.lite .</code> Push to Quay <code>podman push mcpgateway quay.io/NS/mcpgateway</code> Create project <code>oc new-project mcp-demo</code> Load .env <code>oc create configmap mcpgateway-env --from-env-file=.env</code> Deploy <code>oc apply -f mcpgateway-deployment.yaml</code> Expose <code>oc apply -f mcpgateway-route.yaml</code> Tail logs <code>oc logs -f deployment/mcpgateway</code>"},{"location":"deployment/openshift/#troubleshooting","title":"\ud83d\udee0 Troubleshooting","text":"Issue Fix <code>Error: container has runAsNonRoot and image has non-numeric user</code> Add <code>runAsUser: 1001</code> or pick <code>nonroot-v2</code> SCC. PVC stuck in <code>Pending</code> Check storage class or request size &gt; quota. Route returns 503 Verify pod readiness probe passes and the Service targets port 80 -&gt; 4444."},{"location":"deployment/openshift/#further-reading","title":"\ud83d\udcda Further reading","text":"<ol> <li>OpenShift Route documentation \u2013 creation &amp; TLS</li> <li>SCC and restricted-v2 / nonroot-v2 behaviour</li> <li>ConfigMap envFrom patterns</li> <li>Postgres persistent template example</li> <li>Redis Enterprise Operator on OCP (OperatorHub)</li> <li>Health-check probes in OpenShift</li> <li>BuildConfig Docker strategy &amp; <code>dockerfilePath</code></li> </ol>"},{"location":"development/","title":"Development","text":"<p>Welcome! This guide is for developers contributing to MCP Gateway. Whether you're fixing bugs, adding features, or extending federation or protocol support, this doc will help you get up and running quickly and consistently.</p>"},{"location":"development/#what-youll-find-here","title":"\ud83e\uddf0 What You'll Find Here","text":"Page Description Building Locally How to install dependencies, set up a virtual environment, and run the gateway Packaging How to build a release, container image, or prebuilt binary DEVELOPING.md Coding standards, commit conventions, and review workflow"},{"location":"development/#developer-environment","title":"\ud83d\udee0 Developer Environment","text":"<p>MCP Gateway is built with:</p> <ul> <li>Python 3.10+</li> <li>FastAPI + SQLAlchemy (async) + Pydantic Settings</li> <li>HTMX, Alpine.js, TailwindCSS for the Admin UI</li> </ul> <p>Development tools:</p> <ul> <li>Linters: <code>ruff</code>, <code>mypy</code>, <code>black</code>, <code>isort</code></li> <li>Testing: <code>pytest</code>, <code>httpx</code></li> <li>Serving: <code>uvicorn</code>, <code>gunicorn</code></li> </ul> <p>Code style and consistency is enforced via:</p> <pre><code>make lint          # runs ruff, mypy, black, isort\nmake pre-commit    # runs pre-commit hooks on staged files\n</code></pre> <p>As well as GitHub Actions code scanning.</p>"},{"location":"development/#testing","title":"\ud83e\uddea Testing","text":"<p>Test coverage includes:</p> <ul> <li>Unit tests under <code>tests/unit/</code></li> <li>Integration tests under <code>tests/integration/</code></li> <li>End-to-end tests under <code>tests/e2e/</code></li> <li>Example payload performance testing under <code>tests/hey/</code></li> </ul> <p>Use:</p> <pre><code>make test          # run all tests\nmake test-unit     # run only unit tests\nmake test-e2e      # run end-to-end\n</code></pre>"},{"location":"development/#linting-and-hooks","title":"\ud83d\udd0d Linting and Hooks","text":"<p>CI will fail your PR if code does not pass lint checks.</p> <p>You should manually run:</p> <pre><code>make lint\nmake pre-commit\n</code></pre> <p>Enable hooks with:</p> <pre><code>pre-commit install\n</code></pre>"},{"location":"development/#containers","title":"\ud83d\udc33 Containers","text":"<p>Build and run with Podman or Docker:</p> <pre><code>make podman            # build production image\nmake podman-run-ssl    # run with self-signed TLS at https://localhost:4444\n</code></pre>"},{"location":"development/#authentication","title":"\ud83d\udd10 Authentication","text":"<p>Admin UI and API are protected by Basic Auth or JWT.</p> <p>To generate a JWT:</p> <pre><code>python -m mcpgateway.utils.create_jwt_token \\\n  -u admin \\\n  -e 10080 | tee token.txt\n\nexport MCPGATEWAY_BEARER_TOKEN=$(cat token.txt)\n</code></pre> <p>Then test:</p> <pre><code>curl -k -sX GET \\\n  -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n  https://localhost:4444/tools | jq\n</code></pre>"},{"location":"development/#configuration","title":"\ud83d\udce6 Configuration","text":"<p>Edit <code>.env</code> or set environment variables. A complete list is documented in the README.</p> <p>Use:</p> <pre><code>cp .env.example .env\n</code></pre> <p>Key configs include:</p> Variable Purpose <code>DATABASE_URL</code> Database connection <code>JWT_SECRET_KEY</code> Signing key for JWTs <code>DEV_MODE=true</code> Enables hot reload and debug <code>CACHE_TYPE=memory</code> Options: memory, redis, none"},{"location":"development/#contribution-tips","title":"\ud83d\udea7 Contribution Tips","text":"<ul> <li>Pick a <code>good first issue</code></li> <li>Read the <code>CONTRIBUTING.md</code></li> <li>Fork, branch, commit with purpose</li> <li>Submit PRs against <code>main</code> with clear titles and linked issues</li> </ul>"},{"location":"development/#cicd","title":"\u2705 CI/CD","text":"<p>GitHub Actions enforce:</p> <ul> <li>CodeQL security scanning</li> <li>Pre-commit linting</li> <li>Dependency audits</li> <li>Docker image builds</li> </ul> <p>CI configs live in <code>.github/workflows/</code>.</p> <p>Let me know if you'd like a shorter version or want to customize for internal team handoff.</p>"},{"location":"development/building/","title":"Building Locally","text":"<p>Follow these instructions to set up your development environment, build the gateway from source, and run it interactively.</p>"},{"location":"development/building/#prerequisites","title":"\ud83e\udde9 Prerequisites","text":"<ul> <li>Python \u2265 3.10</li> <li><code>make</code></li> <li>(Optional) Docker or Podman for container builds</li> </ul>"},{"location":"development/building/#one-liner-setup-recommended","title":"\ud83d\udd27 One-Liner Setup (Recommended)","text":"<pre><code>make venv install serve\n</code></pre> <p>This will:</p> <ol> <li>Create a virtual environment in <code>.venv/</code></li> <li>Install Python dependencies including dev extras</li> <li>Run the gateway using Gunicorn</li> </ol>"},{"location":"development/building/#manual-python-setup","title":"\ud83d\udc0d Manual Python Setup","text":"<pre><code>python -m venv .venv\nsource .venv/bin/activate\npip install -e \".[dev]\"\n</code></pre> <p>This installs:</p> <ul> <li>Core app dependencies</li> <li>Dev tools (<code>ruff</code>, <code>black</code>, <code>mypy</code>, etc.)</li> <li>Test runners (<code>pytest</code>, <code>coverage</code>)</li> </ul>"},{"location":"development/building/#running-the-app","title":"\ud83d\ude80 Running the App","text":"<p>You can run the gateway with:</p> <pre><code>make serve         # production-mode Gunicorn (http://localhost:4444)\nmake run           # dev-mode Uvicorn (reloads on change)\n./run.sh --reload  # same as above, with CLI flags\n</code></pre> <p>Use <code>make run</code> or <code>./run.sh</code> during development for auto-reload.</p>"},{"location":"development/building/#live-reload-tips","title":"\ud83d\udd04 Live Reload Tips","text":"<p>Ensure <code>RELOAD=true</code> and <code>DEV_MODE=true</code> are set in your <code>.env</code> during development.</p> <p>Also set:</p> <pre><code>DEBUG=true\nLOG_LEVEL=debug\n</code></pre>"},{"location":"development/building/#test-it","title":"\ud83e\uddea Test It","text":"<pre><code>curl http://localhost:4444/health\ncurl http://localhost:4444/tools\n</code></pre> <p>You should see <code>[]</code> or registered tools (once added).</p>"},{"location":"development/github/","title":"GitHub Workflow Guide","text":"<p>This mini\u2011handbook covers the daily Git tasks we use on mcp-context-forge - from the first clone to the last merge.</p>"},{"location":"development/github/#1-onetime-setup","title":"1. One\u2011Time Setup","text":"<pre><code># Fork on GitHub from https://github.com/IBM/mcp-context-forge.git first, then:\ngit clone https://github.com/&lt;your\u2011user&gt;/mcp-context-forge.git\ncd mcp-context-forge\n\n# Add the canonical repo so you can pull upstream changes\ngit remote add upstream https://github.com/IBM/mcp-context-forge.git\ngit remote -v   # sanity\u2011check remotes\n</code></pre>"},{"location":"development/github/#15-installing-github-cli-gh","title":"1.5 Installing GitHub CLI (<code>gh</code>)","text":""},{"location":"development/github/#macos-homebrew","title":"macOS (Homebrew)","text":"<pre><code>brew install gh\n</code></pre>"},{"location":"development/github/#windows-winget","title":"Windows (winget)","text":"<p>While you can run all this through Powershell, the recommended way to develop on Windows is through WSL2 and Visual Studio Code. The same steps as Ubuntu/Debian apply.</p> <pre><code>winget install GitHub.cli\n</code></pre>"},{"location":"development/github/#ubuntu-debian","title":"Ubuntu / Debian","text":"<pre><code>curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | \\\n  sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg\nsudo chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg\n\necho \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main\" | \\\n  sudo tee /etc/apt/sources.list.d/github-cli.list\n\nsudo apt update\nsudo apt install gh\n</code></pre>"},{"location":"development/github/#fedora-rhel","title":"Fedora / RHEL","text":"<pre><code>sudo dnf install 'https://github.com/cli/cli/releases/download/v2.74.0/gh_2.74.0_linux_amd64.rpm'\n</code></pre> <p>Tip: Replace the version number (<code>2.74.0</code>) with the latest release from https://github.com/cli/cli/releases.</p>"},{"location":"development/github/#firsttime-authentication","title":"First\u2011time authentication","text":"<pre><code>gh auth login             # follow the interactive prompts\n</code></pre> <p>Choose:</p> <ol> <li>GitHub.com</li> <li>HTTPS</li> <li>Either Paste an authentication token or Authorize in browser.</li> </ol>"},{"location":"development/github/#verify-configuration","title":"Verify configuration","text":"<pre><code>gh auth status            # should say \"Logged in to github.com as &lt;your\u2011user&gt;\"\ngh repo view              # shows repo info if run inside a clone\n</code></pre>"},{"location":"development/github/#everyday-commands","title":"Everyday commands","text":"Command Purpose <code>gh pr checkout &lt;id&gt;</code> Fetch &amp; switch to a PR locally (used in \u00a74). <code>gh pr create -w</code> Create a PR and open it in the browser. <code>gh pr status</code> Show which PR is checked out and any requested reviews. <code>gh pr merge &lt;id&gt;</code> Squash / rebase / merge the PR from the terminal."},{"location":"development/github/#16-personal-git-configuration-recommended","title":"1.6 Personal Git Configuration (Recommended)","text":"<p>Setting a few global Git options makes everyday work friction\u2011free and guarantees that every commit passes DCO checks.</p>"},{"location":"development/github/#161-commit-template","title":"1.6.1 Commit template","text":"<p>Create a single\u2011line template that Git pre\u2011pends to every commit message so you never forget the sign\u2011off:</p> <pre><code>echo 'Signed-off-by: &lt;Your Name&gt; &lt;you@example.com&gt;' &gt; ~/.git-commit-template\n</code></pre>"},{"location":"development/github/#162-gitconfig-example","title":"1.6.2 <code>~/.gitconfig</code> example","text":"<p>Put this in <code>~/.gitconfig</code> (or append the bits you're missing):</p> <pre><code># ~/.gitconfig\n[user]\n    name = &lt;Your Name&gt;\n    email = &lt;you@example.com&gt;\n\n[init]\n    defaultBranch = main  # Use 'main' instead of 'master' when creating new repos\n\n[core]\n    autocrlf = input       # On commit: convert CRLF to LF (Windows \u2192 Linux)\n    eol = lf               # Ensure all files in the repo use LF internally\n\n[alias]\n    cm = commit -s -m      # `git cm \"message\"` \u2192 signed commit\n    ca = commit --amend -s # `git ca` \u2192 amend + sign\u2011off\n\n[commit]\n    template = ~/.git-commit-template\n</code></pre> <p>Or run the one\u2011liners:</p> <pre><code>git config --global user.name  \"Your Name\"\ngit config --global user.email \"you@example.com\"\ngit config --global alias.cm   \"commit -s -m\"\ngit config --global alias.ca   \"commit --amend -s\"\ngit config --global commit.template ~/.git-commit-template\n</code></pre> <p>Replace placeholders with your real details, and you're good to go.</p>"},{"location":"development/github/#2-staying-in-sync-with-upstream","title":"2. Staying in Sync with Upstream","text":"<pre><code># From any branch:\ngit fetch upstream\ngit switch main                 # or master, depending on the project\ngit merge --ff-only upstream/main\n\ngit push origin main             # keep your fork up to date\n</code></pre>"},{"location":"development/github/#3-creating-your-own-work-branch","title":"3. Creating Your Own Work Branch","text":"<pre><code>git switch -c feat/my-great-idea\n# \u2026hack away\u2026\ngit add .\n# Always sign your commits for DCO compliance:\ngit commit -s -m \"feat: explain context\u2011merging algorithm\"\n\ngit push -u origin HEAD          # publishes the branch\n# Then open a Pull Request (PR) on GitHub.\n</code></pre> <p>Why <code>-s</code>? The <code>-s / --signoff</code> flag appends a <code>Signed-off-by: Your Name &lt;email&gt;</code> trailer that lets CI verify Developer Certificate of Origin (DCO) compliance.</p>"},{"location":"development/github/#4-fetching-reviewing-an-existing-pr","title":"4. Fetching &amp; Reviewing an Existing PR","text":""},{"location":"development/github/#41-with-plain-git-works-everywhere","title":"4.1 With Plain Git (works everywhere)","text":"<pre><code>git fetch upstream pull/29/head:pr-29   # Pull Request #29\ngit switch pr-29\n</code></pre>"},{"location":"development/github/#42-with-github-cli-fastest-if-installed","title":"4.2 With GitHub CLI (fastest if installed)","text":"<pre><code>gh pr checkout 29\n</code></pre>"},{"location":"development/github/#5-smoketesting-every-pr-before-you-comment","title":"5. Smoke\u2011Testing Every PR Before You Comment \ud83c\udf0b","text":"<p>Hard rule: No PR gets a \"Looks good to me\" without passing both the local and container builds below.</p>"},{"location":"development/github/#51-local-build-sqlite-selfsigned-https","title":"5.1 Local build (SQLite + self\u2011signed HTTPS)","text":"<pre><code>make venv install install-dev serve-ssl\n</code></pre> <ul> <li>Sets up a Python virtualenv</li> <li>Installs runtime + dev dependencies</li> <li>Runs the HTTPS dev server against SQLite</li> </ul>"},{"location":"development/github/#52-container-build-postgresql-redis","title":"5.2 Container build (PostgreSQL + Redis)","text":"<pre><code>make compose-up\n</code></pre> <ul> <li>Spins up the full Docker Compose stack</li> <li>Uses PostgreSQL for persistence and Redis for queueing</li> <li>Rebuilds images so you catch Docker\u2011specific issues</li> </ul>"},{"location":"development/github/#53-gateway-jwt-local-api-access","title":"5.3 Gateway JWT (local API access)","text":"<p>Quickly confirm that authentication works and the gateway is healthy:</p> <pre><code>export MCPGATEWAY_BEARER_TOKEN=$(python -m mcpgateway.utils.create_jwt_token -u admin --secret my-test-key)\ncurl -s -k -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" https://localhost:4444/health\n</code></pre> <p>Expected output:</p> <pre><code>{\"status\": \"ok\"}\n</code></pre> <p>If you see anything other than <code>{\"status\":\"ok\"}</code>, investigate before approving the PR.</p> <p>Quickly confirm that the MCP Gateway is configured with the correct database, and it is reachable:</p> <pre><code>curl -s -k -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" https://localhost:4444/version | jq\n</code></pre> <p>Then proceed to register an MCP Server under Gateways using the UI, ensuring that Tools work, creating a Virtual Server and testing that from UI, API and a MCP Client.</p> <p>These steps are described in Basic Testing.</p>"},{"location":"development/github/#54-run-the-automated-test-suite","title":"5.4 Run the automated test suite","text":"<pre><code>make test         # or `pytest` directly\n</code></pre> <p>All tests must pass locally. If you add or modify functionality, ensure new tests cover the change.</p>"},{"location":"development/github/#55-lint-static-analysis","title":"5.5 Lint &amp; static analysis","text":"<pre><code>make lint         # runs ruff, mypy, black --check, etc.\n</code></pre> <p>Code should come back clean. Fix any warnings before pushing.</p> <p>If any of the above steps fail, leave a review requesting fixes and paste the relevant logs inline or as a gist.</p>"},{"location":"development/github/#6-squashing-commits","title":"6. Squashing Commits \ud83e\udd5e","text":"<p>Keeping a clean, single\u2011commit history per PR makes <code>git bisect</code> and blame easier.</p>"},{"location":"development/github/#61-squash-interactively-local-recommended","title":"6.1 Squash interactively (local, recommended)","text":"<pre><code># In your feature branch, before pushing OR after addressing review feedback:\n\ngit fetch upstream  # make sure refs are fresh\ngit rebase -i upstream/main\n</code></pre> <p>In the interactive list, mark the first commit as <code>pick</code> and every subsequent one as <code>squash</code> (or <code>fixup</code> for no extra message). Save &amp; quit; Git opens an editor so you can craft the final commit message\u2014remember to keep the <code>Signed-off-by</code> line!</p> <p>If the branch is already on GitHub and you've squashed locally, force\u2011push the updated, single\u2011commit branch:</p> <pre><code>git push --force-with-lease\n</code></pre>"},{"location":"development/github/#62-squash-via-github-ui-simple-but-lastminute","title":"6.2 Squash via GitHub UI (simple, but last\u2011minute)","text":"<ol> <li>In the PR, click \"Merge\" \u2192 \"Squash and merge.\"</li> <li>Tweak the commit title/description as needed.</li> <li>Ensure the <code>Signed-off-by:</code> trailer is present (GitHub adds it automatically if you enabled DCO in the repo).</li> </ol> <p>Use the UI method only if reviewers are done\u2014every push re\u2011triggers CI.</p>"},{"location":"development/github/#7-functional-code-review-checklist","title":"7. Functional &amp; Code Review Checklist","text":"Check Why it matters Does it build locally? Fastest signal that the code even compiles. Does it build in Docker? Catches missing OS packages or env\u2011var mishaps. Unit tests green? Ensures regressions are caught immediately. No new lint errors? Keeps the CI pipeline and codebase clean. Commits squashed &amp; signed? One commit history + DCO compliance. Docs / comments updated? Future devs will thank you."},{"location":"development/github/#8-merging-the-pr","title":"8. Merging the PR","text":"<ul> <li>Squash\u2011and\u2011merge is the default merge strategy.</li> <li>Confirm the final commit message follows Conventional Commits and retains a <code>Signed-off-by:</code> trailer.</li> <li>GitHub automatically deletes the source branch after a successful merge\u2014no manual cleanup required.</li> </ul> <p>Verify GitHub CI status checks</p> <p>Before requesting review, confirm that all required status checks on the PR page are green (\"All checks have passed\"). You should now see something like:</p> <pre><code>Bandit / bandit (pull_request)                  \u2705  Successful in 21s\nBuild Python Package / build-package (3.10)     \u2705  Successful in 12s\nCode scanning results / Bandit                  \u2705  No new alerts in code changed by this pull request\nCode scanning results / Dockle                  \u2705  No new alerts in code changed by this pull request\nCode scanning results / Hadolint                \u2705  No new alerts in code changed by this pull request\nCode scanning results / Trivy                   \u2705  No new alerts in code changed by this pull request\nCodeQL Advanced / CodeQL (javascript-typescript)\u2705  Successful in 1m\nCodeQL Advanced / CodeQL (python)               \u2705  Successful in 1m\nDCO                                             \u2705  Passed\nDependency Review / dependency-review           \u2705  Successful in 4s\nSecure Docker Build / build-scan-sign           \u2705  Successful in 4m\nTravis CI - Branch                              \u2705  Build Passed\nTravis CI - Pull Request                        \u2705  Build Passed\n</code></pre> <p>If anything is red or still running, wait or push a fix in the same PR until every line is green. Ensure that a CODEOWNER is assigned to review the PR.</p> <p>Once the PR is merged, double\u2011check that the CI/CD pipeline deploys the change to all environments without errors.</p> <p>If any of the above steps fail after the PR is merged or cannot deploy, leave a review requesting fixes and paste the relevant logs inline or as a gist.</p>"},{"location":"development/github/#9-cleaning-up-locally","title":"9. Cleaning Up Locally","text":"<pre><code>git switch main\ngit branch -D pr-29                # or the feature branch name\ngit fetch -p                       # prune remotes that GitHub deleted\n</code></pre>"},{"location":"development/github/#10-handy-git-aliases-optional","title":"10. Handy Git Aliases (Optional)","text":"<pre><code>git config --global alias.co checkout\ngit config --global alias.cm 'commit -s -m'\ngit config --global alias.ca 'commit --amend -s'\ngit config --global alias.rb \"rebase -i --autosquash\"\ngit config --global alias.pr '!f() { git fetch upstream pull/$1/head:pr-$1 &amp;&amp; git switch pr-$1; }; f'\n</code></pre> <p>Now <code>git pr 42</code> does the whole fetch\u2011and\u2011switch in one go.</p>"},{"location":"development/github/#11-troubleshooting-faq","title":"11. Troubleshooting FAQ","text":"Symptom Fix <code>error: cannot lock ref</code> Run <code>git gc --prune=now</code> and retry. <code>docker: no space left</code> <code>docker system prune -af &amp;&amp; docker volume prune</code> Unit tests hang on macOS Ensure you aren't on an Apple\u2011Silicon image that needs platform flags."},{"location":"development/github/#happy-hacking","title":"Happy hacking! \ud83d\udee0\ufe0f","text":"<p>Submit improvements to this doc via another signed, squashed PR so everyone benefits.</p>"},{"location":"development/packaging/","title":"Packaging &amp; Distribution","text":"<p>This guide covers how to package MCP Gateway for deployment in various environments, including building production containers and generating releases.</p>"},{"location":"development/packaging/#production-container-podman-or-docker","title":"\ud83d\udce6 Production Container (Podman or Docker)","text":"<p>Build an OCI-compliant container image using:</p> <pre><code>make podman\npodman build -t mcpgateway:latest -f Containerfile .\n</code></pre> <p>Or with Docker (if Podman is not available):</p> <pre><code>make docker\n# or manually\ndocker build -t mcpgateway:latest -f Containerfile .\n</code></pre> <p>A lite image is also available for use in production, see <code>Containerfile.lite</code></p>"},{"location":"development/packaging/#run-with-tls-self-signed","title":"\ud83d\udd10 Run with TLS (self-signed)","text":"<pre><code>make podman-run-ssl\n</code></pre> <p>This uses self-signed certs from <code>./certs/</code> and runs HTTPS on port <code>4444</code>.</p>"},{"location":"development/packaging/#container-run-http","title":"\ud83d\udee0 Container Run (HTTP)","text":"<pre><code>make podman-run\n</code></pre> <p>This runs the container without TLS on port <code>4444</code>.</p>"},{"location":"development/packaging/#versioning","title":"\ud83d\udcdd Versioning","text":"<p>MCP Gateway uses semantic versioning (<code>MAJOR.MINOR.PATCH</code>) and the version is defined in:</p> <pre><code>mcpgateway/__init__.py\n</code></pre> <p>You can bump the version manually or automate it via Git tags or CI/CD.</p>"},{"location":"development/packaging/#release-artifacts","title":"\ud83d\udcc1 Release Artifacts","text":"<p>If you need to ship ZIPs, wheels, or a full binary:</p> <pre><code>python -m build\n</code></pre> <p>Outputs will be under <code>dist/</code>. You can then:</p> <ul> <li>Push to PyPI (internal or public)</li> <li>Upload to GitHub Releases</li> <li>Package in a <code>.deb</code>, <code>.rpm</code>, etc.</li> </ul>"},{"location":"development/packaging/#whats-in-the-container","title":"\ud83d\udcc2 What's in the Container?","text":"<p>A typical image includes:</p> <ul> <li>Gunicorn running with <code>mcpgateway.main:app</code></li> <li>All code, static files, and compiled assets</li> </ul> <p>You can override settings using environment variables at runtime.</p>"},{"location":"manage/","title":"Management Overview","text":"<p>This section provides operational guidance for running and maintaining a production instance of MCP Gateway.</p> <p>Whether you're self-hosting, running in the cloud, or deploying to Kubernetes, this section helps you monitor, back up, and maintain the system.</p>"},{"location":"manage/#whats-covered","title":"\ud83e\udded What's Covered","text":"Page Description Backups How to persist and restore your database, configs, and resource state Logging Configure structured logging, log destinations, and log rotation"},{"location":"manage/#runtime-config-via-env","title":"\ud83d\udd10 Runtime Config via <code>.env</code>","text":"<p>Most operational settings (logging level, database pool size, auth mode) are controlled through <code>.env</code> or environment variables.</p> <p>Update the file and restart the container or process to apply changes.</p>"},{"location":"manage/#health-readiness","title":"\ud83e\uddea Health &amp; Readiness","text":"<p>Expose the <code>/health</code> endpoint for use with:</p> <ul> <li>Cloud load balancer health checks</li> <li>Kubernetes probes</li> <li>CI/CD smoke tests</li> </ul> <p>Sample check:</p> <pre><code>curl http://localhost:4444/health\n</code></pre> <p>Expected response:</p> <pre><code>{ \"status\": \"healthy\"}\n</code></pre>"},{"location":"manage/#service-restart-commands","title":"\ud83d\udd01 Service Restart Commands","text":"<p>Depending on your environment:</p> <ul> <li><code>docker restart mcpgateway</code></li> <li><code>kubectl rollout restart deployment/mcpgateway</code></li> </ul>"},{"location":"manage/backup/","title":"Backups","text":"<p>MCP Gateway stores its runtime state in a SQL database and optionally in Redis (for sessions and caching). This guide explains how to persist and restore that state safely.</p>"},{"location":"manage/backup/#what-needs-to-be-backed-up","title":"\ud83d\udce6 What Needs to Be Backed Up","text":"Component What It Contains Database (<code>mcp.db</code> or PostgreSQL) All tools, prompts, resources, servers, metrics <code>.env</code> file Environment variables and secrets (e.g. JWT secret, DB URL) Volume-mounted uploads (if any) User-uploaded data or TLS certs Redis (optional) Session tokens, cached resources (only if using <code>CACHE_TYPE=redis</code>)"},{"location":"manage/backup/#backup-strategies","title":"\ud83d\udcbe Backup Strategies","text":""},{"location":"manage/backup/#for-sqlite-default","title":"For SQLite (default)","text":"<pre><code>cp mcp.db backups/mcp-$(date +%F).db\n</code></pre>"},{"location":"manage/backup/#for-postgresql","title":"For PostgreSQL","text":"<pre><code>pg_dump -U youruser -h yourhost -F c -f backups/mcp-$(date +%F).pgdump\n</code></pre> <p>You can also automate this via <code>cron</code> or a container sidecar.</p>"},{"location":"manage/backup/#restore-instructions","title":"\ud83d\udd01 Restore Instructions","text":""},{"location":"manage/backup/#sqlite","title":"SQLite","text":"<pre><code>cp backups/mcp-2024-05-10.db mcp.db\n</code></pre> <p>Restart the gateway afterward.</p>"},{"location":"manage/backup/#postgresql","title":"PostgreSQL","text":"<pre><code>pg_restore -U youruser -d mcp -h yourhost backups/mcp-2024-05-10.pgdump\n</code></pre>"},{"location":"manage/backup/#storing-secrets","title":"\ud83d\uddc3 Storing Secrets","text":"<p>Use a secrets manager (e.g., AWS Secrets Manager, Azure Key Vault, or Kubernetes Secrets) to manage <code>.env</code> contents securely in production.</p>"},{"location":"manage/backup/#verify-your-backup","title":"\ud83e\uddea Verify Your Backup","text":"<p>Run smoke tests:</p> <pre><code>curl -s -k -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" http://localhost:4444/tools\ncurl -s -k -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" http://localhost:4444/prompts\n</code></pre> <p>You should see previously registered tools and templates.</p>"},{"location":"manage/backup/#understanding-the-database-schema","title":"\ud83e\uddec Understanding the Database Schema","text":"<p>MCP Gateway uses a relational database (e.g. SQLite or PostgreSQL) to persist all registered entities and track tool/server usage. When session storage is configured as <code>CACHE_TYPE=database</code>, it also persists active user sessions and streamed message content.</p>"},{"location":"manage/backup/#key-tables","title":"Key Tables","text":"Table Purpose <code>tools</code> Stores registered tools, including schemas and auth configs <code>tool_metrics</code> Tracks execution stats per tool (latency, success/fail) <code>resources</code> Stores static or dynamic URI-based resources <code>resource_metrics</code> Logs usage of resources (access count, latency, etc.) <code>resource_subscriptions</code> Tracks SSE client subscriptions to resources <code>prompts</code> Jinja2 prompt templates with input arguments <code>prompt_metrics</code> Usage metrics for each prompt <code>servers</code> Virtual servers that group tools/resources under an SSE stream <code>server_metrics</code> Invocation stats per server <code>gateways</code> External federated MCP servers added by the admin <code>mcp_sessions</code> Persistent session registry when using <code>CACHE_TYPE=database</code> <code>mcp_messages</code> Persisted streamed content (text/image/etc.) tied to sessions <code>*_association</code> tables Many-to-many mapping between tools/resources/prompts and their servers/gateways"},{"location":"manage/backup/#session-and-message-tables","title":"Session and Message Tables","text":"<p>These only appear when session/messaging backend is set to <code>database</code>:</p> <ul> <li><code>mcp_sessions</code>: Each record is an open session ID (used for SSE streams and client context).</li> <li><code>mcp_messages</code>: Stores streamed messages (text, image, resource) linked to a session\u2014useful for debugging or offline playback.</li> </ul> <p>You can query active sessions:</p> <pre><code>SELECT session_id, created_at FROM mcp_sessions ORDER BY created_at DESC;\n</code></pre> <p>Or inspect message content (JSON-encoded):</p> <pre><code>SELECT content FROM mcp_messages WHERE session_id = 'abc123';\n</code></pre> <p>These tables are cleaned automatically when session TTLs expire, but can also be purged manually if needed.</p>"},{"location":"manage/logging/","title":"Logging","text":"<p>MCP Gateway emits structured logs that can be viewed locally or forwarded to a log aggregation service. This guide shows how to configure log levels, formats, and destinations.</p>"},{"location":"manage/logging/#log-structure","title":"\ud83e\uddfe Log Structure","text":"<p>Logs are emitted in JSON or text format, depending on your configuration.</p> <p>Example (JSON format):</p> <pre><code>{\n  \"timestamp\": \"2025-05-15T10:32:10Z\",\n  \"level\": \"INFO\",\n  \"module\": \"gateway_service\",\n  \"message\": \"Registered gateway: peer-gateway-1\"\n}\n</code></pre>"},{"location":"manage/logging/#configuring-logs","title":"\ud83d\udd27 Configuring Logs","text":"<p>You can control logging behavior using <code>.env</code> settings:</p> Variable Description Example <code>LOG_LEVEL</code> Minimum log level <code>INFO</code>, <code>DEBUG</code>, <code>ERROR</code> <code>LOG_FORMAT</code> Log output format <code>json</code> or <code>text</code> <code>LOG_FILE</code> Write logs to a file (optional) <code>/var/log/mcpgateway.log</code>"},{"location":"manage/logging/#streaming-logs-containers","title":"\ud83d\udce1 Streaming Logs (Containers)","text":"<pre><code>docker logs -f mcpgateway\n# or with Podman\npodman logs -f mcpgateway\n</code></pre>"},{"location":"manage/logging/#shipping-logs-to-external-services","title":"\ud83d\udce4 Shipping Logs to External Services","text":"<p>MCP Gateway can write to stdout or a file. To forward logs to services like:</p> <ul> <li>ELK (Elastic Stack)</li> <li>LogDNA / IBM Log Analysis</li> <li>Datadog</li> <li>Fluentd / Loki</li> </ul> <p>You can:</p> <ul> <li>Mount log files to a sidecar container</li> <li>Use a logging agent (e.g., Filebeat)</li> <li>Pipe logs to syslog-compatible services</li> </ul>"},{"location":"manage/logging/#debug-mode","title":"\ud83e\uddea Debug Mode","text":"<p>For development, enable verbose logs by setting:</p> <pre><code>LOG_LEVEL=debug\nLOG_FORMAT=text\nDEBUG=true\n</code></pre> <p>This enables detailed request traces and internal service logs.</p>"},{"location":"manage/tuning/","title":"Gateway Tuning Guide","text":"<p>This page collects practical levers for squeezing the most performance, reliability, and observability out of MCP Gateway\u2014no matter where you run the container (Code Engine, Kubernetes, Docker Compose, Nomad, etc.).</p> <p>TL;DR</p> <ol> <li>Tune the runtime environment via <code>.env</code> and configure mcpgateway to use PostgreSQL and Redis.</li> <li>Adjust Gunicorn workers &amp; time\u2011outs in <code>gunicorn.conf.py</code>.</li> <li>Right\u2011size CPU/RAM for the container or spin up more instances (with shared Redis state) and change the database settings (ex: connection limits).</li> <li>Benchmark with hey (or your favourite load\u2011generator) before &amp; after.</li> </ol>"},{"location":"manage/tuning/#1-environment-variables-env","title":"1 \u00b7 Environment variables (<code>.env</code>)","text":"Variable Default Why you might change it <code>AUTH_REQUIRED</code> <code>true</code> Disable for internal/behind\u2011VPN deployments to shave a few ms per request. <code>JWT_SECRET_KEY</code> random Longer key \u279c slower HMAC verify; still negligible\u2014leave as is. <code>CACHE_TYPE</code> <code>database</code> Switch to <code>redis</code> or <code>memory</code> if your workload is read\u2011heavy and latency\u2011sensitive. <code>DATABASE_URL</code> SQLite Move to managed PostgreSQL + connection pooling for anything beyond dev tests. <code>HOST</code>/<code>PORT</code> <code>0.0.0.0:4444</code> Expose a different port or bind only to <code>127.0.0.1</code> behind a reverse\u2011proxy. <p>Tip  Any change here requires rebuilding or restarting the container if you pass the file with <code>--env\u2011file</code>.</p>"},{"location":"manage/tuning/#2-gunicorn-settings-gunicornconfpy","title":"2 \u00b7 Gunicorn settings (<code>gunicorn.conf.py</code>)","text":"Knob Purpose Rule of thumb <code>workers</code> Parallel processes <code>2\u20134 \u00d7 vCPU</code> for CPU\u2011bound work; fewer if memory\u2011bound. <code>threads</code> Per\u2011process threads Use only with <code>sync</code> worker; keeps memory low for I/O workloads. <code>timeout</code> Kill stuck worker Set \u2265 end\u2011to\u2011end model latency. E.g. 600 s for LLM calls. <code>preload_app</code> Load app once Saves RAM; safe for pure\u2011Python apps. <code>worker_class</code> Async workers <code>gevent</code> or <code>eventlet</code> for many concurrent requests / websockets. <code>max_requests(+_jitter)</code> Self\u2011healing Recycle workers to mitigate memory leaks. <p>Edit the file before building the image, then redeploy.</p>"},{"location":"manage/tuning/#3-container-resources","title":"3 \u00b7 Container resources","text":"vCPU \u00d7 RAM Good for Notes <code>0.5 \u00d7 1 GB</code> Smoke tests / CI Smallest footprint; likely CPU\u2011starved under load. <code>1 \u00d7 4 GB</code> Typical dev / staging Handles a few hundred RPS with default 8 workers. <code>2 \u00d7 8 GB</code> Small prod Allows ~16\u201320 workers; good concurrency. <code>4 \u00d7 16 GB</code>+ Heavy prod Combine with async workers or autoscaling. <p>Always test with your workload; JSON\u2011RPC payload size and backend model latency change the equation.</p> <p>To change your database connection settings, see the respective documentation for your selected database or managed service. For example, when using IBM Cloud Databases for PostgreSQL - you can raise the maximum number of connections.</p>"},{"location":"manage/tuning/#4-performance-testing","title":"4 \u00b7 Performance testing","text":""},{"location":"manage/tuning/#41-tooling-hey","title":"4.1 Tooling: hey","text":"<p>Install one of:</p> <pre><code>brew install hey            # macOS\nsudo apt install hey         # Debian/Ubuntu\n# or build from source\ngo install github.com/rakyll/hey@latest  # $GOPATH/bin must be in PATH\n</code></pre>"},{"location":"manage/tuning/#42-sample-loadtest-script-testsheysh","title":"4.2 Sample load\u2011test script (<code>tests/hey.sh</code>)","text":"<pre><code>#!/usr/bin/env bash\n# Run 10 000 requests with 200 concurrent workers.\nJWT=\"$(cat jwt.txt)\"   # &lt;- place a valid token here\nhey -n 10000 -c 200 \\\n    -m POST \\\n    -T application/json \\\n    -H \"Authorization: Bearer ${JWT}\" \\\n    -D tests/hey/payload.json \\\n    http://localhost:4444/rpc\n</code></pre> <p>Payload (<code>tests/hey/payload.json</code>)</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"convert_time\",\n  \"params\": {\n    \"source_timezone\": \"Europe/Berlin\",\n    \"target_timezone\": \"Europe/Dublin\",\n    \"time\": \"09:00\"\n  }\n}\n</code></pre>"},{"location":"manage/tuning/#43-reading-the-output","title":"4.3 Reading the output","text":"<p><code>hey</code> prints latency distribution, requests/second, and error counts. Focus on:</p> <ul> <li>99<sup>th</sup> percentile latency \u2013 adjust <code>timeout</code> if it clips.</li> <li>Errors \u2013 5xx under load often mean too few workers or DB connections.</li> <li>Throughput (RPS) \u2013 compare before/after tuning.</li> </ul>"},{"location":"manage/tuning/#44-common-bottlenecks-fixes","title":"4.4 Common bottlenecks &amp; fixes","text":"Symptom Likely cause Mitigation High % of 5xx under load Gunicorn workers exhausted Increase <code>workers</code>, switch to async workers, raise CPU. Latency &gt; timeout Long model call / external API Increase <code>timeout</code>, add queueing, review upstream latency. Memory OOM Too many workers / large batch size Lower <code>workers</code>, disable <code>preload_app</code>, add RAM."},{"location":"manage/tuning/#5-logging-observability","title":"5 \u00b7 Logging &amp; observability","text":"<ul> <li>Set <code>loglevel = \"debug\"</code> in <code>gunicorn.conf.py</code> during tests; revert to <code>info</code> in prod.</li> <li>Forward <code>stdout</code>/<code>stderr</code> from the container to your platform's log stack (e.g. <code>kubectl logs</code>, <code>docker logs</code>).</li> <li>Expose <code>/metrics</code> via Prometheus exporter (coming soon) for request timing &amp; queue depth.</li> </ul>"},{"location":"manage/tuning/#6-security-tips-while-tuning","title":"6 \u00b7 Security tips while tuning","text":"<ul> <li>Never commit real <code>JWT_SECRET_KEY</code>, DB passwords, or tokens\u2014use <code>.env.example</code> as a template.</li> <li>Prefer platform secrets (K8s Secrets, Code Engine secrets) over baking creds into the image.</li> <li>If you enable <code>gevent</code>/<code>eventlet</code>, pin their versions and run bandit or trivy scans.</li> </ul>"},{"location":"manage/upgrade/","title":"Upgrading MCP Gateway and Managing Database Migrations","text":"<p>This guide provides step-by-step instructions for upgrading the MCP Gateway and handling associated database migrations to ensure a smooth transition with minimal downtime.</p>"},{"location":"manage/upgrade/#upgrade-overview","title":"\ud83d\udd04 Upgrade Overview","text":"<p>MCP Gateway is under active development, and while we strive for backward compatibility, it's essential to review version changes carefully when upgrading. Due to rapid iterations, documentation updates may sometimes lag. If you encounter issues, consult our GitHub repository or reach out via GitHub Issues.</p>"},{"location":"manage/upgrade/#upgrade-steps","title":"\ud83d\udee0 Upgrade Steps","text":""},{"location":"manage/upgrade/#1-backup-current-configuration-and-data","title":"1. Backup Current Configuration and Data","text":"<p>Before initiating an upgrade:</p> <ul> <li>Export Configuration: Backup your current configuration files.</li> <li>Database Backup: Create a full backup of your database to prevent data loss.</li> </ul>"},{"location":"manage/upgrade/#2-review-release-notes","title":"2. Review Release Notes","text":"<p>Check the release notes for:</p> <ul> <li>Breaking Changes: Identify any changes that might affect your current setup.</li> <li>Migration Scripts: Look for any provided scripts or instructions for database migrations.</li> </ul>"},{"location":"manage/upgrade/#3-update-mcp-gateway","title":"3. Update MCP Gateway","text":"<p>Depending on your deployment method: podman, docker, kubernetes, etc.</p>"},{"location":"manage/upgrade/#4-apply-database-migrations","title":"4. Apply Database Migrations","text":"<p>If the new version includes database schema changes:</p> <ul> <li>Migration Scripts: Execute any provided migration scripts.</li> <li>Manual Migrations: If no scripts are provided, consult the release notes for manual migration instructions.</li> </ul>"},{"location":"manage/upgrade/#5-verify-the-upgrade","title":"5. Verify the Upgrade","text":"<p>Post-upgrade, ensure:</p> <ul> <li>Service Availability: MCP Gateway is running and accessible.</li> <li>Functionality: All features and integrations are working as expected.</li> <li>Logs: Check logs for any errors or warnings.</li> </ul>"},{"location":"manage/upgrade/#testing-and-validation","title":"\ud83e\uddea Testing and Validation","text":"<ul> <li>Staging Environment: Test the upgrade process in a staging environment before applying to production.</li> <li>Automated Tests: Run your test suite to catch any regressions.</li> <li>User Acceptance Testing (UAT): Engage end-users to validate critical workflows.</li> </ul>"},{"location":"manage/upgrade/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>MCP Gateway GitHub Repository</li> <li>MCP Gateway Documentation</li> </ul>"},{"location":"overview/","title":"Overview","text":"<p>Welcome to the MCP Gateway documentation.</p> <p>This section introduces what the Gateway is, how it fits into the MCP ecosystem, and what core features and capabilities it offers out of the box.</p>"},{"location":"overview/#what-is-mcp-gateway","title":"What is MCP Gateway?","text":"<p>MCP Gateway is an orchestration and federation layer for the Model Context Protocol (MCP). It provides:</p> <ul> <li>A unified entrypoint for tools, resources, prompts, and agents</li> <li>Federation of multiple MCP servers into one composable catalog</li> <li>Protocol enforcement, health monitoring, and registry centralization</li> <li>A visual Admin UI to manage everything in real time</li> </ul> <p>Whether you're integrating REST APIs, local functions, or full LLM agents, MCP Gateway standardizes access and transport \u2014 over HTTP, WebSockets, SSE, or stdio.</p>"},{"location":"overview/#whats-in-this-section","title":"What's in This Section","text":"Page Description Features Breakdown of supported features including federation, transports, and tool wrapping Admin UI Screenshots and explanation of the interactive web dashboard"},{"location":"overview/features/","title":"Features","text":"<p>MCP Gateway offers a robust feature set for integrating and managing tools, servers, prompts, and resources under the Model Context Protocol.</p>"},{"location":"overview/features/#core-capabilities","title":"\ud83e\udde0 Core Capabilities","text":"<ul> <li> <p>Full MCP 2025-03-26 Protocol Support   Implements all required methods: <code>initialize</code>, <code>ping</code>, <code>notify</code>, <code>complete</code>, <code>createMessage</code>, and fallback JSON-RPC.</p> </li> <li> <p>Multi-Transport Support   Accessible via:</p> </li> <li>HTTP/JSON-RPC</li> <li>WebSocket (bi-directional with ping/pong)</li> <li>Server-Sent Events (SSE)</li> <li> <p>stdio (for subprocess embedding)</p> </li> <li> <p>Unified Registry   Maintains a centralized catalog of:</p> </li> <li>Tools (native or REST-adapted)</li> <li>Prompts (Jinja2 templates with schema validation)</li> <li>Resources (MIME-aware, URI-addressable)</li> <li>Servers (virtual or federated)</li> <li>Federated Gateways</li> </ul>"},{"location":"overview/features/#federation-discovery","title":"\ud83c\udf10 Federation &amp; Discovery","text":"<ul> <li>Peer discovery (mDNS or explicit list)</li> <li>Periodic health checks with failover logic</li> <li>Transparent merging of capabilities</li> <li>Federation timeouts, retries, and sync intervals configurable</li> </ul>"},{"location":"overview/features/#tool-management","title":"\ud83d\udee0 Tool Management","text":"<ul> <li>Register tools via REST, UI, or JSON-RPC</li> <li>Wrap any REST API, CLI command, or function</li> <li>Supports:</li> <li>JSON Schema validation</li> <li>Concurrency limits</li> <li>Rate limiting</li> <li>Retry policies</li> <li>Output filtering via JSONPath</li> </ul>"},{"location":"overview/features/#prompt-templates","title":"\ud83d\udcac Prompt Templates","text":"<ul> <li>Jinja2-powered text blocks</li> <li>Enforced schema (required/optional args)</li> <li>Versioned templates with rollback</li> <li>Used by agents and sampling calls</li> </ul>"},{"location":"overview/features/#resource-handling","title":"\ud83d\udce6 Resource Handling","text":"<ul> <li>URI-addressed resources</li> <li>MIME type detection</li> <li>LRU+TTL caching (in-memory, Redis, or DB)</li> <li>SSE-based subscriptions to dynamic resources</li> </ul>"},{"location":"overview/features/#observability","title":"\ud83d\udcca Observability","text":"<ul> <li>Structured JSON logs</li> <li>Log levels per route</li> <li><code>/health</code> endpoint with live latency stats</li> <li>Metrics for tools, servers, prompts, and gateways</li> </ul>"},{"location":"overview/features/#admin-interface","title":"\ud83d\udda5 Admin Interface","text":"<ul> <li>Interactive UI with full CRUD for:</li> <li>Tools</li> <li>Resources</li> <li>Prompts</li> <li>Servers</li> <li>Gateways</li> <li>Roots</li> <li>Built with HTMX, Alpine.js, and Tailwind CSS</li> </ul>"},{"location":"overview/features/#authentication-security","title":"\ud83d\udd10 Authentication &amp; Security","text":"<ul> <li>Supports both Basic and JWT authentication</li> <li>Bearer tokens signed with configurable secrets</li> <li>TLS verification options</li> <li>Optional anonymous/public mode (<code>AUTH_REQUIRED=false</code>)</li> </ul>"},{"location":"overview/ui/","title":"Admin UI","text":"<p>MCP Gateway includes a built-in Admin UI for managing all entities in real time via a web browser.</p>"},{"location":"overview/ui/#accessing-the-ui","title":"\ud83d\udda5\ufe0f Accessing the UI","text":"<p>After launching the gateway (<code>make serve</code> or <code>make podman-run</code>), open your browser and go to:</p> <p>http://localhost:4444/admin - or the corresponding URL / port / protocol (ex: https when launching with <code>make podman-run-ssl</code>)</p> <p>Login using the <code>BASIC_AUTH_USER</code> and <code>BASIC_AUTH_PASSWORD</code> set in your <code>.env</code>.</p>"},{"location":"overview/ui/#ui-overview","title":"\ud83e\udded UI Overview","text":"<p>The Admin UI is built with HTMX, Alpine.js, and Tailwind CSS, offering a dynamic, SPA-like experience without JavaScript bloat.</p> <p>It provides tabbed access to:</p> <ul> <li>Servers Catalog: Define or edit MCP servers (real or virtual)</li> <li>Tools: Register REST or native tools, configure auth/rate limits, test responses</li> <li>Resources: Add templated or static resources, set MIME types, enable caching</li> <li>Prompts: Define Jinja2 prompt templates with argument schemas and preview rendering</li> <li>Gateways: View and manage federated peers, toggle activity status</li> <li>Roots: Register root URIs for agent or resource scoping</li> <li>Metrics: Real-time usage and performance metrics for all entities</li> </ul>"},{"location":"overview/ui/#common-actions","title":"\u270d\ufe0f Common Actions","text":"Action How Register a tool Use the Tools tab \u2192 Add Tool form View prompt output Go to Prompts \u2192 click View Toggle server activity Use the \"Activate/Deactivate\" buttons in Servers tab Delete a resource Navigate to Resources \u2192 click Delete (after confirming) <p>All actions are reflected in the live API via <code>/tools</code>, <code>/prompts</code>, etc.</p>"},{"location":"overview/ui/#auth-jwt-from-ui","title":"\ud83d\udd10 Auth + JWT from UI","text":"<p>Upon successful login, the UI automatically sets a secure JWT token as an HTTP-only cookie (<code>jwt_token</code>).</p> <p>This token is reused for all Admin API calls from within the UI.</p>"},{"location":"overview/ui/#live-reloading-dev-only","title":"\ud83d\udd04 Live Reloading (Dev Only)","text":"<p>If running in development mode (<code>DEV_MODE=true</code> or <code>make run</code>), changes to templates and routes reload automatically.</p>"},{"location":"testing/","title":"\ud83e\uddea Testing MCP Gateway","text":"<p>This section contains guides for testing your MCP Gateway deployment.</p>"},{"location":"testing/#basic-smoke-test","title":"\ud83d\udd39 Basic Smoke Test","text":"<p>Use the Basic Smoke Test to verify:</p> <ul> <li>JWT token generation and authentication</li> <li>Gateway registration</li> <li>Tool registration</li> <li>Server creation and event streaming</li> <li>Tool invocation via JSON-RPC</li> </ul> <p>This test is ideal for validating local development environments or freshly deployed test instances.</p> <p>For additional scenarios (e.g., completion APIs, multi-hop toolchains), expand the test suite as needed.</p>"},{"location":"testing/basic/","title":"MCP Gateway - Basic","text":"<p>Test script for MCP Gateway development environments. Verifies API readiness, JWT auth, Gateway/Tool/Server lifecycle, and RPC invocation.</p>"},{"location":"testing/basic/#environment-setup","title":"\ud83d\udd27 Environment Setup","text":""},{"location":"testing/basic/#0-bootstrap-env","title":"0. Bootstrap <code>.env</code>","text":"<pre><code>cp .env.example .env\n</code></pre>"},{"location":"testing/basic/#1-start-the-gateway","title":"1. Start the Gateway","text":"<pre><code>make podman podman-run-ssl\n# or\nmake venv install serve-ssl\n</code></pre> <p>Gateway will listen on:</p> <ul> <li>Admin UI \u2192 https://localhost:4444/admin</li> <li>Swagger   \u2192 https://localhost:4444/docs</li> <li>ReDoc     \u2192 https://localhost:4444/redoc</li> </ul>"},{"location":"testing/basic/#authentication","title":"\ud83d\udd11 Authentication","text":""},{"location":"testing/basic/#2-generate-and-export-tokens","title":"2. Generate and export tokens","text":""},{"location":"testing/basic/#gateway-jwt-for-local-api-access","title":"Gateway JWT (for local API access)","text":"<pre><code>export MCPGATEWAY_BEARER_TOKEN=$(python -m mcpgateway.utils.create_jwt_token -u admin)\ncurl -s -k -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" https://localhost:4444/health\n</code></pre> <p>Expected: <code>{\"status\":\"ok\"}</code></p>"},{"location":"testing/basic/#remote-gateway-token-peer","title":"Remote gateway token (peer)","text":"<pre><code>export MY_MCP_TOKEN=\"sse-bearer-token-here...\"\n</code></pre>"},{"location":"testing/basic/#optional-local-test-server-token-github-mcp-server","title":"Optional: local test server token (GitHub MCP server)","text":"<pre><code>export LOCAL_MCP_URL=\"http://localhost:8000/sse\"\nexport LOCAL_MCP_TOOL_URL=\"http://localhost:9000/rpc\"\n</code></pre>"},{"location":"testing/basic/#3-set-convenience-variables","title":"3. Set convenience variables","text":"<pre><code>export BASE_URL=\"https://localhost:4444\"\nexport AUTH_HEADER=\"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\"\nexport JSON=\"Content-Type: application/json\"\n</code></pre>"},{"location":"testing/basic/#smoke-tests","title":"\ud83e\uddea Smoke Tests","text":""},{"location":"testing/basic/#4-ping-json-rpc-system","title":"4. Ping JSON-RPC system","text":"<pre><code>curl -s -k -X POST $BASE_URL/protocol/ping \\\n  -H \"$AUTH_HEADER\" -H \"$JSON\" \\\n  -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"ping\"}'\n</code></pre> <p>Expected:</p> <pre><code>{\"jsonrpc\":\"2.0\",\"id\":1,\"result\":{}}\n</code></pre>"},{"location":"testing/basic/#5-add-a-peer-gateway","title":"5. Add a Peer Gateway","text":"<pre><code>curl -s -k -X POST $BASE_URL/gateways \\\n  -H \"$AUTH_HEADER\" -H \"$JSON\" \\\n  -d '{\n        \"name\": \"my-mcp\",\n        \"url\": \"https://link-to-remote-mcp-server/sse\",\n        \"description\": \"My MCP Servers\",\n        \"auth_type\": \"bearer\",\n        \"auth_token\": \"'\"$MY_MCP_TOKEN\"'\"\n      }'\n</code></pre> <p>List gateways:</p> <pre><code>curl -s -k -H \"$AUTH_HEADER\" $BASE_URL/gateways\n</code></pre>"},{"location":"testing/basic/#6-add-a-tool","title":"6. Add a Tool","text":"<pre><code>curl -s -k -X POST $BASE_URL/tools \\\n  -H \"$AUTH_HEADER\" -H \"$JSON\" \\\n  -d '{\n        \"name\": \"clock_tool\",\n        \"url\": \"'\"$LOCAL_MCP_TOOL_URL\"'\",\n        \"description\": \"Returns current time\",\n        \"request_type\": \"POST\",\n        \"integration_type\": \"MCP\",\n        \"input_schema\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"timezone\": { \"type\": \"string\" }\n          }\n        }\n      }'\n</code></pre>"},{"location":"testing/basic/#7-create-a-virtual-server","title":"7. Create a Virtual Server","text":"<pre><code>curl -s -k -X POST $BASE_URL/servers/ \\\n  -H \"$AUTH_HEADER\" -H \"$JSON\" -H 'accept: application/json' \\\n  -d '{\n        \"name\": \"demo-server\",\n        \"description\": \"Smoke-test virtual server\",\n        \"icon\": \"https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png\",\n        \"associatedTools\": [\"1\"],\n        \"associatedResources\": [],\n        \"associatedPrompts\": []\n      }'\n</code></pre> <p>Expected:</p> <pre><code>{\n  \"id\": 2,\n  \"name\": \"demo-server\",\n  \"description\": \"Smoke-test virtual server\",\n  \"icon\": \"https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png\",\n  \"createdAt\": \"2025-05-28T04:28:38.554558\",\n  \"updatedAt\": \"2025-05-28T04:28:38.554564\",\n  \"isActive\": true,\n  \"associatedTools\": [\n    1\n  ],\n  \"associatedResources\": [],\n  \"associatedPrompts\": [],\n  \"metrics\": {\n    \"totalExecutions\": 0,\n    \"successfulExecutions\": 0,\n    \"failedExecutions\": 0,\n    \"failureRate\": 0,\n    \"minResponseTime\": null,\n    \"maxResponseTime\": null,\n    \"avgResponseTime\": null,\n    \"lastExecutionTime\": null\n  }\n}\n</code></pre> <p>Check:</p> <pre><code>curl -s -k -H \"$AUTH_HEADER\" $BASE_URL/servers | jq\n</code></pre>"},{"location":"testing/basic/#8-open-an-sse-stream","title":"8. Open an SSE stream","text":"<pre><code>curl -s -k -N -H \"$AUTH_HEADER\" $BASE_URL/servers/1/sse\n</code></pre> <p>Leave running - real-time events appear here.</p>"},{"location":"testing/basic/#9-invoke-the-tool-via-rpc","title":"9. Invoke the Tool via RPC","text":"<pre><code>curl -s -k -X POST $BASE_URL/rpc \\\n  -H \"$AUTH_HEADER\" -H \"$JSON\" \\\n  -d '{\n        \"jsonrpc\": \"2.0\",\n        \"id\": 99,\n        \"method\": \"get_current_time\",\n        \"params\": {\n          \"timezone\": \"Europe/Dublin\"\n        }\n      }'\n</code></pre> <p>Expected:</p> <pre><code>{\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": \"{\\n  \\\"timezone\\\": \\\"Europe/Dublin\\\",\\n  \\\"datetime\\\": \\\"2025-05-28T05:24:13+01:00\\\",\\n  \\\"is_dst\\\": true\\n}\"\n    }\n  ],\n  \"is_error\": false\n}\n</code></pre>"},{"location":"testing/basic/#10-connect-to-github-mcp-tools-via-supergateway","title":"10. Connect to GitHub MCP Tools via SuperGateway","text":"<p>You can test the Gateway against GitHub's official <code>mcp-server-git</code> tool using <code>supergateway</code>.</p> <p>Start a temporary SSE wrapper around the GitHub MCP server:</p> <pre><code>npx -y supergateway --stdio \"uvx run mcp-server-git\"\n</code></pre> <p>This starts:</p> <ul> <li>SSE endpoint: <code>http://localhost:8000/sse</code></li> <li>Message POST: <code>http://localhost:8000/message</code></li> </ul> <p>To register it with the MCP Gateway:</p> <pre><code>export MY_MCP_TOKEN=\"optional-auth-header-if-needed\"\n\ncurl -s -k -X POST $BASE_URL/gateways \\\n  -H \"$AUTH_HEADER\" -H \"$JSON\" \\\n  -d '{\n        \"name\": \"github-mcp\",\n        \"url\": \"http://localhost:8000/sse\",\n        \"description\": \"GitHub MCP Tools via SuperGateway\",\n        \"auth_type\": \"none\"\n      }'\n</code></pre> <p>This gives you access to GitHub's MCP tools like <code>get_repo_issues</code>, <code>get_pull_requests</code>, etc.</p>"},{"location":"testing/basic/#11-development-testing-with-mcp-inspector","title":"11. Development Testing with MCP Inspector","text":"<p>Launch a visual inspector to interactively test your Gateway:</p> <pre><code>npx @modelcontextprotocol/inspector\n</code></pre> <p>Once launched at http://localhost:5173:</p> <ol> <li>Click \"Add Server\"</li> <li>Use the URL for your virtual server's SSE stream:</li> </ol> <pre><code>http://localhost:4444/servers/1/sse\n</code></pre> <ol> <li>Add this header:</li> </ol> <pre><code>{\n  \"Authorization\": \"Bearer &lt;your-jwt-token&gt;\"\n}\n</code></pre> <ol> <li>Save and test tool invocations by selecting a tool and sending sample input:</li> </ol> <pre><code>{ \"timezone\": \"Europe/Dublin\" }\n</code></pre>"},{"location":"testing/basic/#cleanup","title":"\ud83e\uddf9 Cleanup","text":"<pre><code>curl -s -k -X DELETE -H \"$AUTH_HEADER\" $BASE_URL/servers/1\ncurl -s -k -X DELETE -H \"$AUTH_HEADER\" $BASE_URL/tools/1\ncurl -s -k -X DELETE -H \"$AUTH_HEADER\" $BASE_URL/gateways/1\n</code></pre>"},{"location":"testing/basic/#summary","title":"\u2705 Summary","text":"<p>This smoke test validates:</p> <ul> <li>\u2705 Gateway JWT auth</li> <li>\u2705 Peer Gateway registration with remote bearer</li> <li>\u2705 Tool registration and RPC wiring</li> <li>\u2705 Virtual server creation</li> <li>\u2705 SSE subscription and live messaging</li> <li>\u2705 JSON-RPC invocation flow</li> <li>\u2705 Connecting MCP Inspector to the MCP Gateway</li> <li>\u2705 Connecting the official GitHub MCP server to the Gateway</li> </ul>"},{"location":"using/","title":"Using MCP Gateway","text":"<p>This section focuses on how to use MCP Gateway effectively as a developer, integrator, or end user.</p>"},{"location":"using/#typical-use-cases","title":"\ud83d\udc68\u200d\ud83d\udcbb Typical Use Cases","text":"<ul> <li>You want to expose tools, prompts, or resources via MCP.</li> <li>You want to use <code>mcpgateway-wrapper</code> to connect to any MCP Gateway service using <code>stdio</code>, while still supporting authentication to the gateway.</li> <li>You're building a client or agent framework that speaks the MCP protocol.</li> <li>You want to consume Gateway APIs from an LLM agent, browser app, or CLI tool.</li> </ul>"},{"location":"using/#what-youll-find-in-this-section","title":"\ud83d\udcda What You'll Find in This Section","text":"Page Description mcpgateway-wrapper Wrap CLI tools or subprocesses to expose them via SSE/stdio Clients Compatible UIs and developer tools Agents LangChain, LangGraph, CrewAI, and other frameworks"},{"location":"using/#authentication-reminder","title":"\ud83d\udd11 Authentication Reminder","text":"<p>All Gateway usage requires authentication unless <code>AUTH_REQUIRED=false</code>. Refer to:</p> <pre><code>curl -H \"Authorization: Bearer $TOKEN\" http://localhost:4444/tools\n</code></pre> <p>Or use Basic Auth for the Admin UI and <code>/admin</code> routes.</p>"},{"location":"using/mcpgateway-wrapper/","title":"STDIO Wrapper","text":"<p><code>mcpgateway-wrapper</code> acts as a lightweight MCP-compatible stdio server that dynamically mirrors tools from a live MCP Gateway. It allows any client that supports the MCP protocol \u2014 such as Claude Desktop, Cline, or Continue \u2014 to invoke tools directly via the Gateway.</p>"},{"location":"using/mcpgateway-wrapper/#key-features","title":"\ud83d\udd11 Key Features","text":"<ul> <li> <p>Dynamic Tool Access   Automatically fetches all tools from a given MCP Gateway server catalog in real time.</p> </li> <li> <p>Centralized Gateway Integration   Exposes all tools managed by your MCP Gateway under a single stdio-compatible interface.</p> </li> <li> <p>Full MCP Protocol Support   Responds to <code>initialize</code>, <code>ping</code>, <code>notify</code>, <code>complete</code>, and <code>createMessage</code> via stdio transport.</p> </li> <li> <p>Tool Invocation   All tool calls are proxied to the Gateway's tool registry via HTTP.</p> </li> <li> <p>Extensible   Future support for Prompts and Resources is planned.</p> </li> </ul>"},{"location":"using/mcpgateway-wrapper/#components","title":"\u2699\ufe0f Components","text":""},{"location":"using/mcpgateway-wrapper/#tools","title":"\u2705 Tools","text":"<p>Fetched from the configured server catalog (<code>/servers/{id}</code>) and exposed dynamically.</p>"},{"location":"using/mcpgateway-wrapper/#resources-coming-soon","title":"\ud83d\udea7 Resources (Coming Soon)","text":"<p>Will mirror resources registered on the Gateway.</p>"},{"location":"using/mcpgateway-wrapper/#prompts-coming-soon","title":"\ud83d\udea7 Prompts (Coming Soon)","text":"<p>Will fetch and expose prompt templates via the MCP interface.</p>"},{"location":"using/mcpgateway-wrapper/#quickstart","title":"\ud83d\ude80 Quickstart","text":""},{"location":"using/mcpgateway-wrapper/#1-change-to-the-wrapper-directory","title":"1. Change to the wrapper directory","text":"<pre><code>cd mcpgateway-wrapper\n</code></pre>"},{"location":"using/mcpgateway-wrapper/#2-integrate-with-claude-desktop","title":"2. Integrate with Claude Desktop","text":"<p>On macOS:</p> <pre><code>~/Library/Application Support/Claude/claude_desktop_config.json\n</code></pre> <p>On Windows:</p> <pre><code>%APPDATA%/Claude/claude_desktop_config.json\n</code></pre> <p>Add a new server block:</p> <pre><code>\"mcpServers\": {\n  \"mcpgateway-wrapper\": {\n    \"command\": \"uv\",\n    \"args\": [\n      \"--directory\",\n      \"path-to-mcpgateway-wrapper\",\n      \"run\",\n      \"mcpgateway-wrapper\"\n    ],\n    \"env\": {\n      \"MCP_GATEWAY_BASE_URL\": \"http://localhost:4444\",\n      \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/2\",\n      \"MCP_AUTH_USER\": \"admin\",\n      \"MCP_AUTH_PASS\": \"changeme\"\n    }\n  }\n}\n</code></pre> <p>Replace <code>path-to-mcpgateway-wrapper</code> with the actual folder path.</p>"},{"location":"using/mcpgateway-wrapper/#environment-variables","title":"\u2705 Environment Variables","text":"Variable Purpose <code>MCP_GATEWAY_BASE_URL</code> Base URL to your MCP Gateway (e.g. localhost:4444) <code>MCP_SERVER_CATALOG_URLS</code> One or more <code>/servers/{id}</code> catalog URLs <code>MCP_AUTH_USER</code> Username for HTTP Basic authentication <code>MCP_AUTH_PASS</code> Password for HTTP Basic authentication"},{"location":"using/mcpgateway-wrapper/#local-development","title":"\ud83d\udc0d Local Development","text":"<p>To run locally:</p> <pre><code>uv run mcpgateway-wrapper\n</code></pre> <p>Or debug using the MCP Inspector:</p> <pre><code>npx @modelcontextprotocol/inspector uv --directory \"path-to-wrapper\" run mcpgateway-wrapper\n</code></pre>"},{"location":"using/mcpgateway-wrapper/#build","title":"\ud83c\udfd7 Build","text":"<p>Use <code>uv</code> to manage builds:</p> <pre><code>uv sync       # Install dependencies\n</code></pre>"},{"location":"using/mcpgateway-wrapper/#example-use-case","title":"\ud83d\udcdd Example Use Case","text":"<p>Once launched, any MCP-compatible client (e.g. Claude Desktop or Cline) can call:</p> <pre><code>{\n  \"method\": \"hello_world\",\n  \"params\": { \"name\": \"Alice\" }\n}\n</code></pre> <p>And the wrapper will:</p> <ol> <li>Match the method to a tool in the Gateway's registry</li> <li>Send a tool invocation request to the Gateway</li> <li>Return the result via stdout</li> </ol>"},{"location":"using/mcpgateway-wrapper/#planned-features","title":"\ud83d\udd2e Planned Features","text":"<ul> <li>Prompt rendering support</li> <li>Resource URI fetching</li> <li>Token caching for long-lived auth</li> <li>Federation fallback if the Gateway is unreachable</li> </ul>"},{"location":"using/agents/","title":"Agent Integrations","text":"<p>This section provides guidance on integrating various AI agent frameworks with the Model Context Protocol (MCP) Gateway. MCP enables agents to dynamically discover and utilize tools across multiple servers, enhancing their capabilities and flexibility.</p>"},{"location":"using/agents/#supported-agent-frameworks","title":"\ud83e\udde0 Supported Agent Frameworks","text":"<ul> <li>LangChain: Utilize MCP tools within LangChain agents using the <code>langchain-mcp-adapters</code> package.</li> <li>LangGraph: Integrate MCP tools into LangGraph agents for advanced workflow orchestration.</li> <li>CrewAI: Connect CrewAI agents to MCP servers using the <code>crewai-tools</code> library.</li> <li>Bee Agent Framework: Leverage MCP tools within the Bee Agent Framework for scalable agent deployments.</li> <li>AutoGen: Integrate MCP tools with AutoGen agents using the <code>autogen-ext-mcp</code> package.</li> <li>LlamaIndex: Incorporate MCP tools into LlamaIndex workflows for enhanced data retrieval and question answering.</li> <li>OpenAI Agents SDK: Utilize MCP tools within OpenAI's Agents SDK for building AI agents with standardized tool access.</li> <li>Semantic Kernel: Connect Semantic Kernel agents to MCP servers for enriched context and tool integration.</li> </ul>"},{"location":"using/agents/#overview","title":"\ud83d\udd0d Overview","text":"<p>Each integration guide includes:</p> <ul> <li>Installation Instructions: Step-by-step setup for the respective agent framework.</li> <li>Configuration Details: How to connect the agent to the MCP Gateway, including authentication and transport options.</li> <li>Usage Examples: Sample code demonstrating how to invoke MCP tools within the agent's workflow.</li> <li>Additional Resources: Links to official documentation and repositories for further reference.</li> </ul>"},{"location":"using/agents/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>Model Context Protocol Overview</li> <li>MCP Gateway Documentation</li> </ul>"},{"location":"using/agents/autogen/","title":"AutoGen Integration with MCP Gateway","text":"<p>AutoGen is an open-source framework from Microsoft for building multi-agent systems. It supports tool calling and dynamic agent coordination.</p>"},{"location":"using/agents/autogen/#mcp-support","title":"\ud83d\udd27 MCP Support","text":"<p>Experimental support for MCP integration is available via custom <code>ToolAgent</code> wrappers that call MCP tools via HTTP or <code>mcpgateway-wrapper</code>.</p> <p>A full guide is coming soon. For now, you can use <code>requests</code> or <code>httpx</code> to call MCP Gateway endpoints from AutoGen agents.</p>"},{"location":"using/agents/autogen/#resources","title":"\ud83d\udd17 Resources","text":"<ul> <li>AutoGen GitHub</li> <li>AutoGen Docs</li> </ul>"},{"location":"using/agents/bee/","title":"Bee Agent Framework Integration with MCP Gateway","text":"<p>The Bee Agent Framework is an open-source platform developed by IBM for building, deploying, and managing AI agents at scale. Integrating Bee with the Model Context Protocol (MCP) allows agents to dynamically discover and utilize tools hosted on MCP servers, enhancing their capabilities and flexibility.</p>"},{"location":"using/agents/bee/#key-features","title":"\ud83e\uddf0 Key Features","text":"<ul> <li>Dynamic Tool Discovery: Agents can fetch available tools from MCP servers in real-time.</li> <li>Standardized Communication: Utilizes the open MCP standard for consistent tool integration.</li> <li>Multi-Server Support: Interact with tools defined on multiple MCP servers simultaneously.</li> <li>Human-in-the-Loop: Incorporate human feedback into agent workflows for improved decision-making.</li> </ul>"},{"location":"using/agents/bee/#installation","title":"\ud83d\udee0 Installation","text":"<p>To use MCP tools in the Bee Agent Framework, follow these steps:</p> <ol> <li>Clone the Bee Agent Framework Repository:</li> </ol> <p><code>bash    git clone https://github.com/i-am-bee/bee-agent-framework.git    cd bee-agent-framework</code></p> <ol> <li>Install Dependencies:</li> </ol> <pre><code>yarn install\n</code></pre> <ol> <li>Set Up the Environment:</li> </ol> <p>Ensure you have Node.js and Yarn installed. You may also need to set environment variables for your MCP server:</p> <pre><code>export MCP_GATEWAY_BASE_URL=http://localhost:4444\nexport MCP_AUTH_USER=admin\nexport MCP_AUTH_PASS=changeme\n</code></pre>"},{"location":"using/agents/bee/#connecting-to-mcp-gateway","title":"\ud83d\udd17 Connecting to MCP Gateway","text":"<p>Bee provides a native <code>MCPTool</code> class to simplify integration with MCP servers. Here's how to set it up:</p> <ol> <li>Import the MCPTool Class:</li> </ol> <pre><code>import { MCPTool } from 'bee-agent-framework/tools/mcp';\n</code></pre> <ol> <li>Configure the MCPTool:</li> </ol> <pre><code>const mcpTool = new MCPTool({\n  baseUrl: process.env.MCP_GATEWAY_BASE_URL,\n  auth: {\n    username: process.env.MCP_AUTH_USER,\n    password: process.env.MCP_AUTH_PASS,\n  },\n});\n</code></pre> <ol> <li>Register the Tool with Your Agent:</li> </ol> <pre><code>agent.registerTool(mcpTool);\n</code></pre> <p>This setup allows your Bee agent to discover and invoke tools from the specified MCP server dynamically.</p>"},{"location":"using/agents/bee/#creating-an-agent","title":"\ud83e\udd16 Creating an Agent","text":"<p>After setting up the MCPTool, you can create a Bee agent:</p> <pre><code>import { Agent } from 'bee-agent-framework';\n\nconst agent = new Agent({\n  name: 'Data Analyst',\n  tools: [mcpTool],\n});\n</code></pre>"},{"location":"using/agents/bee/#using-the-agent","title":"\ud83e\uddea Using the Agent","text":"<p>Once the agent is created, you can assign tasks and execute them:</p> <pre><code>agent.runTask('Generate a sales report for Q1 2025');\n</code></pre> <p>The agent will utilize tools from the MCP server to accomplish the task.</p>"},{"location":"using/agents/bee/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>Bee Agent Framework Documentation</li> <li>Bee Agent Framework GitHub Repository</li> <li>Model Context Protocol Overview</li> </ul>"},{"location":"using/agents/crewai/","title":"CrewAI Integration with MCP Gateway","text":"<p>CrewAI is a multi-agent orchestration framework that enables AI agents to collaborate on complex tasks. Integrating CrewAI with the Model Context Protocol (MCP) allows agents to dynamically discover and utilize tools hosted on MCP servers, enhancing their capabilities and flexibility.</p>"},{"location":"using/agents/crewai/#key-features","title":"\ud83e\uddf0 Key Features","text":"<ul> <li>Dynamic Tool Discovery: Agents can fetch available tools from MCP servers in real-time.</li> <li>Standardized Communication: Utilizes the open MCP standard for consistent tool integration.</li> <li>Multi-Server Support: Interact with tools defined on multiple MCP servers simultaneously.</li> </ul>"},{"location":"using/agents/crewai/#installation","title":"\ud83d\udee0 Installation","text":"<p>To use MCP tools in CrewAI, install the <code>crewai-tools</code> package with MCP support:</p> <p>```bash pip install \"crewai-tools[mcp]\"</p>"},{"location":"using/agents/langchain/","title":"LangChain Integration with MCP Gateway","text":"<p>LangChain is a framework for developing applications powered by language models. Integrating LangChain with the Model Context Protocol (MCP) allows agents to utilize tools defined across one or more MCP servers, enabling seamless interaction with external data sources and services.</p>"},{"location":"using/agents/langchain/#key-features","title":"\ud83e\uddf0 Key Features","text":"<ul> <li>Dynamic Tool Access: Connects to MCP servers to fetch available tools in real time.</li> <li>Multi-Server Support: Interact with tools defined on multiple MCP servers simultaneously.</li> <li>Standardized Communication: Utilizes the open MCP standard for consistent tool integration.</li> </ul>"},{"location":"using/agents/langchain/#installation","title":"\ud83d\udee0 Installation","text":"<p>To use MCP tools in LangChain, install the <code>langchain-mcp-adapters</code> package:</p> <pre><code>pip install langchain-mcp-adapters\n</code></pre>"},{"location":"using/agents/langchain/#connecting-to-mcp-gateway","title":"\ud83d\udd17 Connecting to MCP Gateway","text":"<p>Here's how to set up a connection to your MCP Gateway:</p> <pre><code>from langchain_mcp_adapters.client import MultiServerMCPClient\nfrom langgraph.prebuilt import create_react_agent\n\nclient = MultiServerMCPClient(\n    {\n        \"gateway\": {\n            \"url\": \"http://localhost:4444/mcp\",\n            \"transport\": \"streamable_http\",\n        }\n    }\n)\n</code></pre> <p>Replace <code>\"http://localhost:4444/mcp\"</code> with the URL of your MCP Gateway.</p>"},{"location":"using/agents/langchain/#creating-an-agent","title":"\ud83e\udd16 Creating an Agent","text":"<p>After setting up the client, you can create a LangChain agent:</p> <pre><code>agent = create_react_agent(\n    tools=client.get_tools(),\n    llm=your_language_model,\n)\n</code></pre> <p>Replace <code>your_language_model</code> with your configured language model instance.</p>"},{"location":"using/agents/langchain/#using-the-agent","title":"\ud83e\uddea Using the Agent","text":"<p>Once the agent is created, you can use it to perform tasks:</p> <pre><code>response = agent.run(\"Use the 'weather' tool to get the forecast for Dublin.\")\nprint(response)\n</code></pre>"},{"location":"using/agents/langchain/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>LangChain MCP Adapters Documentation</li> <li>LangChain GitHub Repository</li> <li>Model Context Protocol Overview</li> </ul>"},{"location":"using/agents/langgraph/","title":"LangGraph Integration with MCP Gateway","text":"<p>LangGraph is a framework for developing applications powered by language models. Integrating LangGraph with the Model Context Protocol (MCP) allows agents to utilize tools defined across one or more MCP servers, enabling seamless interaction with external data sources and services.</p>"},{"location":"using/agents/langgraph/#key-features","title":"\ud83e\uddf0 Key Features","text":"<ul> <li>Dynamic Tool Access: Connects to MCP servers to fetch available tools in real time.</li> <li>Multi-Server Support: Interact with tools defined on multiple MCP servers simultaneously.</li> <li>Standardized Communication: Utilizes the open MCP standard for consistent tool integration.</li> </ul>"},{"location":"using/agents/langgraph/#installation","title":"\ud83d\udee0 Installation","text":"<p>To use MCP tools in LangGraph, install the <code>langchain-mcp-adapters</code> package:</p> <pre><code>pip install langchain-mcp-adapters\n</code></pre>"},{"location":"using/agents/langgraph/#connecting-to-mcp-gateway","title":"\ud83d\udd17 Connecting to MCP Gateway","text":"<p>Here's how to set up a connection to your MCP Gateway:</p> <pre><code>from langchain_mcp_adapters.client import MultiServerMCPClient\nfrom langgraph.prebuilt import create_react_agent\n\nclient = MultiServerMCPClient(\n    {\n        \"gateway\": {\n            \"url\": \"http://localhost:4444/mcp\",\n            \"transport\": \"streamable_http\",\n        }\n    }\n)\n</code></pre> <p>Replace <code>\"http://localhost:4444/mcp\"</code> with the URL of your MCP Gateway.</p>"},{"location":"using/agents/langgraph/#creating-an-agent","title":"\ud83e\udd16 Creating an Agent","text":"<p>After setting up the client, you can create a LangGraph agent:</p> <pre><code>agent = create_react_agent(\n    tools=client.get_tools(),\n    llm=your_language_model,\n)\n</code></pre> <p>Replace <code>your_language_model</code> with your configured language model instance.</p>"},{"location":"using/agents/langgraph/#using-the-agent","title":"\ud83e\uddea Using the Agent","text":"<p>Once the agent is created, you can use it to perform tasks:</p> <pre><code>response = agent.run(\"Use the 'weather' tool to get the forecast for Dublin.\")\nprint(response)\n</code></pre>"},{"location":"using/agents/langgraph/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>LangGraph MCP Integration Documentation</li> <li>LangChain MCP Adapters GitHub Repository</li> <li>Model Context Protocol Overview</li> </ul>"},{"location":"using/agents/llamaindex/","title":"LlamaIndex Integration with MCP Gateway","text":"<p>LlamaIndex is a framework for building retrieval-augmented generation (RAG) pipelines.</p>"},{"location":"using/agents/llamaindex/#mcp-support","title":"\ud83d\udd27 MCP Support","text":"<p>You can wrap tool calls from MCP Gateway as query engines, retrievers, or tool nodes inside LlamaIndex.</p> <p>A dedicated <code>ToolRetriever</code> adapter is under development to support direct MCP tool discovery.</p>"},{"location":"using/agents/openai-sdk/","title":"OpenAI Agents SDK + MCP Gateway","text":"<p>OpenAI's Agents SDK supports structured tool use and multi-modal workflows. MCP Gateway can serve as a unified tool registry for OpenAI agents.</p>"},{"location":"using/agents/openai-sdk/#integration","title":"\ud83d\udd27 Integration","text":"<p>OpenAI SDK has native support for MCP.</p>"},{"location":"using/agents/openai-sdk/#resources","title":"\ud83d\udd17 Resources","text":"<ul> <li>OpenAI Agents SDK</li> <li>MCP Tool Protocol</li> </ul>"},{"location":"using/agents/semantic-kernel/","title":"Semantic Kernel Integration with MCP Gateway","text":"<p>Semantic Kernel is a Microsoft OSS framework for building AI-first apps.</p>"},{"location":"using/agents/semantic-kernel/#mcp-integration","title":"\ud83d\udd27 MCP Integration","text":"<p>Support for external tools via REST allows you to call MCP tools from SK plugins using <code>HttpFunction</code>.</p> <p>Define a plugin that points to MCP Gateway's <code>/tools/invoke</code> and pass arguments as JSON.</p>"},{"location":"using/agents/semantic-kernel/#resources","title":"\ud83d\udd17 Resources","text":"<ul> <li>Semantic Kernel GitHub</li> <li>Using REST APIs in SK</li> </ul>"},{"location":"using/clients/","title":"MCP Clients","text":"<p>MCP Gateway is compatible with any client that speaks the Model Context Protocol (MCP). This section documents tested clients, their configuration, and any integration tips.</p>"},{"location":"using/clients/#client-types","title":"\ud83d\udd0c Client Types","text":"<p>There are two ways clients typically connect:</p> <ul> <li>Direct to Gateway (HTTP/SSE/WS)</li> <li>Via <code>mcpgateway-wrapper</code> (stdio transport, especially for LLM apps)</li> </ul>"},{"location":"using/clients/#compatible-clients","title":"\u2705 Compatible Clients","text":"Client Type Notes Claude Desktop UI Configure to launch <code>mcpgateway-wrapper</code> via JSON Cline CLI Supports stdio or direct MCP over HTTP Continue VSCode plugin MCP plugin support MCP Inspector Web debugger Great for manual testing and exploring protocol features <p>Each of these tools can consume the MCP protocol and dynamically detect tools from the Gateway.</p>"},{"location":"using/clients/#whats-in-this-section","title":"\ud83d\udcc1 What's in This Section","text":"Page Description Claude Desktop How to connect Claude to MCP Gateway via wrapper Cline Using the CLI tool for invoking tools or prompts Continue Integrating with the VSCode plugin MCP Inspector Launch and test the Gateway or wrapper via a web debugger"},{"location":"using/clients/claude-desktop/","title":"Claude Desktop","text":"<p>Claude Desktop is a desktop application that supports MCP integration via stdio. You can configure it to launch <code>mcpgateway-wrapper</code>, enabling Claude to access all tools registered in MCP Gateway.</p>"},{"location":"using/clients/claude-desktop/#where-to-configure","title":"\ud83d\udda5\ufe0f Where to Configure","text":"<p>Depending on your OS, edit the Claude configuration file:</p> <ul> <li> <p>macOS:   <code>~/Library/Application Support/Claude/claude_desktop_config.json</code></p> </li> <li> <p>Windows:   <code>%APPDATA%/Claude/claude_desktop_config.json</code></p> </li> </ul>"},{"location":"using/clients/claude-desktop/#example-configuration","title":"\u2699\ufe0f Example Configuration","text":"<p>Add this block to the <code>\"mcpServers\"</code> section of your config:</p> <pre><code>\"mcpServers\": {\n  \"mcpgateway-wrapper\": {\n    \"command\": \"uv\",\n    \"args\": [\n      \"--directory\",\n      \"/path/to/mcpgateway-wrapper\",\n      \"run\",\n      \"mcpgateway-wrapper\"\n    ],\n    \"env\": {\n      \"MCP_GATEWAY_BASE_URL\": \"http://localhost:4444\",\n      \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/2\",\n      \"MCP_AUTH_USER\": \"admin\",\n      \"MCP_AUTH_PASS\": \"changeme\"\n    }\n  }\n}\n</code></pre> <p>\ud83d\udd01 Adjust <code>path/to/mcpgateway-wrapper</code> and server ID as needed.</p>"},{"location":"using/clients/claude-desktop/#test-it-in-claude","title":"\ud83e\uddea Test it in Claude","text":"<p>Once Claude launches:</p> <ol> <li>Choose the <code>mcpgateway-wrapper</code> backend</li> <li>Type a tool invocation (e.g., <code>weather</code>, <code>hello</code>, etc.)</li> <li>The tool should be fetched from the Gateway and executed dynamically</li> </ol>"},{"location":"using/clients/claude-desktop/#advanced-pre-installed-wrapper-mode","title":"\ud83d\ude80 Advanced: Pre-installed Wrapper Mode","text":"<p>If you've published the wrapper to PyPI or have it globally installed:</p> <pre><code>\"mcpServers\": {\n  \"mcpgateway-wrapper\": {\n    \"command\": \"uvx\",\n    \"args\": [\"mcpgateway-wrapper\"]\n  }\n}\n</code></pre> <p>This assumes your environment variables are managed globally or set in the terminal session launching Claude.</p>"},{"location":"using/clients/cline/","title":"Cline (VS Code Extension)","text":"<p>Cline is a Visual Studio Code extension that brings AI-powered coding assistance directly into your editor. It supports the Model Context Protocol (MCP), enabling seamless integration with MCP-compatible servers like MCP Gateway.</p>"},{"location":"using/clients/cline/#key-features","title":"\ud83e\uddf0 Key Features","text":"<ul> <li>AI-Powered Coding: Leverages advanced AI models (e.g., Claude 3.5 Sonnet, DeepSeek Chat) for code generation, editing, and debugging.</li> <li>MCP Integration: Connects to MCP servers to discover and utilize tools dynamically.</li> <li>Terminal and Browser Access: Executes terminal commands and performs browser operations with user permission.</li> <li>Custom Tools: Supports adding custom tools via MCP for extended functionality.</li> </ul>"},{"location":"using/clients/cline/#installation","title":"\ud83d\udee0 Installation","text":"<ol> <li>Install Cline Extension:</li> <li>Open VS Code.</li> <li>Navigate to the Extensions view (<code>Ctrl+Shift+X</code> or <code>Cmd+Shift+X</code>).</li> <li> <p>Search for \"Cline\" and click \"Install\".</p> </li> <li> <p>Sign In to Cline:</p> </li> <li>Click the Cline icon in the Activity Bar.</li> <li>Follow the prompts to sign in or create a new account at app.cline.bot.</li> <li>New users receive free credits; no credit card required.</li> </ol>"},{"location":"using/clients/cline/#connecting-to-mcp-gateway","title":"\ud83d\udd17 Connecting to MCP Gateway","text":"<p>To integrate Cline with your MCP Gateway:</p> <ol> <li>Configure MCP Server:</li> <li>Open the Cline settings in VS Code.</li> <li>Navigate to the MCP Servers section.</li> <li> <p>Add a new MCP server with the following configuration:</p> <pre><code>{\n  \"name\": \"MCP Gateway\",\n  \"url\": \"http://localhost:4444\",\n  \"auth\": {\n    \"type\": \"basic\",\n    \"username\": \"admin\",\n    \"password\": \"changeme\"\n  }\n}\n</code></pre> </li> <li> <p>Replace the URL, username, and password with your MCP Gateway's details.</p> </li> <li> <p>Enable the MCP Server:</p> </li> <li> <p>Ensure the newly added MCP server is enabled in the Cline settings.</p> </li> <li> <p>Verify Connection:</p> </li> <li>In the Cline interface, navigate to the MCP Servers section.</li> <li>Confirm that the MCP Gateway server is listed and shows a green status indicator.</li> </ol>"},{"location":"using/clients/cline/#using-mcp-tools-in-cline","title":"\ud83e\uddea Using MCP Tools in Cline","text":"<p>Once connected:</p> <ul> <li>Discover Tools: Cline will automatically fetch and list available tools from the MCP Gateway.</li> <li>Invoke Tools: Use natural language prompts in Cline to invoke tools. For example:</li> <li>\"Run the <code>hello_world</code> tool with the argument <code>name: Alice</code>.\"</li> <li>Monitor Responses: Cline will display the tool's output directly within the chat interface.</li> </ul>"},{"location":"using/clients/cline/#tips-for-effective-use","title":"\ud83d\udcdd Tips for Effective Use","text":"<ul> <li>.clinerules File: Create a <code>.clinerules</code> file in your project root to define project-specific behaviors and instructions for Cline.</li> <li>Custom Instructions: Utilize Cline's Custom Instructions feature to tailor its behavior across all projects.</li> <li>Model Selection: Choose the AI model that best fits your project's needs within the Cline settings.</li> </ul>"},{"location":"using/clients/cline/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>Cline Official Website</li> <li>Cline Documentation</li> </ul>"},{"location":"using/clients/continue/","title":"Continue (VS Code Extension)","text":"<p>Continue is an open-source AI code assistant available as a Visual Studio Code extension. It supports the Model Context Protocol (MCP), allowing seamless integration with MCP-compatible servers like MCP Gateway.</p>"},{"location":"using/clients/continue/#key-features","title":"\ud83e\uddf0 Key Features","text":"<ul> <li>AI-Powered Coding: Provides code completions, edits, and chat-based assistance.</li> <li>MCP Integration: Connects to MCP servers to discover and utilize tools dynamically.</li> <li>Customizable Models: Supports various AI models, including local and remote options.</li> <li>Contextual Awareness: Understands your codebase to provide relevant suggestions.</li> </ul>"},{"location":"using/clients/continue/#installation","title":"\ud83d\udee0 Installation","text":"<ol> <li>Install Continue Extension:</li> <li>Open VS Code.</li> <li>Navigate to the Extensions view (<code>Ctrl+Shift+X</code> or <code>Cmd+Shift+X</code>).</li> <li> <p>Search for \"Continue\" and click \"Install\".</p> </li> <li> <p>Configure Continue:</p> </li> <li>Open the Command Palette (<code>Ctrl+Shift+P</code> or <code>Cmd+Shift+P</code>).</li> <li>Select \"Continue: Open Config\".</li> <li>This opens the <code>~/.continue/config.json</code> file.</li> </ol>"},{"location":"using/clients/continue/#connecting-to-mcp-gateway","title":"\ud83d\udd17 Connecting to MCP Gateway","text":"<p>To integrate Continue with your MCP Gateway:</p> <ol> <li>Add MCP Server Configuration:    In your <code>~/.continue/config.json</code>, add the following under the <code>experimental</code> section:</li> </ol> <p><code>json    {      \"experimental\": {        \"modelContextProtocolServer\": {          \"transport\": {            \"type\": \"stdio\",            \"command\": \"uvx\",            \"args\": [\"mcpgateway-wrapper\"]          }        }      }    }</code></p> <p>Replace <code>\"mcpgateway-wrapper\"</code> with the appropriate command or path to your MCP Gateway server if different.</p> <ol> <li> <p>Set Environment Variables:    Ensure the following environment variables are set:</p> </li> <li> <p><code>MCP_GATEWAY_BASE_URL</code>: Base URL of your MCP Gateway (e.g., <code>http://localhost:4444</code>).</p> </li> <li><code>MCP_SERVER_CATALOG_URLS</code>: URL(s) to the server catalog(s) (e.g., <code>http://localhost:4444/servers/2</code>).</li> <li><code>MCP_AUTH_USER</code>: Username for authentication (e.g., <code>admin</code>).</li> <li><code>MCP_AUTH_PASS</code>: Password for authentication (e.g., <code>changeme</code>).</li> </ol> <p>You can set these in your system environment or within the Continue configuration if supported.</p>"},{"location":"using/clients/continue/#using-mcp-tools-in-continue","title":"\ud83e\uddea Using MCP Tools in Continue","text":"<p>Once configured:</p> <ul> <li>Discover Tools: Continue will automatically fetch and list available tools from the MCP Gateway.</li> <li> <p>Invoke Tools: Use natural language prompts in Continue to invoke tools. For example:</p> </li> <li> <p>\"Run the <code>hello_world</code> tool with the argument <code>name: Alice</code>.\"</p> </li> <li>Monitor Responses: Continue will display the tool's output directly within the chat interface.</li> </ul>"},{"location":"using/clients/continue/#tips-for-effective-use","title":"\ud83d\udcdd Tips for Effective Use","text":"<ul> <li>Custom Instructions: Utilize Continue's Custom Instructions feature to tailor its behavior across all projects.</li> <li>Model Selection: Choose the AI model that best fits your project's needs within the Continue settings.</li> <li>.continue/config.json: Customize your Continue experience by editing this configuration file.</li> </ul>"},{"location":"using/clients/continue/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>Continue Official Website</li> <li>Continue Documentation</li> <li>Continue GitHub Repository</li> </ul>"},{"location":"using/clients/copilot/","title":"\ud83e\udde0 Microsoft GitHub Copilot + MCP Gateway","text":"<p>Extend GitHub Copilot's functionality in VS Code by connecting it to your MCP Gateway, enabling powerful tool invocation, resource access, and dynamic integration\u2014all via the Model Context Protocol (MCP).</p> <p>GitHub Copilot can also be configured to use local models via Ollama.</p>"},{"location":"using/clients/copilot/#prerequisites","title":"\ud83d\udee0 Prerequisites","text":"<ul> <li>VS Code \u2265 1.99</li> <li><code>\"chat.mcp.enabled\": true</code> in your VS Code settings</li> <li>MCP Gateway running (via <code>make serve</code> or Docker)</li> <li>Admin JWT or basic credentials to authenticate</li> </ul>"},{"location":"using/clients/copilot/#option-1-sse-direct-http-integration","title":"\ud83d\udd17 Option 1: SSE (Direct HTTP Integration)","text":"<p>For remote or authenticated servers, use the SSE transport in <code>.vscode/mcp.json</code>:</p>"},{"location":"using/clients/copilot/#1-create-the-config-file","title":"1. Create the Config File","text":"<p>Create <code>.vscode/mcp.json</code> in your project root:</p> <pre><code>{\n  \"servers\": {\n    \"mcp\": {\n      \"type\": \"sse\",\n      \"url\": \"https://mcpgateway.domain/servers/1/sse\",\n      \"headers\": {\n        \"Authorization\": \"Bearer &lt;YOUR_JWT_TOKEN&gt;\"\n      }\n    }\n  }\n}\n</code></pre> <p>\ud83d\udca1 You can generate a JWT with:</p> <pre><code>python -m mcpgateway.utils.create_jwt_token -u admin -e 10080 &gt; token.txt\n</code></pre>"},{"location":"using/clients/copilot/#option-2-mcpgateway-wrapper-stdio-integration","title":"\ud83d\udd17 Option 2: <code>mcpgateway-wrapper</code> (STDIO Integration)","text":"<p>If your client (e.g., Copilot) supports stdio-based MCP servers, use <code>mcpgateway-wrapper</code> to expose the Gateway as a local process:</p>"},{"location":"using/clients/copilot/#1-install-the-wrapper","title":"1. Install the Wrapper","text":"<p>Clone or download the <code>mcpgateway-wrapper</code> repository and navigate to it:</p> <pre><code># Clone the repo\ngit clone git@github.com:IBM/mcp-context-forge.git\ncd mcp-context-forge\n\n# Install dependencies and activate the venv\nmake venv install activate\n. ~/.venv/mcpgateway/bin/activate\n\n# Install uvx\npip install uvx\n\ncd mcpgateway-wrapper\n</code></pre>"},{"location":"using/clients/copilot/#2-run-the-wrapper-locally","title":"2. Run the Wrapper Locally","text":"<pre><code>uv run mcpgateway-wrapper\n</code></pre> <p>Or using Inspector for debug:</p> <pre><code>npx @modelcontextprotocol/inspector uv --directory . run mcpgateway-wrapper\n</code></pre>"},{"location":"using/clients/copilot/#3-create-vscodemcpjson","title":"3. Create <code>.vscode/mcp.json</code>","text":"<p>Point Copilot to the local wrapper process:</p> <pre><code>{\n  \"servers\": {\n    \"mcp-wrapper\": {\n      \"type\": \"stdio\",\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"path/to/mcpgateway-wrapper\",\n        \"run\",\n        \"mcpgateway-wrapper\"\n      ],\n      \"env\": {\n        \"MCP_GATEWAY_BASE_URL\": \"http://localhost:4444\",\n        \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/1\",\n        \"MCP_AUTH_USER\": \"admin\",\n        \"MCP_AUTH_PASS\": \"changeme\"\n      }\n    }\n  }\n}\n</code></pre> <p>\u2705 This setup allows Copilot to invoke Gateway-managed tools without HTTP auth headers, ideal for local dev or restrictive environments.</p>"},{"location":"using/clients/copilot/#verifying-tool-access","title":"\ud83e\uddea Verifying Tool Access","text":"<p>After setup:</p> <ol> <li>Open the Copilot chat pane (<code>Ctrl + Shift + i</code>)</li> <li>Switch to Agent Mode</li> <li>Click Tools - tools from your MCP server should appear</li> </ol> <p>Try prompting:</p> <pre><code>#echo { \"message\": \"Hello\" }\n</code></pre> <p>Expected: Copilot invokes the Gateway's <code>echo</code> tool and displays the response.</p>"},{"location":"using/clients/copilot/#tips-for-success","title":"\ud83d\udcdd Tips for Success","text":"<ul> <li>Use SSE for production, stdio for local/CLI workflows</li> <li>Register servers via Admin UI or <code>/admin#catalog</code></li> <li>Use JWTs for secure, headless integration</li> </ul>"},{"location":"using/clients/copilot/#resources","title":"\ud83d\udcda Resources","text":"<ul> <li>MCP Gateway GitHub</li> <li>mcpgateway-wrapper</li> <li>MCP Spec</li> <li>Copilot Docs</li> </ul> <p>Would you like this exported as a Markdown file or added to your MkDocs site?</p>"},{"location":"using/clients/mcp-inspector/","title":"MCP Inspector","text":"<p>MCP Inspector is a visual debugging tool for the Model Context Protocol. It connects to MCP-compliant servers (like <code>mcpgateway-wrapper</code> or MCP Gateway directly) and allows you to:</p> <ul> <li>Inspect available tools</li> <li>Execute tool invocations</li> <li>View the full JSON-RPC/MCP traffic</li> <li>Simulate prompt rendering or resource access (future)</li> </ul>"},{"location":"using/clients/mcp-inspector/#launching-mcp-inspector","title":"\ud83d\ude80 Launching MCP Inspector","text":"<p>If you have Node.js installed, you can launch it via <code>npx</code>:</p> <pre><code>npx @modelcontextprotocol/inspector \\\n  uv --directory path/to/mcpgateway-wrapper \\\n  run mcpgateway-wrapper\n</code></pre> <p>This will:</p> <ul> <li>Start the wrapper</li> <li>Open a local Inspector session in your browser</li> </ul>"},{"location":"using/clients/mcp-inspector/#inspector-features","title":"\ud83d\udd27 Inspector Features","text":"<ul> <li>\ud83d\udcdc View registered tools in real time</li> <li>\ud83e\uddea Send test completions or invocations</li> <li>\ud83d\udc40 Observe request/response JSON as it flows through the system</li> <li>\ud83d\udd01 Replay or modify previous messages</li> <li>\ud83e\uddf5 View sampling messages (when streaming is supported)</li> </ul>"},{"location":"using/clients/mcp-inspector/#auth-config","title":"\ud83d\udd10 Auth &amp; Config","text":"<p>Ensure you provide the necessary <code>MCP_AUTH_USER</code> and <code>MCP_AUTH_PASS</code> as environment variables if your gateway requires authentication:</p> <pre><code>export MCP_GATEWAY_BASE_URL=http://localhost:4444\nexport MCP_SERVER_CATALOG_URLS=http://localhost:4444/servers/2\nexport MCP_AUTH_USER=admin\nexport MCP_AUTH_PASS=changeme\n</code></pre> <p>Then run the Inspector again.</p>"},{"location":"using/clients/mcp-inspector/#connect-to-live-gateway","title":"\ud83c\udf10 Connect to Live Gateway","text":"<p>You can also connect directly to MCP Gateway without the wrapper:</p> <pre><code>npx @modelcontextprotocol/inspector --url http://localhost:4444\n</code></pre> <p>This will query available tools, prompts, and metadata from the root.</p>"},{"location":"using/clients/openwebui/","title":"OpenWebUI Integration with MCP Gateway","text":"<p>OpenWebUI is a self-hosted, extensible interface for interacting with large language models (LLMs). Integrating OpenWebUI with the Model Context Protocol (MCP) allows you to enhance your AI workflows by leveraging tools and resources provided by MCP servers.</p>"},{"location":"using/clients/openwebui/#integration-overview","title":"\ud83d\udd0c Integration Overview","text":"<p>OpenWebUI supports integration with external tools via OpenAPI specifications. MCP Gateway exposes its tools through OpenAPI-compatible endpoints, enabling seamless integration with OpenWebUI.</p>"},{"location":"using/clients/openwebui/#prerequisites","title":"\ud83d\udee0\ufe0f Prerequisites","text":"<ul> <li>OpenWebUI: Ensure you have OpenWebUI installed and running. Refer to the OpenWebUI documentation for installation instructions.</li> <li>MCP Gateway: Set up and run the MCP Gateway. Detailed setup instructions can be found in the MCP Gateway documentation.</li> </ul>"},{"location":"using/clients/openwebui/#connecting-mcp-tools-to-openwebui","title":"\ud83d\udd17 Connecting MCP Tools to OpenWebUI","text":""},{"location":"using/clients/openwebui/#1-launch-mcp-gateway","title":"1. Launch MCP Gateway","text":"<p>Start the MCP Gateway to expose its tools via OpenAPI endpoints. For example:</p> <pre><code>uv run mcpgateway\n</code></pre> <p>Ensure that the MCP Gateway is accessible at a known URL, such as <code>http://localhost:4444</code>.</p>"},{"location":"using/clients/openwebui/#2-identify-mcp-tool-endpoints","title":"2. Identify MCP Tool Endpoints","text":"<p>Determine the specific tool endpoints provided by the MCP Gateway. These endpoints follow the OpenAPI specification and are typically accessible at URLs like:</p> <pre><code>http://localhost:4444/tools/&lt;tool-name&gt;\n</code></pre> <p>Replace <code>&lt;tool-name&gt;</code> with the actual name of the tool you wish to integrate.</p>"},{"location":"using/clients/openwebui/#3-add-mcp-tools-to-openwebui","title":"3. Add MCP Tools to OpenWebUI","text":""},{"location":"using/clients/openwebui/#a-access-openwebui-settings","title":"a. Access OpenWebUI Settings","text":"<ul> <li>Navigate to the OpenWebUI interface in your browser.</li> <li>Click on the \u2699\ufe0f Settings icon.</li> </ul>"},{"location":"using/clients/openwebui/#b-add-a-new-tool-server","title":"b. Add a New Tool Server","text":"<ul> <li>In the Settings menu, locate the Tools section.</li> <li>Click on the \u2795 Add Tool Server button.</li> <li>Enter the URL of the MCP tool endpoint (e.g., <code>http://localhost:4444/tools/&lt;tool-name&gt;</code>).</li> <li>Click Save to register the tool.</li> </ul> <p>Repeat this process for each MCP tool you wish to integrate.</p>"},{"location":"using/clients/openwebui/#using-mcp-tools-in-openwebui","title":"\ud83e\uddea Using MCP Tools in OpenWebUI","text":"<p>Once the MCP tools are registered:</p> <ul> <li>Enable Tools in Chat: In the chat interface, click on the \u2795 icon to view available tools. Toggle the desired MCP tools to enable them for the current session.</li> <li>Invoke Tools: Interact with the AI model as usual. When appropriate, the model will utilize the enabled MCP tools to fulfill your requests.</li> </ul>"},{"location":"using/clients/openwebui/#advanced-configuration","title":"\u2699\ufe0f Advanced Configuration","text":""},{"location":"using/clients/openwebui/#global-tool-servers","title":"Global Tool Servers","text":"<p>To make MCP tools available to all users:</p> <ul> <li>Navigate to Admin Settings &gt; Tools.</li> <li>Add the MCP tool endpoints as described above.</li> <li>These tools will now be accessible to all users, subject to individual activation in their chat sessions.</li> </ul>"},{"location":"using/clients/openwebui/#native-function-calling","title":"Native Function Calling","text":"<p>OpenWebUI supports native function calling for tools:</p> <ul> <li>In the chat interface, go to Chat Controls &gt; Advanced Params.</li> <li>Set the Function Calling parameter to <code>Native</code>.</li> <li>This enables more structured interactions between the AI model and the tools.</li> </ul>"},{"location":"using/clients/openwebui/#additional-resources","title":"\ud83e\uddf0 Additional Resources","text":"<ul> <li>OpenWebUI Documentation</li> <li>MCP Gateway Documentation</li> <li>OpenWebUI GitHub Repository</li> <li>MCP Gateway GitHub Repository</li> </ul> <p>By integrating MCP tools into OpenWebUI, you can enhance your AI assistant's capabilities, enabling it to perform a wider range of tasks by leveraging the diverse tools provided by the MCP ecosystem.</p>"}]}