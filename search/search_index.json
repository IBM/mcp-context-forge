{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"MCP Gateway","text":"<p>A flexible FastAPI-based gateway and router for Model Context Protocol (MCP) with support for virtual servers. It acts as a unified interface for tools, resources, prompts, virtual servers, and federated gateways \u2014 all accessible via rich multi-transport APIs and an interactive web-based Admin UI.</p> <p></p>"},{"location":"#what-it-does","title":"What it Does","text":"<ul> <li>\ud83d\udeaa Acts as a gateway layer in front of MCP servers or APIs</li> <li>\ud83d\udd17 Connects and federates multiple MCP backends (auto-discovery, fail-over, merging)</li> <li>\ud83d\udd04 Virtualizes REST APIs and external MCP servers as compliant tools and servers</li> <li>\ud83d\udee0\ufe0f Centralizes registration and management of tools, prompts, and resources</li> <li>\ud83d\udce1 Exposes all endpoints over HTTP/JSON-RPC, WebSocket, Server-Sent Events (SSE), and stdio</li> <li>\ud83d\udce6 Provides a stdio wrapper (<code>mcpgateway-wrapper</code>) for terminal-based or headless MCP clients</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Multi-Transport: HTTP, WebSocket, SSE, and stdio with auto-negotiation</li> <li>Federation &amp; Health Checks: Auto-discovery (mDNS or static), syncing, monitoring</li> <li>Admin UI: Real-time management (HTMX + Tailwind)</li> <li>Tool Wrapping: REST / CLI / local functions with JSON-Schema validation</li> <li>Security: JWT + Basic Auth, custom headers, rate limits, SSL control</li> <li>Caching &amp; Observability: Redis/in-memory/database caching, metrics, structured logs</li> <li>Virtual Servers: Group tools/resources/prompts into MCP-compliant servers</li> <li>Wrapper Mode: <code>mcpgateway-wrapper</code> turns any remote gateway into a local stdio MCP server</li> </ul> <p>For upcoming capabilities, see the Roadmap.</p> <pre><code>graph TD\n    subgraph UI_and_Auth\n        UI[\ud83d\udda5\ufe0f Admin UI]\n        Auth[\ud83d\udd10 Auth - JWT and Basic]\n        UI --&gt; Core\n        Auth --&gt; Core\n    end\n\n    subgraph Gateway_Core\n        Core[\ud83d\udeaa MCP Gateway Core]\n        Protocol[\ud83d\udce1 Protocol - Init Ping Completion]\n        Federation[\ud83c\udf10 Federation Manager]\n        Transports[\ud83d\udd00 Transports - HTTP WS SSE Stdio]\n        Core --&gt; Protocol\n        Core --&gt; Federation\n        Core --&gt; Transports\n    end\n\n    subgraph Services\n        Tools[\ud83e\uddf0 Tool Service]\n        Resources[\ud83d\udcc1 Resource Service]\n        Prompts[\ud83d\udcdd Prompt Service]\n        Servers[\ud83e\udde9 Server Service]\n        Core --&gt; Tools\n        Core --&gt; Resources\n        Core --&gt; Prompts\n        Core --&gt; Servers\n    end\n\n    subgraph Persistence\n        DB[\ud83d\udcbe Database - SQLAlchemy]\n        Tools --&gt; DB\n        Resources --&gt; DB\n        Prompts --&gt; DB\n        Servers --&gt; DB\n    end\n\n    subgraph Caching\n        Cache[\u26a1 Cache - Redis or Memory]\n        Core --&gt; Cache\n    end</code></pre>"},{"location":"#audience","title":"Audience","text":"<p>MCP Gateway serves:</p> <ul> <li>AI Platform Teams building unified gateways for LLM tools &amp; services</li> <li>DevOps Engineers deploying secure, observable, federated control planes</li> <li>Open-source contributors extending MCP tooling or adapters</li> <li>Cloud Architects running on Kubernetes, IBM Code Engine, AWS, Azure, or bare Docker</li> </ul>"},{"location":"#installation-deployment","title":"Installation &amp; Deployment","text":"Scenario One-liner / CLI Snippet Docs Local (PyPI) <code>pip install mcp-contextforge-gateway &amp;&amp; mcpgateway --host 0.0.0.0 --port 4444</code> Quick Start Docker / Podman <code>docker run -p 4444:4444 ghcr.io/ibm/mcp-context-forge:&lt;tag&gt;</code> Containers Docker-Compose (dev) <code>docker compose up</code> Compose Helm / Vanilla Kubernetes <code>helm repo add mcpgw https://IBM.github.io/mcp-context-forge &amp;&amp; helm install mcpgw mcpgw/mcpgateway</code> Helm Chart Minikube (local k8s) <code>make minikube</code> Minikube Guide OpenShift / OKD <code>oc apply -k openshift/</code> OpenShift Argo CD / GitOps <code>kubectl apply -f argo.yaml</code> Argo CD IBM Cloud \u2013 Code Engine <code>ibmcloud ce app create --name mcpgw --image ghcr.io/ibm/mcp-context-forge:&lt;tag&gt;</code> IBM Code Engine AWS \u2013 ECS (Fargate) <code>aws ecs create-service --cli-input-json file://ecs.json</code> AWS Guide AWS \u2013 EKS (Helm) <code>helm install mcpgw mcpgw/mcpgateway</code> AWS Guide Google Cloud Run <code>gcloud run deploy mcpgw --image ghcr.io/ibm/mcp-context-forge:&lt;tag&gt;</code> GCP Cloud Run Google GKE (Helm) <code>helm install mcpgw mcpgw/mcpgateway</code> GCP Guide Azure \u2013 Container Apps <code>az containerapp up --name mcpgw --image ghcr.io/ibm/mcp-context-forge:&lt;tag&gt;</code> Azure Guide Azure \u2013 AKS (Helm) <code>helm install mcpgw mcpgw/mcpgateway</code> Azure Guide <p>PyPI Package: <code>mcp-contextforge-gateway</code></p> <p>OCI Image: <code>ghcr.io/ibm/mcp-context-forge:0.1.1</code></p>"},{"location":"#get-started","title":"Get Started","text":"<p>Jump straight to:</p> <ul> <li>Quick Start Guide</li> <li>Features Overview</li> <li>Admin UI Walk-through</li> <li>Using the <code>mcpgateway-wrapper</code></li> <li>Deployment Options</li> </ul> <p>Note</p> <p>Source \u2192 IBM/mcp-context-forge Docs \u2192 https://ibm.github.io/mcp-context-forge/</p>"},{"location":"#authors-and-contributors","title":"Authors and Contributors","text":"<ul> <li>Mihai Criveti \u2013 IBM Distinguished Engineer, Agentic AI</li> </ul>"},{"location":"architecture/","title":"Architecture Overview","text":"<p>The MCP Gateway acts as a unified entry point for tools, resources, prompts, and servers, federating local and remote nodes into a coherent MCP-compliant interface.</p> <p>This gateway:</p> <ul> <li>Wraps REST/MCP tools and resources under JSON-RPC and streaming protocols</li> <li>Offers a pluggable backend (cache, auth, storage)</li> <li>Exposes multiple transports (HTTP, WS, SSE, stdio)</li> <li>Automatically discovers and merges federated peers</li> </ul>"},{"location":"architecture/#system-architecture","title":"System Architecture","text":"<pre><code>graph TD\n    subgraph Clients\n        ui[\"Admin UI (Browser)\"]\n        cli[\"CLI Tools\"]\n        sdk[\"SDK / Scripts\"]\n    end\n\n    subgraph Gateway\n        app[\"FastAPI App\"]\n        auth[\"Auth Middleware&lt;br/&gt;(JWT + Basic)\"]\n        router[\"Transport Router&lt;br/&gt;(HTTP / WS / SSE / STDIO)\"]\n        services[\"Service Layer&lt;br/&gt;(Tool / Resource / Prompt / Server)\"]\n        db[\"Async DB&lt;br/&gt;(SQLAlchemy + Alembic)\"]\n        cache[\"Cache Backend&lt;br/&gt;(memory / redis / db)\"]\n        metrics[\"Metrics Exporter&lt;br/&gt;(/metrics Prometheus)\"]\n    end\n\n    subgraph Federation\n        discovery[\"Discovery Service&lt;br/&gt;(DNS-SD + Static Peers)\"]\n        peers[\"Remote Gateways\"]\n    end\n\n    ui --&gt; app\n    cli --&gt; router\n    sdk --&gt; router\n    app --&gt; auth --&gt; router\n    router --&gt; services\n    services --&gt; db\n    services --&gt; cache\n    services --&gt; metrics\n    services --&gt; discovery\n    discovery --&gt; peers\n</code></pre> <p>Each service (ToolService, ResourceService, etc.) operates independently with unified auth/session/context layers.</p>"},{"location":"architecture/#adrs-and-design-decisions","title":"ADRs and Design Decisions","text":"<p>We maintain a formal set of Architecture Decision Records documenting all major design tradeoffs and rationale.</p> <p>\ud83d\udcdc See the full ADR Index \u2192</p>"},{"location":"architecture/roadmap/","title":"Roadmap","text":""},{"location":"architecture/roadmap/#federation-routing","title":"\ud83c\udf10 Federation &amp; Routing","text":""},{"location":"architecture/roadmap/#epic-streamable-http-transport-protocol-revision-2025-03-26","title":"\ud83e\udded Epic: Streamable HTTP Transport (Protocol Revision 2025-03-26)","text":"<p>Note: stdio and the legacy HTTP+SSE transports are already supported; this epic adds the new Streamable HTTP transport per the 2025-03-26 spec.</p> <ul> <li> <p>HTTP POST Messaging As an MCP client   I want to send every JSON-RPC request, notification, or batch in a separate HTTP POST to the MCP endpoint, with <code>Accept: application/json, text/event-stream</code> So that the server can choose between immediate JSON replies or initiating an SSE stream.</p> </li> <li> <p>SSE-Backed Streaming on POST As a developer   I want the server, upon receiving request-bearing POSTs, to return <code>Content-Type: text/event-stream</code> and open an SSE stream\u2014emitting JSON-RPC responses, server-to-client requests, and notifications until complete\u2014before closing the stream   So that clients can consume large or real-time payloads incrementally without buffering.</p> </li> <li> <p>Unsolicited Server Notifications via GET As a client   I want to open an SSE stream with a GET (using <code>Accept: text/event-stream</code>) to the same MCP endpoint   So that I can receive unsolicited server-to-client messages independently of POST calls.</p> </li> <li> <p>Session Management &amp; Resumability As an operator   I want the server to issue a secure <code>Mcp-Session-Id</code> on Initialize, require it on subsequent calls (400 if missing), allow DELETE to terminate, and support SSE resumability via <code>Last-Event-ID</code> headers   So that clients can manage, resume, and explicitly end long-running sessions robustly.</p> </li> <li> <p>Security &amp; Compatibility As a platform admin   I want to validate <code>Origin</code> headers, bind to localhost by default, and enforce authentication against DNS rebinding\u2014while optionally preserving the legacy HTTP+SSE endpoints for backward compatibility with 2024-11-05 clients   So that we uphold security best practices and maintain dual-transport support.</p> </li> </ul>"},{"location":"architecture/roadmap/#federation-routing_1","title":"\ud83c\udf10 Federation &amp; Routing","text":""},{"location":"architecture/roadmap/#epic-a2a-transport-support","title":"\ud83e\udded Epic: A2A Transport Support","text":"<p>Enable full-duplex, application-to-application (A2A) integration so that virtual servers and gateways can speak A2A natively.</p> <ul> <li> <p>A2A Gateway Registration As a platform admin   I want to register A2A-enabled servers as gateways (in addition to HTTP/SSE/WS)   So that I can federate A2A backends alongside standard MCP peers.</p> </li> <li> <p>A2A Tool Invocation As a developer   I want to call A2A servers as tools via the A2A protocol   So that A2A-native services appear in my tool catalog and handle messages over A2A transports.</p> </li> <li> <p>Expose Virtual Servers via A2A As an operator   I want to expose virtual servers (i.e. REST-wrapped MCP servers) over the A2A transport   So that clients that only support A2A can invoke those servers transparently.</p> </li> </ul>"},{"location":"architecture/roadmap/#lifecycle-management","title":"\u2699\ufe0f Lifecycle &amp; Management","text":""},{"location":"architecture/roadmap/#epic-virtual-server-protocol-version-selection","title":"\ud83e\udded Epic: Virtual Server Protocol Version Selection","text":"<p>Allow choosing which MCP protocol version each virtual server uses.</p> <ul> <li> <p>Per-Server Protocol Version As a platform admin   I want to specify the MCP protocol version (e.g. 2025-03-26 or earlier) on each virtual server   So that clients requiring legacy behavior can continue to work without affecting others.</p> </li> <li> <p>Protocol Compatibility Testing As a developer   I want to validate a virtual server's behavior against multiple protocol versions in the Admin UI   So that I can catch breaking changes before rolling out new servers.</p> </li> </ul>"},{"location":"architecture/roadmap/#observability-telemetry","title":"\ud83d\udcc8 Observability &amp; Telemetry","text":""},{"location":"architecture/roadmap/#epic-opentelemetry-tracing-metrics-export","title":"\ud83e\udded Epic: OpenTelemetry Tracing &amp; Metrics Export","text":"Trace &amp; Metric Visibility <p>Distributed Tracing: As a developer, I want traces spanning tools, prompts, and gateways so I can understand multi-step flows.</p> <p>Metrics Scraping: As an SRE, I want a Prometheus-compatible <code>/metrics</code> endpoint so I can alert on latency and error rate.</p>"},{"location":"architecture/roadmap/#epic-structured-json-logging-with-correlation-ids","title":"\ud83e\udded Epic: Structured JSON Logging with Correlation IDs","text":"Context-Rich Logging <p>Correlation IDs: As a DevOps user, I want logs with correlation and trace IDs so I can trace a request across services.</p>"},{"location":"architecture/roadmap/#lifecycle-management_1","title":"\u2699\ufe0f Lifecycle &amp; Management","text":""},{"location":"architecture/roadmap/#epic-hot-configuration-reload","title":"\ud83e\udded Epic: Hot Configuration Reload","text":"Dynamic Config Updates <p>In-Place Reload: As a system admin, I want to apply config changes (tools, servers, resources) without restarts so I maintain zero-downtime.</p>"},{"location":"architecture/roadmap/#epic-cli-enhancements-for-admin-operations","title":"\ud83e\udded Epic: CLI Enhancements for Admin Operations","text":"Automated Admin Commands <p>Admin CLI: As a DevOps engineer, I want CLI subcommands to register tools, flush caches, and export configs so I can integrate with CI/CD.</p>"},{"location":"architecture/roadmap/#epic-config-importexport-json-gateways-virtual-servers","title":"\ud83e\udded Epic: Config Import/Export (JSON Gateways &amp; Virtual Servers)","text":"JSON Config Portability <p>Individual Entity Export/Import: As a platform admin, I want to export or import a single gateway or virtual server's config in JSON so I can backup or migrate that one entity.</p> <p>Bulk Export/Import: As a platform admin, I want to export or import the full configuration (all gateways, virtual servers, prompts, resources) at once so I can replicate environments or perform large-scale updates.</p> <p>Encrypted Credentials: As a security-conscious operator, I want passwords and sensitive fields in exported JSON to be encrypted so my backups remain secure.</p> Automated Admin Commands <p>Admin CLI: As a DevOps engineer, I want CLI subcommands to register tools, flush caches, and export configs so I can integrate with CI/CD.</p>"},{"location":"architecture/roadmap/#epic-cache-management-api","title":"\ud83e\udded Epic: Cache Management API","text":"Cache Control <p>Cache Inspection &amp; Flush: As a site admin, I want endpoints to view cache stats and clear entries so I can manage data freshness.</p>"},{"location":"architecture/roadmap/#federation-routing_2","title":"\ud83c\udf10 Federation &amp; Routing","text":""},{"location":"architecture/roadmap/#epic-dynamic-federation-management","title":"\ud83e\udded Epic: Dynamic Federation Management","text":"Peer Gateway Management <p>Register/Remove Peers: As a platform admin, I want to add or remove federated gateways at runtime so I can scale and maintain federation.</p>"},{"location":"architecture/roadmap/#epic-circuit-breakers-for-unstable-backends","title":"\ud83e\udded Epic: Circuit Breakers for Unstable Backends","text":"Backend Isolation <p>Circuit Breaker: As the gateway, I want to trip circuits for backends after repeated failures so I prevent cascading retries.</p>"},{"location":"architecture/roadmap/#epic-intelligent-load-balancing-for-redundant-servers","title":"\ud83e\udded Epic: Intelligent Load Balancing for Redundant Servers","text":"Smart Request Routing <p>Adaptive Balancing: As an orchestrator, I want to route to the fastest healthy backend instance so I optimize response times.</p>"},{"location":"architecture/roadmap/#developer-experience","title":"\ud83d\udee0\ufe0f Developer Experience","text":""},{"location":"architecture/roadmap/#epic-prompt-template-tester-validator","title":"\ud83e\udded Epic: Prompt Template Tester &amp; Validator","text":"Prompt Validation <p>Template Linting: As a prompt engineer, I want to preview and validate Jinja2 templates with sample data so I avoid runtime errors.</p>"},{"location":"architecture/roadmap/#epic-system-diagnostics-self-check-report","title":"\ud83e\udded Epic: System Diagnostics &amp; Self-Check Report","text":"Diagnostics Bundle <p>Diagnostic Export: As an operator, I want a self-contained system report (config, health, metrics) so I can troubleshoot effectively.</p>"},{"location":"architecture/roadmap/#epic-auto-tuning-of-timeout-retry-policies","title":"\ud83e\udded Epic: Auto-Tuning of Timeout &amp; Retry Policies","text":"Adaptive Policy Tuning <p>Auto-Tuning: As the gateway, I want to adjust timeouts and retry intervals based on observed latencies so I balance reliability and speed.</p>"},{"location":"architecture/roadmap/#resilience-runtime","title":"\ud83d\udce6 Resilience &amp; Runtime","text":""},{"location":"architecture/roadmap/#epic-graceful-startup-and-shutdown","title":"\ud83e\udded Epic: Graceful Startup and Shutdown","text":"Graceful Lifecycle <p>In-Flight Draining: As the gateway, I want to complete active requests before shutdown so I prevent dropped connections.</p>"},{"location":"architecture/roadmap/#epic-high-availability-via-stateless-clustering","title":"\ud83e\udded Epic: High Availability via Stateless Clustering","text":"Clustered Scaling <p>Stateless Instances: As an architect, I want multiple interchangeable gateway nodes so I can load-balance and ensure failover.</p>"},{"location":"architecture/roadmap/#namespaces-catalog-integrity","title":"\ud83e\udded Namespaces &amp; Catalog Integrity","text":""},{"location":"architecture/roadmap/#epic-name-collision-handling-in-federated-catalogs","title":"\ud83e\udded Epic: Name Collision Handling in Federated Catalogs","text":"Unified Naming <p>Namespaced Tools: As an operator, I want to distinguish identical tool names from different servers (e.g. <code>ServerA/toolX</code> vs <code>ServerB/toolX</code>) so I avoid conflicts.</p>"},{"location":"architecture/roadmap/#secrets-sensitive-data","title":"\ud83d\udd10 Secrets &amp; Sensitive Data","text":""},{"location":"architecture/roadmap/#epic-secure-secrets-management-masking","title":"\ud83e\udded Epic: Secure Secrets Management &amp; Masking","text":"Externalized Secrets <p>Secret Store Integration: As an operator, I want to fetch credentials from a secrets manager so I avoid storing secrets in static configs.</p> <p>Log Scrubbing: As a compliance officer, I want sensitive data masked in logs and metrics so I maintain data security.</p>"},{"location":"architecture/roadmap/#developer-experience_1","title":"\ud83d\udee0\ufe0f Developer Experience","text":""},{"location":"architecture/roadmap/#epic-chrome-mcp-plugin-integration","title":"\ud83e\udded Epic: Chrome MCP Plugin Integration","text":"Browser-Based MCP Management <p>Plugin Accessibility: As a developer, I want a Chrome extension to manage MCP configurations, servers, and connections directly from the browser So that I can reduce dependency on local CLI tools and improve accessibility.</p> <p>Key Features: - Real-Time Session Control: Monitor and interact with MCP sessions via a browser UI. - Cross-Platform Compatibility: Ensure the plugin works seamlessly across devices and operating systems. - Secure API Proxy: Route requests securely via <code>mcpgateway.translate</code> or <code>mcpgateway.wrapper</code> for token-based access.</p> <p>Implementation Notes: - Distributed via the Chrome Web Store. - Uses JWT tokens stored in extension config or injected from Admin UI. - Interfaces with public <code>/servers</code>, <code>/tools</code>, <code>/resources</code>, and <code>/message</code> endpoints.</p>"},{"location":"architecture/roadmap/#epic-transport-translation-bridge-mcpgatewaytranslate","title":"\ud83e\udded Epic: Transport-Translation Bridge (<code>mcpgateway.translate</code>)","text":"CLI Bridge for Any-to-Any Transport <p>Goal: As a CLI user or integrator, I want to bridge stdio-only MCP servers to modern transports like SSE, WS, or Streamable HTTP</p> <p>So that I can use legacy binaries in web clients or tunnel remote services locally.</p> <p>Scenarios: - Stdio \u279c SSE:   Expose a local binary (e.g., <code>uvx mcp-server-git</code>) at <code>http://localhost:9000/sse</code>.</p> <ul> <li> <p>SSE \u279c Stdio:   Tunnel a remote SSE server to <code>stdin/stdout</code> so CLI tools can talk to it natively.</p> </li> <li> <p>Health &amp; CORS:   Add <code>/healthz</code> and CORS allowlist for reverse proxies and browser integrations.</p> </li> <li> <p>Dockerized:   Run the bridge as a standalone container from GHCR with no Python installed.</p> </li> </ul> <p>Example CLI Usage:</p> <pre><code>mcpgateway.translate \\\n  --stdio \"uvx mcp-server-git\" \\\n  --port 9000 \\\n  --ssePath /sse \\\n  --messagePath /message \\\n  --healthEndpoint /healthz \\\n  --cors \"https://app.example.com\"\n</code></pre> <p>Design:</p> <ul> <li>Uses async pumps between transport pairs (e.g., <code>Stdio \u2194 SSE</code>, <code>SSE \u2194 WS</code>).</li> <li>Maintains JSON-RPC fidelity and session state.</li> <li>Adapts message framing (e.g., Base64 for binary over SSE).</li> <li>Secure headers injected via <code>--header</code> or <code>--oauth2Bearer</code>.</li> </ul> <p>Docker:</p> <pre><code>docker run --rm -p 9000:9000 \\\n  ghcr.io/ibm/mcp-context-forge:translate\n</code></pre> <p>Acceptance Criteria:</p> <ul> <li>CLI and Docker bridge exposes <code>/sse</code> and <code>/message</code> for bidirectional MCP.</li> <li>Session ID and keep-alives handled automatically.</li> <li>Fully observable (<code>--logLevel</code>, Prometheus metrics, JWT headers, etc).</li> <li>Invalid flag combinations yield clean error output.</li> </ul> <p>Security:</p> <ul> <li>Honors <code>MCP_AUTH_TOKEN</code> and CORS allowlist.</li> <li>Redacts tokens in logs.</li> <li>Supports TLS verification toggle (<code>--skipSSLVerify</code>).</li> </ul>"},{"location":"architecture/roadmap/#epic-one-click-download-of-ready-to-use-client-config","title":"\ud83e\udded Epic: One-Click Download of Ready-to-Use Client Config","text":"Copy Config for Claude or CLI <p>Goal: As a user viewing a virtual server in the Admin UI, I want a button to download a pre-filled Claude JSON config</p> <p>So that I can immediately use the selected server in <code>Claude Desktop</code>, <code>mcpgateway.wrapper</code>, or any stdio/SSE-based client.</p> <p>Use Cases:</p> <ul> <li>Claude Desktop (stdio wrapper):   Download a <code>.json</code> config that launches the wrapper with correct <code>MCP_SERVER_CATALOG_URLS</code> and token pre-set.</li> <li>Browser / SSE Client:   Download a <code>.json</code> or <code>.env</code> snippet with <code>Authorization</code> header, SSE URL, and ready-to-paste curl/Javascript.</li> </ul> <p>Implementation Details:</p> <ul> <li>Button appears in the Admin UI under each virtual server's View panel.</li> <li>Config supports:<ul> <li><code>mcpgateway.wrapper</code> (for stdio clients)</li> <li><code>/sse</code> endpoint with token (for browser / curl)</li> </ul> </li> <li>JWT token is generated or reused on demand.</li> <li>Filled-in config includes:<ul> <li>Virtual server ID</li> <li>Base gateway URL</li> <li>Short-lived token (<code>MCP_AUTH_TOKEN</code>)</li> <li>Optional Docker or pipx run command</li> </ul> </li> <li>Claude Desktop format includes <code>command</code>, <code>args</code>, and <code>env</code> block.</li> </ul> <p>API Support:</p> <ul> <li>Add endpoint:   <pre><code>GET /servers/{id}/client-config\n</code></pre></li> <li>Optional query params:<ul> <li><code>type=claude</code> (default)</li> <li><code>type=sse</code></li> </ul> </li> <li>Returns JSON config with headers:   <pre><code>Content-Disposition: attachment; filename=\"claude-config.json\"\nContent-Type: application/json\n</code></pre></li> </ul> <p>Example (Claude-style JSON):</p> <pre><code>{\n  \"mcpServers\": {\n    \"server-alias\": {\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"mcpgateway.wrapper\"],\n      \"env\": {\n        \"MCP_AUTH_TOKEN\": \"example-token\",\n        \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/3\",\n        \"MCP_TOOL_CALL_TIMEOUT\": \"120\"\n      }\n    }\n  }\n}\n</code></pre> <p>Example (curl-ready SSE config):</p> <pre><code>curl -H \"Authorization: ...\" \\\n    http://localhost:4444/servers/3/sse\n</code></pre> <p>Acceptance Criteria:</p> <ul> <li>UI exposes a single Download Config button per server.</li> <li>Endpoint <code>/servers/{id}/client-config</code> returns fully populated config.</li> <li>Tokens are scoped, short-lived, or optionally ephemeral.</li> <li>Claude Desktop accepts the file without user edits.</li> </ul> <p>Security:</p> <ul> <li>JWT token is only included if the requester is authenticated.</li> <li>Download links are protected behind user auth and audit-logged.</li> <li>Expiry and scope settings match user profile or server defaults.</li> </ul> <p>Stretch goal:</p> <ul> <li>Toggle to choose between Claude, curl, or Docker styles.</li> <li>QR code output or \"Copy to Clipboard\" button. QR might work with the phone app, etc.</li> </ul>"},{"location":"architecture/roadmap/#epic-ldap-external-identity-integration","title":"\ud83e\udded Epic: LDAP &amp; External Identity Integration","text":"Corporate Directory Auth <p>LDAP Authentication: As a platform admin, I want to configure LDAP/Active Directory so that users authenticate with corporate credentials.</p> <p>Group Sync: As a platform admin, I want to sync LDAP/AD groups into gateway roles so I can manage permissions via directory groups.</p> <p>SSO Integration: As a platform admin, I want to support SAML/OIDC so that teams can use existing single sign-on.</p>"},{"location":"architecture/roadmap/#authentication-authorization-security-identity","title":"\ud83d\udd10 Authentication, Authorization, Security &amp; Identity","text":""},{"location":"architecture/roadmap/#87-epic-jwt-token-catalog-with-per-user-expiry-and-revocation","title":"\ud83e\udded #87 Epic: JWT Token Catalog with Per-User Expiry and Revocation","text":"Token Lifecycle Management <ul> <li>Generate Tokens:     As a platform admin, I want to generate one-time API tokens so I can issue short-lived credentials.</li> <li>Revoke Tokens:     As a platform admin, I want to revoke tokens so I can disable exposed or obsolete tokens.</li> <li>API Token Management:     As a user or automation client, I want to list, create, and revoke tokens via API so I can automate credential workflows.</li> </ul>"},{"location":"architecture/roadmap/#epic-per-virtual-server-api-keys","title":"\ud83e\udded Epic: Per-Virtual-Server API Keys","text":"Scoped Server Access <ul> <li>Server-Scoped Keys:     As a platform admin, I want to create API keys tied to a specific virtual server so that credentials are limited in scope.</li> <li>Key Rotation &amp; Revocation:     As a platform admin, I want to rotate or revoke a virtual server's API keys so I can maintain security without affecting other servers.</li> <li>API Management UI &amp; API:     As a developer, I want to list, create, rotate, and revoke server API keys via the Admin UI and REST API so I can automate credential lifecycle for each virtual server.</li> </ul>"},{"location":"architecture/roadmap/#epic-role-based-access-control-userteamglobal-scopes","title":"\ud83e\udded Epic: Role-Based Access Control (User/Team/Global Scopes)","text":"RBAC &amp; Scoping \u2014 Overview <ul> <li>User-Level Scopes:     As a platform admin, I want to assign permissions at the individual-user level so that I can grant fine-grained access.</li> <li>Team-Level Scopes:     As a platform admin, I want to define teams and grant scopes to teams so that I can manage permissions for groups of users.</li> <li>Global Scopes:     As a platform admin, I want to set global default scopes so that baseline permissions apply to all users.</li> </ul> 1\ufe0f\u20e3 Core Role / Permission Model <ul> <li>Define Canonical Roles:     Built-in <code>Owner</code>, <code>Admin</code>, <code>Developer</code>, <code>Read-Only</code>, and <code>Service</code> roles.     Acceptance Criteria:<ul> <li>Roles stored in <code>roles</code> table, seeded by migration</li> <li>Each role maps to a JSON list of named permissions (e.g. <code>tools:list</code>)</li> <li>Unit tests prove <code>Read-Only</code> cannot mutate anything</li> </ul> </li> <li>Fine-Grained Permission Catalog:<ul> <li>Full CRUD coverage for <code>tools</code>, <code>servers</code>, <code>resources</code>, <code>prompts</code>, <code>gateways</code></li> <li>Meta-permissions like <code>metrics:view</code>, <code>admin:impersonate</code></li> <li>All FastAPI routes must declare a permission via decorator</li> </ul> </li> </ul> 2\ufe0f\u20e3 Scope Hierarchy &amp; Resolution <ul> <li>Precedence:     Global \u2192 Team \u2192 User; resolution returns union of allow rules minus any denies.</li> <li>Wildcards:     Support <code>tools:*</code>, <code>admin:*</code> and expand dynamically into specific scopes.</li> </ul> 3\ufe0f\u20e3 Teams &amp; Membership <ul> <li>Team CRUD APIs &amp; UI:     Admin panel and REST API for team management (<code>GET/POST/PATCH/DELETE</code>), plus CSV/JSON import with dry-run mode.</li> <li>Nested Teams (Optional v2):     Support hierarchical teams with depth-first inheritance and first-match-wins precedence.</li> </ul> 4\ufe0f\u20e3 OAuth 2.1 / OIDC Integration <ul> <li>External IdP Mapping:     SSO/OIDC <code>groups</code> and <code>roles</code> claims map to gateway teams via a <code>team_mappings</code> table.</li> <li>PKCE Auth Code Flow:     Public clients get redirected to IdP; receive gateway-signed JWT with scopes in <code>scp</code> claim.</li> <li>Refresh-Token Rotation &amp; Revocation List:     Short-lived access tokens (\u226415 min), refresh token rotation, revocation checked per request.</li> </ul> 5\ufe0f\u20e3 Service / Machine Credentials <ul> <li>Client-Credentials Grant:     CI systems and automation can obtain scoped access tokens using client ID and secret.</li> <li>Signed JWT Actor Tokens:     Internal components can impersonate users or declare service identities via signed JWTs with <code>act</code> and <code>sub</code>.</li> </ul> 6\ufe0f\u20e3 Enforcement Middleware <ul> <li>FastAPI Dependency: <code>require_scope(\"...\")</code> uses JWT and Redis permission cache; 403 on scope mismatch.</li> <li>Transport-Level Guards:     HTTP/SSE/A2A transports reject missing or invalid scopes early (401/403).</li> </ul> 7\ufe0f\u20e3 Delegated (On-Behalf-Of) Flow <ul> <li>User-Delegated Tokens:     Users can mint scoped, short-lived tokens for agents to act on their behalf (e.g. tool calls); modal in Admin UI allows setting scopes and expiry.</li> </ul> 8\ufe0f\u20e3 Audit &amp; Observability <ul> <li>RBAC Audit Log:     Logs every grant/revoke/login with full metadata (who, what, when, IP, UA); exports to JSON Lines and Prometheus metrics (<code>authz_denied_total</code>).</li> <li>Correlation IDs:     403s include <code>correlation_id</code> header for traceability in logs and dashboards.</li> </ul> 9\ufe0f\u20e3 Self-Service Permission Inspector <ul> <li>Why-Denied Endpoint: <code>POST /authz/explain</code> returns an evaluation trace (role \u2192 scope \u2192 result); Admin UI visualizes graph with colored indicators.</li> </ul> \ud83d\udd1f Migration &amp; Back-Compat <ul> <li>Mixed-Mode Auth Toggle:     Support <code>AUTH_MODE=legacy|rbac</code>; legacy JWTs fallback to a <code>compat</code> role.</li> <li>Data Migration Scripts:     Alembic sets up <code>roles</code>, <code>permissions</code>, <code>teams</code>; CLI <code>mcpgateway migrate-rbac</code> assigns global admins from legacy data.</li> </ul> \u2705 Definition of Done <ul> <li>All HTTP/SSE/WS/A2A routes enforce scopes; fuzz tests confirm no bypass</li> <li>Full Admin UI coverage for role, team, and permission management</li> <li>End-to-end: IdP login \u2192 group-to-team mapping \u2192 scope-enforced tool access</li> <li>Regression tests for scope resolution, wildcard expansion, token lifecycles, delegated access, and audit logging</li> <li>Upgrade guide and SDK usage examples available in documentation</li> </ul>"},{"location":"architecture/adr/","title":"Architecture Decision Records","text":"<p>This page tracks all significant design decisions made for the MCP Gateway project, using the ADR format.</p> ID Title Status Section Date 0001 Adopt FastAPI + Pydantic Accepted Framework 2025-02-01 0002 Use Async SQLAlchemy ORM Accepted Persistence 2025-02-01 0003 Expose Multi-Transport Endpoints Accepted Transport 2025-02-01 0004 Combine JWT &amp; Basic Auth Accepted Security 2025-02-01 0005 Structured JSON Logging Accepted Observability 2025-02-21 0006 Gateway &amp; Tool-Level Rate Limiting Accepted Performance 2025-02-21 0007 Pluggable Cache Backend (memory / Redis / DB) Accepted Caching 2025-02-21 0008 Federation &amp; Auto-Discovery via DNS-SD Accepted Federation 2025-02-21 0009 Built-in Health Checks &amp; Self-Monitoring Accepted Operations 2025-02-21 0010 Observability via Prometheus, Structured Logs Accepted Observability 2025-02-21 <p>\u2733\ufe0f Add new decisions chronologically and link to them from this table.</p>"},{"location":"architecture/adr/001-adopt-fastapi-pydantic/","title":"ADR-0001: Adopt FastAPI + Pydantic","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-01</li> <li>Deciders: Mihai Criveti</li> </ul>"},{"location":"architecture/adr/001-adopt-fastapi-pydantic/#context","title":"Context","text":"<p>The MCP Gateway must serve both human and machine clients with low-latency HTTP and WebSocket endpoints. Payloads require runtime validation and schema documentation, while internal data types must align with environment-driven settings and JSON models.</p> <p>We explored Python-native frameworks that support async-first operation, data validation, OpenAPI generation, and modular service layout.</p>"},{"location":"architecture/adr/001-adopt-fastapi-pydantic/#decision","title":"Decision","text":"<p>We will adopt:</p> <ul> <li>FastAPI as the core web framework for routing HTTP, WebSocket, and streaming endpoints.</li> <li>Pydantic v2 for all settings, schemas, and typed data models (e.g., <code>Tool</code>, <code>Resource</code>, <code>GatewayMetadata</code>, etc.).</li> </ul> <p>These will form the foundation for the application layer and public API.</p>"},{"location":"architecture/adr/001-adopt-fastapi-pydantic/#consequences","title":"Consequences","text":"<ul> <li>\u2728 Strong typing, runtime validation, and auto-generated OpenAPI specs.</li> <li>\ud83e\udde9 Unified model structure across internal logic, external APIs, and config parsing.</li> <li>\ud83d\ude80 Excellent async performance with Uvicorn and Starlette compatibility.</li> <li>\ud83d\udd12 Tight coupling to Pydantic means future transitions (e.g., to dataclasses or attrs) would be non-trivial.</li> </ul>"},{"location":"architecture/adr/001-adopt-fastapi-pydantic/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not Flask + Marshmallow Sync-first architecture, weak async support, manual OpenAPI generation. Django REST Framework Heavyweight, monolithic, tightly bound to Django ORM, not async-native. Tornado or Starlette alone More boilerplate to assemble middlewares, validators, and routing. Node.js + Fastify Excellent performance but requires a split language/runtime and loss of shared model code. Pure <code>httpx</code> + <code>uvicorn</code> + <code>pydantic-core</code> Too low-level; duplicating FastAPI features manually."},{"location":"architecture/adr/001-adopt-fastapi-pydantic/#status","title":"Status","text":"<p>This decision has been implemented in the current architecture.</p>"},{"location":"architecture/adr/002-use-async-sqlalchemy-orm/","title":"ADR-0002: Use Async SQLAlchemy ORM","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-01</li> <li>Deciders: Mihai Criveti</li> </ul>"},{"location":"architecture/adr/002-use-async-sqlalchemy-orm/#context","title":"Context","text":"<p>The gateway must persist:</p> <ul> <li>Tool metadata</li> <li>Resource configurations</li> <li>Usage metrics</li> <li>Peer discovery and federation state</li> </ul> <p>We require a relational database with schema evolution, strong typing, and async support. The current codebase already uses SQLAlchemy ORM models with an async engine and declarative mapping style.</p>"},{"location":"architecture/adr/002-use-async-sqlalchemy-orm/#decision","title":"Decision","text":"<p>We will use:</p> <ul> <li>SQLAlchemy 2.x (async) for all data persistence.</li> <li>AsyncSession and <code>async with</code> scoped transactions.</li> <li>Alembic for migrations, with autogeneration and CLI support.</li> <li>SQLite for development; PostgreSQL or MySQL for production via <code>DATABASE_URL</code>.</li> </ul> <p>This provides consistent, well-understood relational behavior and integrates cleanly with FastAPI.</p>"},{"location":"architecture/adr/002-use-async-sqlalchemy-orm/#consequences","title":"Consequences","text":"<ul> <li>\ud83e\uddf1 Mature and reliable ORM with a wide developer base.</li> <li>\ud83d\udd04 Fully async I/O stack without thread-pools or blocking.</li> <li>\ud83d\udd27 Migrations handled declaratively using Alembic.</li> <li>\ud83d\udcc4 Pydantic models can be derived from or synchronized with SQLAlchemy models if needed.</li> </ul>"},{"location":"architecture/adr/002-use-async-sqlalchemy-orm/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not Raw asyncpg / aiosqlite Manual query strings, error-prone joins, no built-in migrations. Tortoise ORM / GINO Less widely used, more magic, lower confidence in long-term maintainability. Django ORM Not async-native, tightly coupled to Django ecosystem, too heavyweight. NoSQL (e.g., MongoDB) No relational guarantees, weaker query language, major refactor from current SQL-based model."},{"location":"architecture/adr/002-use-async-sqlalchemy-orm/#status","title":"Status","text":"<p>This decision is in place and all gateway persistence uses SQLAlchemy 2.x with async support.</p>"},{"location":"architecture/adr/003-expose-multi-transport-endpoints/","title":"ADR-0003: Expose Multi-Transport Endpoints (HTTP / WebSocket / SSE / STDIO)","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-01</li> <li>Deciders: Mihai Criveti</li> </ul>"},{"location":"architecture/adr/003-expose-multi-transport-endpoints/#context","title":"Context","text":"<p>The MCP Gateway must serve diverse clients: web browsers, CLIs, language-specific SDKs, and headless daemons. Different use cases require support for both request/response and streaming interactions.</p> <p>Requirements:</p> <ul> <li>Human-readable RPC over HTTP for developers</li> <li>Low-latency streaming for long-running tools</li> <li>IPC-style invocations for local CLI integration</li> <li>Unified business logic regardless of transport</li> </ul>"},{"location":"architecture/adr/003-expose-multi-transport-endpoints/#decision","title":"Decision","text":"<p>The gateway will support the following built-in transports:</p> <ul> <li>HTTP JSON-RPC (primary RPC interface)</li> <li>WebSocket (bidirectional messaging)</li> <li>SSE (Server-Sent Events) (for push-only event streaming)</li> <li>STDIO (optional local CLI / subprocess transport)</li> </ul> <p>Transport selection is dynamic, based on environment (<code>TRANSPORT_TYPE</code>) and route grouping. All transports share the same service layer and authentication mechanisms.</p>"},{"location":"architecture/adr/003-expose-multi-transport-endpoints/#consequences","title":"Consequences","text":"<ul> <li>\u2705 Maximum client flexibility, supporting modern browsers and legacy CLI tools.</li> <li>\ud83d\udd04 Business logic remains decoupled from transport implementation.</li> <li>\ud83d\udcf6 Streaming transports (WS, SSE) require timeout, reconnection, and back-pressure handling. Easy expansion with new MCP standards</li> </ul>"},{"location":"architecture/adr/003-expose-multi-transport-endpoints/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not HTTP-only JSON API Poor fit for long-lived streaming tasks; requires polling. gRPC (HTTP/2) Not browser-friendly; requires generated stubs; less discoverable. Separate microservices per transport Code duplication, diverging implementations, and operational complexity. Single transport abstraction Reduces explicitness; transport-specific needs get buried in generic interfaces."},{"location":"architecture/adr/003-expose-multi-transport-endpoints/#status","title":"Status","text":"<p>All four transports are implemented in the current FastAPI application and are toggleable via configuration.</p>"},{"location":"architecture/adr/004-combine-jwt-and-basic-auth/","title":"ADR-0004: Combine JWT &amp; Basic Auth","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-01</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/004-combine-jwt-and-basic-auth/#context","title":"Context","text":"<p>The gateway needs to support two types of clients:</p> <ul> <li>Browser-based users using the Admin UI</li> <li>Headless clients such as scripts, services, and tools</li> </ul> <p>These use cases require different authentication workflows:</p> <ul> <li>Browsers prefer form-based login and session cookies.</li> <li>Automation prefers stateless, token-based access.</li> </ul> <p>The current config exposes both:</p> <ul> <li><code>BASIC_AUTH_USER</code> and <code>BASIC_AUTH_PASSWORD</code></li> <li><code>JWT_SECRET_KEY</code>, <code>JWT_EXPIRY_SECONDS</code>, and cookie settings</li> </ul>"},{"location":"architecture/adr/004-combine-jwt-and-basic-auth/#decision","title":"Decision","text":"<p>We will combine both authentication modes as follows:</p> <ul> <li>Basic Auth secures access to <code>/admin</code>. Upon success, a short-lived JWT cookie is issued.</li> <li>JWT Bearer token (via header or cookie) is required for all API, WebSocket, and SSE requests.</li> <li>Tokens are signed using the shared <code>JWT_SECRET_KEY</code> and include standard claims (sub, exp, scopes).</li> <li>When <code>AUTH_REQUIRED=false</code>, the gateway allows unauthenticated access (dev only).</li> </ul>"},{"location":"architecture/adr/004-combine-jwt-and-basic-auth/#consequences","title":"Consequences","text":"<ul> <li>\u2705 Developers can log in once via browser and obtain an authenticated session.</li> <li>\u2705 Scripts can use a generated JWT directly, with no credential storage.</li> <li>\u274c Tokens must be signed, rotated, and verified securely (TLS required).</li> <li>\ud83d\udd04 JWTs expire and must be refreshed periodically by clients.</li> </ul>"},{"location":"architecture/adr/004-combine-jwt-and-basic-auth/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not JWT only CLI tools need a pre-acquired token; not friendly for interactive login. Basic only Password sent on every request; cannot easily revoke or expire credentials. OAuth2 / OpenID Connect Too complex for self-hosted setups; requires external identity provider. mTLS client auth Secure but heavy; not usable in browsers or simple HTTP clients."},{"location":"architecture/adr/004-combine-jwt-and-basic-auth/#status","title":"Status","text":"<p>This combined authentication mechanism is implemented and enabled by default in the gateway.</p>"},{"location":"architecture/adr/005-structured-json-logging/","title":"ADR-0005: Structured JSON Logging","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-21</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/005-structured-json-logging/#context","title":"Context","text":"<p>The gateway must emit logs that:</p> <ul> <li>Are machine-readable and parseable by tools like ELK, Loki, or Datadog</li> <li>Include rich context (e.g., request ID, auth user, duration)</li> <li>Can be viewed in plaintext locally and JSON in production</li> </ul> <p>Our configuration supports:</p> <ul> <li><code>LOG_FORMAT</code>: <code>json</code> or <code>plain</code></li> <li><code>LOG_LEVEL</code>: standard Python levels</li> <li><code>LOG_FILE</code>: optional log file destination</li> </ul> <p>Logs are initialized at startup via <code>LoggingService</code>.</p>"},{"location":"architecture/adr/005-structured-json-logging/#decision","title":"Decision","text":"<p>Use the Python standard <code>logging</code> module with:</p> <ul> <li>A custom JSON formatter for structured logs (e.g. <code>{\"level\": \"INFO\", \"msg\": ..., \"request_id\": ...}</code>)</li> <li>Plain text output when <code>LOG_FORMAT=plain</code></li> <li>Per-request context via filters or middleware</li> <li>Global setup at app startup to avoid late binding issues</li> </ul>"},{"location":"architecture/adr/005-structured-json-logging/#consequences","title":"Consequences","text":"<ul> <li>\ud83d\udccb Easily parsed logs suitable for production observability pipelines</li> <li>\u2699\ufe0f Compatible with <code>stdout</code>, file, or syslog targets</li> <li>\ud83e\uddea Local development uses plain logs for readability</li> <li>\ud83e\uddf1 Minimal dependency footprint (no third-party logging libraries)</li> </ul>"},{"location":"architecture/adr/005-structured-json-logging/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not loguru Elegant syntax, but non-standard; poor compatibility with Python ecosystem. structlog Adds context pipeline complexity; not needed for current log volume. External sidecar (e.g. Fluent Bit) Useful downstream but doesn't solve app-side structure. Raw print() statements Unstructured, difficult to manage at scale."},{"location":"architecture/adr/005-structured-json-logging/#status","title":"Status","text":"<p>Structured logging is implemented in <code>LoggingService</code>, configurable via environment variables.</p>"},{"location":"architecture/adr/005-vscode-devcontainer-support/","title":"ADR-005: VS Code Dev Container Support","text":""},{"location":"architecture/adr/005-vscode-devcontainer-support/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture/adr/005-vscode-devcontainer-support/#context","title":"Context","text":"<p>New contributors to the MCP Context Forge project face significant setup friction when trying to get a development environment running. The manual setup process requires:</p> <ul> <li>Installing Python 3.11</li> <li>Installing Docker/Podman</li> <li>Setting up virtual environments</li> <li>Installing development dependencies</li> <li>Configuring environment variables</li> <li>Running tests to verify setup</li> </ul> <p>This setup complexity can discourage contributions and slow down the onboarding process for new developers. Many contributors use VS Code or GitHub Codespaces, which support Dev Containers for standardized development environments.</p>"},{"location":"architecture/adr/005-vscode-devcontainer-support/#decision","title":"Decision","text":"<p>We will add VS Code Dev Container support to the project by implementing:</p> <ol> <li><code>.devcontainer/devcontainer.json</code> - Configuration specifying:</li> <li>Container build instructions</li> <li>VS Code extensions (Python, Docker)</li> <li>Post-creation commands</li> <li> <p>Environment variables for development mode</p> </li> <li> <p><code>.devcontainer/Dockerfile</code> - Container definition with:</p> </li> <li>Python 3.11 slim base image</li> <li>Docker CLI for container management</li> <li>System dependencies (curl, git, build-essential)</li> <li>Python tooling (pip, setuptools, pdm, uv)</li> <li> <p>Development environment setup</p> </li> <li> <p><code>.devcontainer/postCreateCommand.sh</code> - Setup script that:</p> </li> <li>Copies <code>.env.example</code> to <code>.env</code> if needed</li> <li>Runs <code>make install-dev</code> to install development dependencies</li> <li> <p>Runs <code>make test</code> to verify the environment</p> </li> <li> <p>Documentation updates - README.md section explaining:</p> </li> <li>How to use the devcontainer in VS Code</li> <li>How to use with GitHub Codespaces</li> <li>Benefits and included tools</li> </ol>"},{"location":"architecture/adr/005-vscode-devcontainer-support/#consequences","title":"Consequences","text":""},{"location":"architecture/adr/005-vscode-devcontainer-support/#positive","title":"Positive","text":"<ul> <li>Instant onboarding: New contributors can start developing immediately with one click</li> <li>Consistent environments: All developers use the same Python version, tools, and dependencies</li> <li>Reduced setup friction: No need to manually install Python, Docker, or configure environments</li> <li>GitHub Codespaces support: Cloud-based development without local setup requirements</li> <li>Automated verification: Tests run automatically to ensure the environment is working</li> <li>Standardized tooling: Everyone gets the same VS Code extensions and configuration</li> </ul>"},{"location":"architecture/adr/005-vscode-devcontainer-support/#negative","title":"Negative","text":"<ul> <li>Additional maintenance: Need to keep devcontainer configuration in sync with project requirements</li> <li>Container build time: Initial setup takes a few minutes for first-time users</li> <li>Docker dependency: Requires Docker/Podman to be installed and running</li> <li>Limited to VS Code: Only benefits developers using VS Code or Codespaces</li> </ul>"},{"location":"architecture/adr/005-vscode-devcontainer-support/#neutral","title":"Neutral","text":"<ul> <li>File size increase: Adds minimal files to the repository</li> <li>Learning curve: Developers unfamiliar with Dev Containers may need to learn the workflow</li> </ul>"},{"location":"architecture/adr/005-vscode-devcontainer-support/#alternatives-considered","title":"Alternatives Considered","text":"<ol> <li>Manual setup instructions only (current state)</li> <li>Pros: No additional complexity</li> <li> <p>Cons: High setup friction, inconsistent environments</p> </li> <li> <p>Gitpod integration</p> </li> <li>Pros: Cloud-based development</li> <li> <p>Cons: Less VS Code-native, additional external dependency</p> </li> <li> <p>Docker Compose for development</p> </li> <li>Pros: Tool-agnostic</li> <li> <p>Cons: More complex setup, less integrated with VS Code</p> </li> <li> <p>Vagrant-based development environment</p> </li> <li>Pros: Full VM isolation</li> <li>Cons: Resource-heavy, slower, less modern workflow</li> </ol>"},{"location":"architecture/adr/005-vscode-devcontainer-support/#implementation-details","title":"Implementation Details","text":"<p>The devcontainer uses: - Python 3.11: As specified in the project requirements - PDM and UV: For package management (matching the project's tooling) - Make targets: Leverages existing <code>make install-dev</code> and <code>make test</code> workflows - Environment variables: Sets <code>MCPGATEWAY_DEV_MODE=true</code> for development - VS Code extensions: Includes Python and Docker extensions for optimal development experience</p>"},{"location":"architecture/adr/005-vscode-devcontainer-support/#verification","title":"Verification","text":"<p>The implementation was tested by: 1. Building the devcontainer in VS Code 2. Verifying that development dependencies install correctly 3. Confirming that the test suite passes 4. Checking that all Make targets work properly inside the container</p>"},{"location":"architecture/adr/005-vscode-devcontainer-support/#references","title":"References","text":"<ul> <li>VS Code Dev Containers documentation</li> <li>GitHub Codespaces documentation</li> <li>Dev Container specification</li> <li>Project issue/PR requesting devcontainer support</li> </ul>"},{"location":"architecture/adr/006-gateway-tool-rate-limiting/","title":"ADR-0006: Gateway &amp; Tool-Level Rate Limiting","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-21</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/006-gateway-tool-rate-limiting/#context","title":"Context","text":"<p>The MCP Gateway may serve hundreds of concurrent clients accessing multiple tools. Without protection, a single client or misbehaving tool could monopolize resources or overwhelm upstream services.</p> <p>The configuration includes:</p> <ul> <li><code>TOOL_RATE_LIMIT</code>: default limit in requests/min per tool/client</li> <li>Planned support for Redis-based or database-backed counters</li> </ul> <p>Current implementation is an in-memory token bucket.</p>"},{"location":"architecture/adr/006-gateway-tool-rate-limiting/#decision","title":"Decision","text":"<p>Implement a rate limiter at the tool invocation level, keyed by:</p> <ul> <li>Tool name</li> <li>Authenticated user / client identity (JWT or Basic)</li> <li>Time window (per-minute by default)</li> </ul> <p>Backend options:</p> <ul> <li>Memory (default for dev / single instance)</li> <li>Redis (planned for clustering / shared limits)</li> <li>Database (eventually consistent fallback)</li> </ul>"},{"location":"architecture/adr/006-gateway-tool-rate-limiting/#consequences","title":"Consequences","text":"<ul> <li>\u2705 Prevents abuse, controls cost, and provides predictable fairness</li> <li>\ud83d\udcc9 Failed requests return <code>429 Too Many Requests</code> with retry headers</li> <li>\u274c Memory backend does not scale across instances; Redis required for HA</li> <li>\ud83d\udd04 Optional override of limits via config/env for testing</li> </ul>"},{"location":"architecture/adr/006-gateway-tool-rate-limiting/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not No rate limiting Leaves gateway and tools vulnerable to overload or accidental DoS. Global rate limit only Heavy tools can starve lightweight tools; no fine-grained control. Proxy-level throttling (e.g. NGINX, Envoy) Can't distinguish tools or users inside payload; lacks granularity."},{"location":"architecture/adr/006-gateway-tool-rate-limiting/#status","title":"Status","text":"<p>Rate limiting is implemented for tool routes, with <code>TOOL_RATE_LIMIT</code> as the default policy.</p>"},{"location":"architecture/adr/007-pluggable-cache-backend/","title":"ADR-0007: Pluggable Cache Backend (memory / Redis / database)","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-21</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/007-pluggable-cache-backend/#context","title":"Context","text":"<p>The MCP Gateway uses short-lived caching for:</p> <ul> <li>Tool responses and resource lookups</li> <li>Peer discovery metadata</li> <li>Temporary session state and rate-limiting</li> </ul> <p>Different deployments require different caching characteristics:</p> <ul> <li>Dev mode: no external services (in-memory only)</li> <li>Production: clustered and persistent (Redis)</li> <li>Air-gapped: embedded fallback (database table)</li> </ul> <p>The config exposes <code>CACHE_TYPE=memory|redis|database</code>.</p>"},{"location":"architecture/adr/007-pluggable-cache-backend/#decision","title":"Decision","text":"<p>Abstract the caching system via a <code>CacheBackend</code> interface and support the following pluggable backends:</p> <ul> <li><code>MemoryCacheBackend</code>: simple <code>dict</code> with TTL, for dev and unit tests</li> <li><code>RedisCacheBackend</code>: shared, centralized cache for multi-node clusters</li> <li><code>DatabaseCacheBackend</code>: uses SQLAlchemy ORM to persist TTL-based records</li> </ul> <p>Selection is driven by the <code>CACHE_TYPE</code> environment variable. Code paths use a consistent interface regardless of backend.</p>"},{"location":"architecture/adr/007-pluggable-cache-backend/#consequences","title":"Consequences","text":"<ul> <li>\ud83d\udd04 Easy to switch cache backend per environment or load profile</li> <li>\ud83d\ude80 Redis allows horizontal scaling and persistent shared state</li> <li>\u274c Memory cache does not survive restarts or share state</li> <li>\ud83d\udc22 Database cache is slower, but useful in restricted networks</li> </ul>"},{"location":"architecture/adr/007-pluggable-cache-backend/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not Hardcoded Redis Adds operational overhead and single point of failure for dev. Memory-only cache Incompatible with horizontal scale or restart resilience. External CDN or HTTP cache Doesn't address in-process sessions, discovery, or tool state. Disk-based cache (e.g., shelve, pickle) Complex invalidation and concurrency issues; not cloud-ready."},{"location":"architecture/adr/007-pluggable-cache-backend/#status","title":"Status","text":"<p>All three cache backends are implemented and the gateway selects one dynamically based on configuration.</p>"},{"location":"architecture/adr/008-federation-discovery/","title":"ADR-0008: Federation &amp; Auto-Discovery via DNS-SD","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-21</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/008-federation-discovery/#context","title":"Context","text":"<p>The MCP Gateway must support federated operation, where multiple gateway instances:</p> <ul> <li>Automatically discover each other on a shared network</li> <li>Exchange metadata and tool/service availability</li> <li>Merge registries and route calls to remote nodes</li> </ul> <p>Manual configuration (e.g. hardcoded peer IPs) is error-prone and brittle in dynamic environments like laptops or Kubernetes.</p> <p>The codebase includes a <code>DiscoveryService</code> and federation settings such as:</p> <ul> <li><code>FEDERATION_ENABLED</code></li> <li><code>FEDERATION_DISCOVERY</code></li> <li><code>DISCOVERY_INTERVAL_SECONDS</code></li> </ul>"},{"location":"architecture/adr/008-federation-discovery/#decision","title":"Decision","text":"<p>We enable auto-discovery via DNS-SD (mDNS/zeroconf) by default. Each gateway:</p> <ul> <li>Publishes itself using <code>_mcp._tcp.local.</code> with TXT records</li> <li>Periodically probes for peers using <code>zeroconf</code> or a fallback registry</li> <li>Merges discovered gateways into its internal routing map</li> <li>Sends periodic liveness pings to verify peer health</li> </ul> <p>Static peer configuration is still supported for restricted networks.</p>"},{"location":"architecture/adr/008-federation-discovery/#consequences","title":"Consequences","text":"<ul> <li>\ud83d\udd0c Gateways connect seamlessly on the same local network or overlay mesh</li> <li>\ud83d\udd75\ufe0f\u200d\u2642\ufe0f DNS-SD adds moderate background network traffic, tunable via TTL</li> <li>\u26a0\ufe0f Firewalls or environments without multicast must use static peer config</li> <li>\u267b\ufe0f Federated topologies are self-healing and require no orchestration</li> </ul>"},{"location":"architecture/adr/008-federation-discovery/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not Static peer list only Manual entry, error-prone, not zero-config. Central registry (e.g. etcd, Consul) Adds external infrastructure and tight coordination. Cloud DNS-based discovery Requires cloud provider integration and persistent internet access. gRPC service registry Less transparent, requires protobuf tooling and internal coordination layer."},{"location":"architecture/adr/008-federation-discovery/#status","title":"Status","text":"<p>Auto-discovery is implemented using <code>zeroconf</code>, and federation is active when <code>FEDERATION_ENABLED=true</code>.</p> <p>Current feature is early pre-alpha and may not work correctly.</p>"},{"location":"architecture/adr/009-built-in-health-checks/","title":"ADR-0009: Built-in Health Checks &amp; Self-Monitoring","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-21</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/009-built-in-health-checks/#context","title":"Context","text":"<p>MCP Gateways must participate in mesh/federated deployments. Faulty nodes must be detected and removed automatically. Additionally, cloud-native infrastructure (like Kubernetes, Docker Swarm, or systemd watchdogs) needs a way to check local health.</p> <p>The gateway config supports health-related settings:</p> <ul> <li><code>HEALTH_CHECK_INTERVAL</code>: frequency of peer checks</li> <li><code>HEALTH_CHECK_TIMEOUT</code>: request timeout per probe</li> <li><code>UNHEALTHY_THRESHOLD</code>: number of failures before a peer is marked unhealthy</li> </ul> <p>The README and architecture describe <code>/health</code> and <code>/metrics</code> endpoints as built-in features</p>"},{"location":"architecture/adr/009-built-in-health-checks/#decision","title":"Decision","text":"<p>Implement two health-check levels:</p> <ol> <li>Local health endpoint at <code>/health</code>:</li> <li>Verifies database connectivity and response time</li> <li> <p>Optionally checks cache (e.g. Redis ping or in-memory status)</p> </li> <li> <p>Federated peer liveness:</p> </li> <li>Every <code>HEALTH_CHECK_INTERVAL</code>, we ping all registered peers via HTTP</li> <li>If a peer fails <code>UNHEALTHY_THRESHOLD</code> times consecutively, it's temporarily deactivated</li> <li>A separate background task handles this (see <code>FederationManager</code>)</li> </ol> <p>Health info is also published to <code>/metrics</code> in Prometheus format.</p>"},{"location":"architecture/adr/009-built-in-health-checks/#consequences","title":"Consequences","text":"<ul> <li>\u2705 Federated topologies can eject bad nodes quickly and re-accept them later</li> <li>\u2705 Local health can be used by Kubernetes probes, HAProxy, etc.</li> <li>\ud83d\udd04 Gateways that go offline briefly won't be removed immediately (tunable)</li> <li>\ud83d\udd0d Metrics include last check time, RTT, and result status</li> </ul>"},{"location":"architecture/adr/009-built-in-health-checks/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not No health checks Delayed or no reaction to failures; requires manual debugging Rely on Kubernetes probes Only detects local process health, not remote peers External APM agent (Datadog) Complex setup, costly for small/self-hosted use cases Central heartbeat server Single point of failure, requires extra infra"},{"location":"architecture/adr/009-built-in-health-checks/#status","title":"Status","text":"<p>This is implemented as part of the <code>FederationManager</code> and exposed via <code>/health</code> and <code>/metrics</code> endpoints.</p>"},{"location":"architecture/adr/010-observability-prometheus/","title":"ADR-0010: Observability via Prometheus, Structured Logs, and Metrics","text":"<ul> <li>Status: Accepted</li> <li>Date: 2025-02-21</li> <li>Deciders: Core Engineering Team</li> </ul>"},{"location":"architecture/adr/010-observability-prometheus/#context","title":"Context","text":"<p>The MCP Gateway is a long-running service that executes tools, processes requests, and federates with remote peers. Operators and developers must be able to observe:</p> <ul> <li>Overall system health</li> <li>Request throughput and latency</li> <li>Tool and resource usage</li> <li>Error rates and failure patterns</li> <li>Federation behavior and peer availability</li> </ul> <p>The gateway needs to surface this without requiring external instrumentation or agents.</p>"},{"location":"architecture/adr/010-observability-prometheus/#decision","title":"Decision","text":"<p>We will implement native observability features using:</p> <ol> <li>Structured JSON logs with optional plaintext fallback:</li> <li>Controlled by <code>LOG_FORMAT=json|text</code> and <code>LOG_LEVEL</code></li> <li> <p>Includes fields: timestamp, level, logger name, request ID, route, auth user, latency</p> </li> <li> <p>Prometheus-compatible <code>/metrics</code> endpoint:</p> </li> <li>Exposes key counters and histograms: tool invocations, failures, resource loads, peer syncs, etc.</li> <li> <p>Uses plain <code>text/plain; version=0.0.4</code> exposition format</p> </li> <li> <p>Latency decorators and in-code timing for critical paths:</p> </li> <li>Completion requests</li> <li>Resource resolution</li> <li> <p>Federation sync/health probes</p> </li> <li> <p>Per-request IDs and correlation:</p> </li> <li>Middleware attaches <code>X-Request-ID</code> if present or generates a new one</li> <li>Request ID propagates through logs and errors</li> </ol>"},{"location":"architecture/adr/010-observability-prometheus/#consequences","title":"Consequences","text":"<ul> <li>\ud83d\udcca Metrics can be scraped by Prometheus and visualized in Grafana</li> <li>\ud83d\udd0d Developers can trace logs by request or user</li> <li>\ud83d\udee0\ufe0f No external sidecars required for basic visibility</li> <li>\ud83d\udce6 Docker image contains <code>/metrics</code> by default and logs to <code>stdout</code> (JSON)</li> </ul>"},{"location":"architecture/adr/010-observability-prometheus/#alternatives-considered","title":"Alternatives Considered","text":"Option Why Not No structured logging Difficult to parse or filter logs; weak correlation per request Third-party APM (e.g., Datadog) Adds vendor lock-in, overhead, and cost Syslog or Fluentd only Requires extra deployment layers; still needs JSON emitters StatsD / Telegraf metrics Less common today than Prometheus; harder to self-host"},{"location":"architecture/adr/010-observability-prometheus/#status","title":"Status","text":"<p>Implemented in <code>LoggingService</code> and <code>metrics_router</code>. Observability is active by default for all transports and routes.</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"deployment/","title":"Deployment Overview","text":"<p>This section explains how to deploy MCP Gateway in various environments \u2014 from local development to cloud-native platforms like Kubernetes, IBM Code Engine, AWS, and Azure.</p>"},{"location":"deployment/#deployment-options","title":"\ud83d\uddfa Deployment Options","text":"<p>MCP Gateway supports multiple deployment strategies:</p> Method Description Local Run directly on your dev machine using <code>make</code>, <code>uvicorn</code>, or a virtual-env Container Package and run as a single container image using Podman or Docker Compose Stack Bring up Gateway + Postgres + Redis (and optional MPC servers) with Podman/Docker Compose Minikube Launch a local single-node Kubernetes cluster and deploy the Gateway stack Kubernetes Generic manifests or Helm chart for any K8s-compliant platform OpenShift OpenShift-specific deployment using Routes, SCCs, and Operator-managed back-ends IBM Code Engine Serverless container build &amp; run on IBM Cloud AWS Deploy on ECS Fargate, EKS, or EC2-hosted containers Azure Run on Azure Container Apps, App Service, or AKS"},{"location":"deployment/#runtime-configuration","title":"\ud83d\udee0 Runtime Configuration","text":"<p>MCP Gateway loads configuration from:</p> <ul> <li><code>.env</code> file (in project root or mounted at <code>/app/.env</code>)</li> <li>Environment variables (overrides <code>.env</code>)</li> <li>CLI flags (e.g., via <code>run.sh</code>)</li> </ul>"},{"location":"deployment/#health-checks","title":"\ud83e\uddea Health Checks","text":"<p>All deployments should expose:</p> <pre><code>GET /health\n</code></pre> <p>This returns basic system latency metrics and can be used with cloud provider readiness probes.</p>"},{"location":"deployment/#container-basics","title":"\ud83d\udce6 Container Basics","text":"<p>The default container image:</p> <ul> <li>Uses the Red Hat Universal Base image running as a non-root user</li> <li>Exposes port <code>4444</code></li> <li>Runs <code>gunicorn</code> with Uvicorn workers</li> <li>Uses <code>.env</code> for all settings</li> </ul> <p>For Kubernetes, you can mount a ConfigMap or Secret as <code>.env</code>.</p>"},{"location":"deployment/argocd/","title":"\ud83d\udea2 Deploying the MCP Gateway Stack with Argo CD","text":"<p>This guide shows how to operate the MCP Gateway Stack with a Git\u2011Ops workflow powered by Argo CD. Once wired up, every commit to the repository becomes an automatic deployment (or rollback) to your Kubernetes cluster.</p> <p>\ud83c\udf33 Git source of truth: <code>https://github.com/IBM/mcp-context-forge</code></p> <ul> <li>App manifests: <code>k8s/</code> (Kustomize\u2011ready)</li> <li>Helm chart (optional): <code>charts/mcp-stack</code></li> </ul>"},{"location":"deployment/argocd/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"Requirement Notes Kubernetes \u2265 1.23 Local (Minikube/kind) or managed (EKS, AKS, GKE, etc.) Argo CD \u2265 2.7 Server &amp; CLI (this guide installs server into the cluster) kubectl Configured to talk to the target cluster Git access The cluster must be able to pull the repo (public or deploy\u2011key)"},{"location":"deployment/argocd/#step-1-install-argo-cd-once-per-cluster","title":"\ud83d\udee0 Step 1 \u2013 Install Argo CD (once per cluster)","text":"<pre><code># Namespace + core components\nkubectl create namespace argocd\nkubectl apply -n argocd \\\n  -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml\n\n# Wait for the server component\nkubectl -n argocd rollout status deploy/argocd-server\n</code></pre>"},{"location":"deployment/argocd/#install-the-cli","title":"Install the CLI","text":"<pre><code># macOS\nbrew install argocd\n\n# Linux (single\u2011binary)\ncurl -sSL -o /tmp/argocd \\\n  https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64\nsudo install -m 555 /tmp/argocd /usr/local/bin/argocd\n</code></pre> <p>Verify:</p> <pre><code>argocd version --client\n</code></pre>"},{"location":"deployment/argocd/#step-2-initial-login","title":"\ud83d\udd10 Step 2 \u2013 Initial Login","text":"<p>Forward the API/UI to your workstation (leave running):</p> <pre><code>kubectl -n argocd port-forward svc/argocd-server 8083:443\n</code></pre> <p>Fetch the one\u2011time admin password and log in:</p> <pre><code>PASS=\"$(kubectl -n argocd get secret argocd-initial-admin-secret \\\n          -o jsonpath='{.data.password}' | base64 -d)\"\nargocd login localhost:8083 \\\n  --username admin --password \"$PASS\" --insecure\n</code></pre> <p>Open the web UI \u2192 http://localhost:8083 (credentials above).</p>"},{"location":"deployment/argocd/#step-3-bootstrap-the-application","title":"\ud83d\ude80 Step 3 \u2013 Bootstrap the Application","text":"<p>Create an Argo CD Application that tracks the <code>k8s/</code> folder from the main branch:</p> <pre><code>APP=mcp-gateway\nREPO=https://github.com/IBM/mcp-context-forge.git\n\nargocd app create \"$APP\" \\\n  --repo \"$REPO\" \\\n  --path k8s \\\n  --dest-server https://kubernetes.default.svc \\\n  --dest-namespace default \\\n  --sync-policy automated \\\n  --revision main\n</code></pre> <p>Trigger the first sync:</p> <pre><code>argocd app sync \"$APP\"\n</code></pre> <p>Argo CD will apply all manifests and keep them in the Synced \ud83c\udf3f / Healthy \ud83d\udc9a state.</p>"},{"location":"deployment/argocd/#step-4-verify-deployment","title":"\u2705 Step 4 \u2013 Verify Deployment","text":"<pre><code>kubectl get pods,svc,ingress\nargocd app list\nargocd app get mcp-gateway\n</code></pre> <p>If using the sample Ingress:</p> <pre><code>curl http://gateway.local/health\n</code></pre> <p>Otherwise, port\u2011forward:</p> <pre><code>kubectl port-forward svc/mcp-context-forge 8080:80 &amp;\ncurl http://localhost:8080/health\n</code></pre>"},{"location":"deployment/argocd/#day2-operations","title":"\ud83d\udd04 Day\u20112 Operations","text":""},{"location":"deployment/argocd/#sync-after-a-new-commit","title":"Sync after a new commit","text":"<pre><code>argocd app sync mcp-gateway\n</code></pre>"},{"location":"deployment/argocd/#view-diff-before-syncing","title":"View diff before syncing","text":"<pre><code>argocd app diff mcp-gateway\n</code></pre>"},{"location":"deployment/argocd/#roll-back-to-a-previous-revision","title":"Roll back to a previous revision","text":"<pre><code>argocd app history mcp-gateway\nargocd app rollback mcp-gateway &lt;REVISION&gt;\n</code></pre>"},{"location":"deployment/argocd/#disable-enable-autosync","title":"Disable / enable auto\u2011sync","text":"<pre><code># Pause auto\u2011sync\na rgocd app set mcp-gateway --sync-policy none\n# Re\u2011enable\nargocd app set mcp-gateway --sync-policy automated\n</code></pre>"},{"location":"deployment/argocd/#uninstall","title":"\ud83e\uddf9 Uninstall","text":"<pre><code># Delete the application (leaves cluster objects intact)\nargocd app delete mcp-gateway --yes\n\n# Remove Argo CD completely\\ nkubectl delete ns argocd\n</code></pre>"},{"location":"deployment/argocd/#makefile-shortcuts","title":"\ud83e\uddf0 Makefile Shortcuts","text":"<p>The repository ships with ready\u2011made targets:</p> Target Action <code>make argocd-install</code> Installs Argo CD server into the current cluster <code>make argocd-forward</code> Port\u2011forwards UI/API on http://localhost:8083 <code>make argocd-app-bootstrap</code> Creates &amp; auto\u2011syncs the mcp\u2011gateway application <code>make argocd-app-sync</code> Forces a manual sync <p>Run <code>make help</code> to list them all.</p>"},{"location":"deployment/argocd/#troubleshooting","title":"\ud83e\uddef Troubleshooting","text":"Symptom Fix <code>ImagePullBackOff</code> Check image name / pull secret &amp; that the repo is public or credentials are configured in Argo CD <code>SyncFailed</code> <code>argocd app logs mcp-gateway</code> for details; often due to immutable fields Web UI 404 Ensure <code>argocd-forward</code> is still running, or expose via Ingress/LoadBalancer RBAC denied Argo CD needs ClusterRoleBinding for non\u2011default namespaces \u2013 see docs"},{"location":"deployment/argocd/#further-reading","title":"\ud83d\udcda Further Reading","text":"<ul> <li>Argo CD Docs \u2013 https://argo-cd.readthedocs.io</li> <li>GitOps Pattern \u2013 https://www.weave.works/technologies/gitops/</li> <li>Kustomize \u2013 https://kubectl.docs.kubernetes.io/references/kustomize/</li> <li>Helm + Argo CD \u2013 https://argo-cd.readthedocs.io/en/stable/user-guide/helm/</li> </ul>"},{"location":"deployment/aws/","title":"\ud83d\udfe7 AWS","text":"<p>MCP Gateway can be deployed to AWS using multiple container-based services:</p> <ul> <li>ECS (Fargate or EC2-backed)</li> <li>EKS (Elastic Kubernetes Service)</li> <li>EC2 (direct VM hosting with Docker)</li> </ul>"},{"location":"deployment/aws/#option-1-ecs-fargate","title":"\ud83d\ude80 Option 1: ECS (Fargate)","text":"<p>ECS is a fully managed container orchestration service. Use it to deploy MCP Gateway without managing servers.</p>"},{"location":"deployment/aws/#steps","title":"Steps","text":"<ol> <li>Build and push your image:</li> </ol> <pre><code>docker build -t YOUR_ECR_URI/mcpgateway .\naws ecr get-login-password | docker login --username AWS --password-stdin YOUR_ECR_URI\ndocker push YOUR_ECR_URI/mcpgateway\n</code></pre> <ol> <li> <p>Create an ECS Task Definition:</p> </li> <li> <p>Use port <code>4444</code></p> </li> <li> <p>Mount a secret or config for your <code>.env</code> (or set environment variables manually)</p> </li> <li> <p>Create a Service:</p> </li> <li> <p>Use a Load Balancer (Application LB)</p> </li> <li>Map <code>/</code> or <code>/admin</code> to port <code>4444</code></li> </ol>"},{"location":"deployment/aws/#option-2-eks","title":"\ud83d\ude80 Option 2: EKS","text":"<p>Use the same Kubernetes deployment guide and run on Amazon EKS.</p> <p>You can:</p> <ul> <li>Use <code>kubectl</code> + <code>eksctl</code></li> <li>Store <code>.env</code> as a Secret or ConfigMap</li> <li>Use AWS Load Balancer Controller or NGINX Ingress</li> </ul>"},{"location":"deployment/aws/#option-3-ec2-docker","title":"\ud83d\ude80 Option 3: EC2 (Docker)","text":"<ol> <li>Launch a VM (e.g., Ubuntu)</li> <li>Install Docker</li> <li>Copy your <code>.env</code> file and build the container:</li> </ol> <pre><code>scp .env ec2-user@host:/home/ec2-user\nssh ec2-user@host\ndocker build -t mcpgateway .\ndocker run -p 80:4444 --env-file .env mcpgateway\n</code></pre>"},{"location":"deployment/aws/#security-tips","title":"\ud83d\udee1\ufe0f Security Tips","text":"<ul> <li>Set <code>AUTH_REQUIRED=true</code> in production</li> <li>Use <code>JWT_SECRET_KEY</code> and <code>AUTH_ENCRYPTION_SECRET</code></li> <li>Terminate TLS at the ELB level, or use Caddy/Nginx in-container if needed</li> </ul>"},{"location":"deployment/aws/#dns-access","title":"\ud83d\udce1 DNS &amp; Access","text":"<p>You can point Route53 or your DNS provider to the Load Balancer hostname.</p> <p>Example:</p> <pre><code>gateway.example.com -&gt; my-elb-1234.us-west-2.elb.amazonaws.com\n</code></pre>"},{"location":"deployment/azure/","title":"\ud83d\udd37 Azure","text":"<p>MCP Gateway can be deployed on Azure in multiple ways:</p> <ul> <li>Azure Container Apps (serverless)</li> <li>Azure App Service (PaaS for containers)</li> <li>Azure Kubernetes Service (AKS) (fully managed K8s)</li> </ul>"},{"location":"deployment/azure/#option-1-azure-container-apps-recommended","title":"\ud83d\ude80 Option 1: Azure Container Apps (Recommended)","text":"<p>Azure Container Apps is ideal for lightweight container-based workloads.</p>"},{"location":"deployment/azure/#steps","title":"Steps","text":"<ol> <li>Build and push your image to Azure Container Registry (ACR):</li> </ol> <pre><code>az acr login --name yourregistry\ndocker tag mcpgateway yourregistry.azurecr.io/mcpgateway\ndocker push yourregistry.azurecr.io/mcpgateway\n</code></pre> <ol> <li>Create the container app:</li> </ol> <pre><code>az containerapp create \\\n  --name mcpgateway \\\n  --resource-group my-rg \\\n  --image yourregistry.azurecr.io/mcpgateway \\\n  --target-port 4444 \\\n  --environment my-container-env \\\n  --registry-server yourregistry.azurecr.io \\\n  --env-vars-from-secrets .env\n</code></pre> <p>You can mount <code>.env</code> via Key Vault or inject environment variables directly.</p>"},{"location":"deployment/azure/#option-2-azure-app-service","title":"\ud83d\ude80 Option 2: Azure App Service","text":"<ol> <li>Push your image to ACR</li> <li>Create an App Service plan and container-based Web App</li> <li>Set <code>PORT=4444</code> and other env vars in Configuration \u2192 Application settings</li> <li>Map your custom domain (optional)</li> </ol>"},{"location":"deployment/azure/#option-3-azure-kubernetes-service-aks","title":"\ud83d\ude80 Option 3: Azure Kubernetes Service (AKS)","text":"<p>Use your existing Kubernetes deployment instructions, but deploy to AKS.</p> <ul> <li>Deploy with Helm or <code>kubectl</code></li> <li>Use Azure Load Balancer or Application Gateway</li> <li>Store secrets in Azure Key Vault (optional)</li> </ul>"},{"location":"deployment/azure/#secrets-config","title":"\ud83d\udd10 Secrets &amp; Config","text":"<p>Use Azure CLI to upload your <code>.env</code> values to App Config or Key Vault:</p> <pre><code>az keyvault secret set --vault-name my-kv --name JWT-SECRET --value \"super-secret\"\n</code></pre> <p>Then reference in App Service / Container App using environment variables.</p>"},{"location":"deployment/azure/#dns-tls","title":"\ud83d\udce1 DNS &amp; TLS","text":"<ul> <li>Use Azure Front Door or Application Gateway to handle TLS</li> <li>Point your domain to the public IP or hostname of the service</li> </ul> <p>Example:</p> <pre><code>gateway.example.com \u2192 mygateway.eastus.azurecontainerapps.io\n</code></pre>"},{"location":"deployment/compose/","title":"\ud83e\udde9 Docker Compose","text":"<p>Running MCP Gateway with Compose spins up a full stack (Gateway, Postgres, Redis, optional MPC servers) behind a single YAML file. The Makefile detects Podman or Docker automatically, and you can override it with <code>COMPOSE_CMD=</code>. Health-checks (<code>service_healthy</code>) gate the Gateway until the database is ready, preventing race conditions.</p>"},{"location":"deployment/compose/#configure-the-compose-command-to-use","title":"Configure the compose command to use","text":"<p>For example, install and use Docker Compose v2:</p> <pre><code>sudo apt install docker-buildx docker-compose-v2\nexport COMPOSE_CMD=\"docker compose\"\n</code></pre>"},{"location":"deployment/compose/#build-the-images","title":"\ud83d\udc33/\ud83e\uddad Build the images","text":"<pre><code>docker pull ghcr.io/ibm/mcp-context-forge:latest\n</code></pre>"},{"location":"deployment/compose/#build-the-images-when-doing-local-development","title":"\ud83d\udc33/\ud83e\uddad Build the images (when doing local development)","text":""},{"location":"deployment/compose/#using-make-preferred","title":"Using Make (preferred)","text":"Target Image Dockerfile Notes <code>make podman</code> <code>mcpgateway:latest</code> Containerfile Rootless Podman, dev-oriented <code>make podman-prod</code> <code>mcpgateway:latest</code> Containerfile.lite Ultra-slim UBI 9-micro build <code>make docker</code> <code>mcpgateway:latest</code> Containerfile Docker Desktop / CI runners <code>make docker-prod</code> <code>mcpgateway:latest</code> Containerfile.lite Same multi-stage \"lite\" build <p>Remember to tag the image or configure the correct image in <code>docker-compose.yml</code></p>"},{"location":"deployment/compose/#manual-equivalents","title":"Manual equivalents","text":"<pre><code># Podman (dev image)\npodman build -t mcpgateway-dev:latest -f Containerfile .\n\n# Podman (prod image, AMD64, squash layers)\npodman build --platform=linux/amd64 --squash \\\n  -t mcpgateway:latest -f Containerfile.lite .\n\n# Docker (dev image)\ndocker build -t mcpgateway-dev:latest -f Containerfile .\n\n# Docker (prod image)\ndocker build -t mcpgateway:latest -f Containerfile.lite .\n</code></pre> <p>Apple Silicon caveat <code>Containerfile.lite</code> derives from ubi9-micro. Running it via QEMU emulation on M-series Macs often fails with a <code>glibc x86-64-v2</code> error. Use the regular image or build a native <code>linux/arm64</code> variant on Mac.</p>"},{"location":"deployment/compose/#start-the-compose-stack","title":"\ud83c\udfc3 Start the Compose stack","text":""},{"location":"deployment/compose/#with-make","title":"With Make","text":"<pre><code>make compose-up                   # auto-detects engine\nCOMPOSE_ENGINE=docker make compose-up   # force Docker\nCOMPOSE_ENGINE=podman make compose-up   # force Podman\n</code></pre>"},{"location":"deployment/compose/#without-make","title":"Without Make","text":"Make target Docker CLI Podman built-in podman-compose <code>compose-up</code> <code>docker compose -f podman-compose.yml up -d</code> <code>podman compose -f podman-compose.yml up -d</code> <code>podman-compose -f podman-compose.yml up -d</code> <code>compose-restart</code> <code>docker compose up -d --pull=missing --build</code> idem idem <code>compose-logs</code> <code>docker compose logs -f</code> <code>podman compose logs -f</code> <code>podman-compose logs -f</code> <code>compose-ps</code> <code>docker compose ps</code> <code>podman compose ps</code> <code>podman-compose ps</code> <code>compose-stop</code> <code>docker compose stop</code> <code>podman compose stop</code> <code>podman-compose stop</code> <code>compose-down</code> <code>docker compose down</code> <code>podman compose down</code> <code>podman-compose down</code> <code>compose-clean</code> <code>docker compose down -v</code> (removes volumes) <code>podman compose down -v</code> <code>podman-compose down -v</code>"},{"location":"deployment/compose/#access-and-verify","title":"\ud83c\udf10 Access and verify","text":"<ul> <li>Gateway URL: http://localhost:4444   (Bound to <code>0.0.0.0</code> inside the container so port-forwarding works.)</li> </ul> <pre><code>curl http://localhost:4444/health    # {\"status\":\"ok\"}\n</code></pre> <ul> <li>Logs: <code>make compose-logs</code> or raw <code>docker compose logs -f gateway</code>.</li> </ul>"},{"location":"deployment/compose/#selecting-a-database","title":"\ud83d\uddc4 Selecting a database","text":"<p>Uncomment one service block in <code>podman-compose.yml</code> and align <code>DATABASE_URL</code>:</p> Service block Connection string <code>postgres:</code> (default) <code>postgresql://postgres:...@postgres:5432/mcp</code> <code>mariadb:</code> <code>mysql+pymysql://admin:...@mariadb:3306/mcp</code> <code>mysql:</code> <code>mysql+pymysql://mysql:...@mysql:3306/mcp</code> <code>mongodb:</code> <code>mongodb://admin:...@mongodb:27017/mcp</code> <p>Named volumes (<code>pgdata</code>, <code>mariadbdata</code>, <code>mysqldata</code>, <code>mongodata</code>) isolate persistent data.</p>"},{"location":"deployment/compose/#lifecycle-cheatsheet","title":"\ud83d\udd04 Lifecycle cheatsheet","text":"Task Make Manual (engine-agnostic) Start / create <code>make compose-up</code> <code>&lt;engine&gt; compose up -d</code> Re-create changed <code>make compose-restart</code> <code>&lt;engine&gt; compose up -d --pull=missing --build</code> Tail logs <code>make compose-logs</code> <code>&lt;engine&gt; compose logs -f</code> Shell into gateway <code>make compose-shell</code> <code>&lt;engine&gt; compose exec gateway /bin/sh</code> Stop <code>make compose-stop</code> <code>&lt;engine&gt; compose stop</code> Remove containers <code>make compose-down</code> <code>&lt;engine&gt; compose down</code> Nuke volumes <code>make compose-clean</code> <code>&lt;engine&gt; compose down -v</code> <p><code>&lt;engine&gt;</code> = <code>docker</code>, <code>podman</code>, or <code>podman-compose</code> as shown earlier.</p>"},{"location":"deployment/compose/#troubleshooting-port-publishing-on-wsl2-rootless-podman","title":"\ud83d\udd0d Troubleshooting port publishing on WSL2 (rootless Podman)","text":"<pre><code># Verify the port is listening (dual-stack)\nss -tlnp | grep 4444        # modern tool\nnetstat -anp | grep 4444    # legacy fallback\n</code></pre> <p>A line like <code>LISTEN rootlessport</code> is normal \u2013 the IPv6 wildcard socket (<code>::</code>) also accepts IPv4 when <code>net.ipv6.bindv6only=0</code> (the default on Linux).</p> <p>WSL2 quirk</p> <p>WSL's NAT maps only the IPv6 side, so <code>http://127.0.0.1:4444</code> fails from Windows. Tell Podman you are inside WSL and restart your containers:</p> <pre><code># inside the WSL distro\necho \"wsl\" | sudo tee /etc/containers/podman-machine\n</code></pre> <p><code>ss</code> should now show an explicit <code>0.0.0.0:4444</code> listener, making the service reachable from Windows and the LAN.</p>"},{"location":"deployment/compose/#references","title":"\ud83d\udcda References","text":"<ul> <li>Docker Compose CLI (<code>up</code>, <code>logs</code>, <code>down</code>) \u2013 official docs</li> <li>Podman's integrated compose wrapper \u2013 man page</li> <li><code>podman-compose</code> rootless implementation \u2013 GitHub project</li> <li>Health-check gating with <code>depends_on: condition: service_healthy</code></li> <li>UBI9 runtime on Apple Silicon limitations (<code>x86_64-v2</code> glibc)</li> <li>General Containerfile build guidance (Fedora/Red Hat)</li> </ul>"},{"location":"deployment/container/","title":"\ud83d\udce6 Container Deployment","text":"<p>You can run MCP Gateway as a fully self-contained container. This is the recommended method for production or platform-agnostic deployments. You can use any container engine (ex: Docker or Podman).</p>"},{"location":"deployment/container/#quick-start-pre-built-container-image","title":"Quick Start (Pre-built Container Image)","text":"<p>If you just want to run the gateway using the official OCI container image from GitHub Container Registry:</p> <pre><code>docker run -d --name mcpgateway \\\n  -p 4444:4444 \\\n  -e HOST=0.0.0.0 \\\n  -e JWT_SECRET_KEY=my-test-key \\\n  -e BASIC_AUTH_USER=admin \\\n  -e BASIC_AUTH_PASSWORD=changeme \\\n  -e AUTH_REQUIRED=true \\\n  -e DATABASE_URL=sqlite:///./mcp.db \\\n  --network=host \\\n  ghcr.io/ibm/mcp-context-forge:latest\n\ndocker logs mcpgateway\n</code></pre> <p>You can now access the UI at http://localhost:4444/admin</p>"},{"location":"deployment/container/#build-the-container","title":"\ud83d\udc33 Build the Container","text":""},{"location":"deployment/container/#using-podman-recommended","title":"Using Podman (recommended)","text":"<pre><code>make podman\n</code></pre>"},{"location":"deployment/container/#using-docker-manual-alternative","title":"Using Docker (manual alternative)","text":"<pre><code>docker build -t mcpgateway:latest -f Containerfile .\n</code></pre> <p>The base image uses <code>python:3.11-slim</code> with Gunicorn and Uvicorn workers.</p>"},{"location":"deployment/container/#run-the-container","title":"\ud83c\udfc3 Run the Container","text":""},{"location":"deployment/container/#with-http-no-tls","title":"With HTTP (no TLS)","text":"<pre><code>make podman-run\n</code></pre> <p>This starts the app at <code>http://localhost:4444</code>.</p>"},{"location":"deployment/container/#with-self-signed-tls-https","title":"With Self-Signed TLS (HTTPS)","text":"<pre><code>make podman-run-ssl\n</code></pre> <p>Runs the gateway using certs from <code>./certs/</code>, available at:</p> <pre><code>https://localhost:4444\n</code></pre>"},{"location":"deployment/container/#runtime-configuration","title":"\u2699 Runtime Configuration","text":"<p>All environment variables can be passed via:</p> <ul> <li><code>docker run -e KEY=value</code></li> <li>A mounted <code>.env</code> file (<code>--env-file .env</code>)</li> </ul>"},{"location":"deployment/container/#test-the-running-container","title":"\ud83e\uddea Test the Running Container","text":"<pre><code>curl http://localhost:4444/health\ncurl http://localhost:4444/tools\n</code></pre> <p>Use <code>curl -k</code> if running with self-signed TLS</p>"},{"location":"deployment/container/#stop-clean-up","title":"\ud83e\uddfc Stop &amp; Clean Up","text":"<pre><code>podman stop mcpgateway\npodman rm mcpgateway\n</code></pre> <p>Or with Docker:</p> <pre><code>docker stop mcpgateway\ndocker rm mcpgateway\n</code></pre>"},{"location":"deployment/fly-io/","title":"\u2699\ufe0f Fly.io Deployment Guide for MCP Gateway","text":"<p>This guide covers the complete deployment workflow for the MCP Gateway on Fly.io, including common troubleshooting steps.</p>"},{"location":"deployment/fly-io/#overview","title":"Overview","text":"<p>Fly.io is a global app platform for running containers close to your users, with built-in TLS, persistent volumes, and managed Postgres support. It offers a generous free tier and automatic HTTPS with fly.dev subdomains.</p>"},{"location":"deployment/fly-io/#1-prerequisites","title":"1 \u00b7 Prerequisites","text":"Requirement Details Fly.io account Sign up Fly CLI Install via Homebrew: <code>brew install flyctl</code> or see Fly docs Docker or Podman For local image builds (optional) Containerfile The included Containerfile with psycopg2-binary support"},{"location":"deployment/fly-io/#2-quick-start-recommended","title":"2 \u00b7 Quick Start (Recommended)","text":""},{"location":"deployment/fly-io/#21-initialize-fly-project","title":"2.1 Initialize Fly project","text":"<p><pre><code>fly launch --name your-app-name --no-deploy\n</code></pre> This creates a new Fly app without deploying immediately.</p>"},{"location":"deployment/fly-io/#22-create-and-attach-fly-postgres","title":"2.2 Create and attach Fly Postgres","text":"<pre><code># Create postgres (choose Development configuration for testing)\nfly postgres create --name your-app-db --region yyz\n\n# Note the connection details from the output, you'll need the password\n</code></pre>"},{"location":"deployment/fly-io/#23-set-secrets","title":"2.3 Set secrets","text":"<pre><code># Set authentication secrets\nfly secrets set JWT_SECRET_KEY=$(openssl rand -hex 32)\nfly secrets set BASIC_AUTH_USER=admin BASIC_AUTH_PASSWORD=your-secure-password\n\n# Set database URL (CRITICAL: use postgresql:// not postgres://)\nfly secrets set DATABASE_URL=\"postgresql://postgres:YOUR_PASSWORD@your-app-db.flycast:5432/postgres\"\n</code></pre> <p>\u26a0\ufe0f Important: Always use <code>postgresql://</code> scheme, not <code>postgres://</code>. The latter causes SQLAlchemy dialect loading errors.</p>"},{"location":"deployment/fly-io/#24-deploy-the-app","title":"2.4 Deploy the app","text":"<pre><code>fly deploy\n</code></pre>"},{"location":"deployment/fly-io/#3-containerfile-requirements","title":"3 \u00b7 Containerfile Requirements","text":"<p>Ensure your Containerfile explicitly installs PostgreSQL dependencies:</p> <pre><code># Create virtual environment, upgrade pip and install dependencies\nRUN python3 -m venv /app/.venv &amp;&amp; \\\n/app/.venv/bin/python3 -m pip install --upgrade pip setuptools pdm uv &amp;&amp; \\\n/app/.venv/bin/python3 -m pip install psycopg2-binary &amp;&amp; \\\n/app/.venv/bin/python3 -m uv pip install \".[redis]\"\n</code></pre> <p>The explicit <code>psycopg2-binary</code> installation is required because uv may not properly install optional dependencies.</p>"},{"location":"deployment/fly-io/#4-flytoml-configuration","title":"4 \u00b7 fly.toml Configuration","text":"<p>Your <code>fly.toml</code> should look like this:</p> <pre><code>app = \"your-app-name\"\nprimary_region = \"yyz\"\n\n[build]\ndockerfile = \"Containerfile\"\n\n[env]\nHOST = \"0.0.0.0\"\nPORT = \"4444\"\n\n[http_service]\ninternal_port = 4444\nforce_https = true\nauto_stop_machines = \"stop\"\nauto_start_machines = true\nmin_machines_running = 0\nprocesses = [\"app\"]\n\n[[vm]]\nmemory = \"1gb\"\ncpu_kind = \"shared\"\ncpus = 1\n</code></pre> <p>Note: Don't put secrets like <code>DATABASE_URL</code> in <code>fly.toml</code> - use <code>fly secrets set</code> instead.</p>"},{"location":"deployment/fly-io/#5-testing-your-deployment","title":"5 \u00b7 Testing Your Deployment","text":""},{"location":"deployment/fly-io/#51-check-app-status","title":"5.1 Check app status","text":"<pre><code>fly status\nfly logs\n</code></pre>"},{"location":"deployment/fly-io/#52-test-endpoints","title":"5.2 Test endpoints","text":"<pre><code># Health check (no auth required)\ncurl https://your-app-name.fly.dev/health\n\n# Protected endpoints (require auth)\ncurl -u admin:your-password https://your-app-name.fly.dev/docs\ncurl -u admin:your-password https://your-app-name.fly.dev/tools\n</code></pre>"},{"location":"deployment/fly-io/#53-expected-responses","title":"5.3 Expected responses","text":"<ul> <li>Health: <code>{\"status\":\"healthy\"}</code></li> <li>Protected endpoints without auth: <code>{\"detail\":\"Not authenticated\"}</code></li> <li>Protected endpoints with auth: JSON response with data</li> </ul>"},{"location":"deployment/fly-io/#6-troubleshooting","title":"6 \u00b7 Troubleshooting","text":""},{"location":"deployment/fly-io/#common-issue-1-sqlalchemy-postgres-dialect-error","title":"Common Issue 1: SQLAlchemy postgres dialect error","text":"<pre><code>sqlalchemy.exc.NoSuchModuleError: Can't load plugin: sqlalchemy.dialects:postgres\n</code></pre> <p>Solutions: 1. Ensure <code>psycopg2-binary</code> is explicitly installed in Containerfile 2. Use <code>postgresql://</code> not <code>postgres://</code> in DATABASE_URL 3. Rebuild with <code>fly deploy --no-cache</code></p>"},{"location":"deployment/fly-io/#common-issue-2-database-connection-refused","title":"Common Issue 2: Database connection refused","text":"<p>Solutions: 1. Verify DATABASE_URL format: <code>postgresql://postgres:PASSWORD@your-db.flycast:5432/postgres</code> 2. Check postgres app is running: <code>fly status -a your-app-db</code> 3. Verify password matches postgres creation output</p>"},{"location":"deployment/fly-io/#common-issue-3-machines-not-updating","title":"Common Issue 3: Machines not updating","text":"<p>Solutions: <pre><code># Force machine updates\nfly machine list\nfly machine update MACHINE_ID --image your-new-image\n\n# Or restart all machines\nfly scale count 0\nfly scale count 1\n</code></pre></p>"},{"location":"deployment/fly-io/#7-production-considerations","title":"7 \u00b7 Production Considerations","text":""},{"location":"deployment/fly-io/#security","title":"Security","text":"<ul> <li>Change default <code>BASIC_AUTH_PASSWORD</code> to a strong password</li> <li>Consider using JWT tokens for API access</li> <li>Enable Fly's private networking for database connections</li> </ul>"},{"location":"deployment/fly-io/#scaling","title":"Scaling","text":"<pre><code># Scale to multiple machines for HA\nfly scale count 2\n\n# Scale machine resources\nfly scale memory 2gb\n</code></pre>"},{"location":"deployment/fly-io/#monitoring","title":"Monitoring","text":"<pre><code># View real-time logs\nfly logs -f\n\n# Check machine metrics\nfly machine status MACHINE_ID\n</code></pre>"},{"location":"deployment/fly-io/#8-clean-deployment-script","title":"8 \u00b7 Clean Deployment Script","text":"<p>For a completely fresh deployment:</p> <pre><code>#!/bin/bash\nset -e\n\nAPP_NAME=\"your-app-name\"\nDB_NAME=\"${APP_NAME}-db\"\nREGION=\"yyz\"\nPASSWORD=$(openssl rand -base64 32)\n\necho \"\ud83d\ude80 Deploying MCP Gateway to Fly.io...\"\n\n# Create app\nfly launch --name $APP_NAME --no-deploy --region $REGION\n\n# Create postgres\nfly postgres create --name $DB_NAME --region $REGION\n\n# Set secrets\nfly secrets set JWT_SECRET_KEY=$(openssl rand -hex 32)\nfly secrets set BASIC_AUTH_USER=admin \nfly secrets set BASIC_AUTH_PASSWORD=$PASSWORD\n\n# Get postgres password and set DATABASE_URL\necho \"\u26a0\ufe0f  Set your DATABASE_URL manually with the postgres password:\"\necho \"fly secrets set DATABASE_URL=\\\"postgresql://postgres:YOUR_PG_PASSWORD@${DB_NAME}.flycast:5432/postgres\\\"\"\n\n# Deploy\necho \"\ud83c\udfd7\ufe0f  Ready to deploy. Run: fly deploy\"\n</code></pre>"},{"location":"deployment/fly-io/#9-additional-resources","title":"9 \u00b7 Additional Resources","text":"<ul> <li>Fly.io Documentation</li> <li>Fly Postgres Guide</li> <li>Fly Secrets Management</li> </ul> <p>Success indicators: - \u2705 <code>fly status</code> shows machines as \"started\" - \u2705 <code>/health</code> endpoint returns <code>{\"status\":\"healthy\"}</code> - \u2705 Protected endpoints require authentication - \u2705 No SQLAlchemy errors in logs</p>"},{"location":"deployment/google-cloud-run/","title":"\u2601\ufe0f Deploying MCP Gateway on Google Cloud Run","text":"<p>MCP Gateway can be deployed to Google Cloud Run, a fully managed, autoscaling platform for containerized applications. This guide provides step-by-step instructions to provision PostgreSQL and Redis backends, deploy the container, configure environment variables, authenticate using JWT, and monitor logs\u2014all optimized for cost-efficiency.</p>"},{"location":"deployment/google-cloud-run/#overview","title":"\u2705 Overview","text":"<p>Google Cloud Run is an ideal platform for MCP Gateway due to its:</p> <ul> <li>Serverless and cost-efficient model with scale-to-zero capability.</li> <li>Public HTTPS endpoints with automatic TLS configuration.</li> <li>Seamless integration with Cloud SQL (PostgreSQL) and Memorystore (Redis).</li> <li>Compatibility with public container registries like GitHub's <code>ghcr.io</code>.</li> </ul> <p>You can deploy the public image directly:</p> <pre><code>ghcr.io/ibm/mcp-context-forge:latest\n</code></pre>"},{"location":"deployment/google-cloud-run/#prerequisites","title":"\ud83d\udee0 Prerequisites","text":""},{"location":"deployment/google-cloud-run/#1-install-and-initialize-google-cloud-cli-gcloud","title":"1. Install and Initialize Google Cloud CLI (<code>gcloud</code>)","text":"<p>Install the Google Cloud SDK:</p> <ul> <li>macOS (Homebrew):</li> </ul> <pre><code>brew install --cask google-cloud-sdk\n</code></pre> <ul> <li>Debian/Ubuntu:</li> </ul> <p>These steps also apply to WSL2 running Ubuntu.</p> <pre><code># Update package lists and install necessary utilities\nsudo apt-get update\nsudo apt-get install -y apt-transport-https ca-certificates gnupg curl\n\n# Import the Google Cloud public key securely\n# This is for newer distributions (Debian 9+ or Ubuntu 18.04+).\ncurl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg\n\n# Add the Google Cloud SDK distribution URI as a package source\n# This is for newer distributions, ensuring packages are signed by the key we just added.\necho \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main\" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list\n\n# Update your package lists again to recognize the new repository\nsudo apt-get update\n\n# Install the Google Cloud CLI\nsudo apt-get install -y google-cloud-cli\n</code></pre> <ul> <li>Windows (PowerShell):</li> </ul> <pre><code>winget install --id Google.CloudSDK\n</code></pre> <p>After installation, initialize the CLI:</p> <pre><code>gcloud init\n</code></pre> <p>Authenticate with your Google Cloud account:</p> <pre><code>gcloud auth login\n</code></pre> <p>Set a project ID:</p> <pre><code>gcloud config set project PROJECT_ID\n</code></pre>"},{"location":"deployment/google-cloud-run/#2-enable-required-apis","title":"2. Enable Required APIs","text":"<p>Enable the necessary Google Cloud APIs:</p> <pre><code># This might take a minute..\ngcloud services enable \\\n  run.googleapis.com \\\n  sqladmin.googleapis.com \\\n  redis.googleapis.com\n</code></pre>"},{"location":"deployment/google-cloud-run/#3-install-docker","title":"3. Install Docker","text":"<p>Ensure Docker is installed for local testing and JWT token generation. Visit Docker's official website for installation instructions.</p>"},{"location":"deployment/google-cloud-run/#4-set-environment-variables","title":"4. Set Environment Variables","text":"<p>Prepare the following environment variables:</p> Variable Description <code>JWT_SECRET_KEY</code> Secret key for signing JWT tokens <code>BASIC_AUTH_USER</code> Username for HTTP Basic Authentication <code>BASIC_AUTH_PASSWORD</code> Password for HTTP Basic Authentication <code>AUTH_REQUIRED</code> Set to <code>true</code> to enforce authentication <code>DATABASE_URL</code> PostgreSQL connection string <code>REDIS_URL</code> Redis connection string <code>CACHE_TYPE</code> Set to <code>redis</code> for production environments <code>PORT</code> Port number the application listens on (e.g., <code>4444</code>) <p>Consider creating a <code>.env.gcr</code> file where you will record the various settings used during deployment.</p> <pre><code># \u2500\u2500\u2500 Google Cloud project \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nPROJECT_ID=\nREGION=us-central1\nSERVICE_NAME=mcpgateway\n\n# \u2500\u2500\u2500 Authentication \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nJWT_SECRET_KEY=\nBASIC_AUTH_USER=\nBASIC_AUTH_PASSWORD=\nAUTH_REQUIRED=true\n\n# \u2500\u2500\u2500 Cloud SQL (PostgreSQL) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nSQL_INSTANCE=mcpgw-db\nSQL_REGION=us-central1\nDATABASE_URL=postgresql://postgres:&lt;PASSWORD&gt;@&lt;SQL_IP&gt;:5432/mcpgw\n\n# \u2500\u2500\u2500 Memorystore (Redis) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nREDIS_INSTANCE=mcpgw-redis\nREDIS_REGION=us-central1\nREDIS_URL=redis://&lt;REDIS_IP&gt;:6379/0\nCACHE_TYPE=redis\n\n# \u2500\u2500\u2500 Application \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nPORT=4444\n</code></pre>"},{"location":"deployment/google-cloud-run/#setup-steps","title":"\u2699\ufe0f Setup Steps","text":""},{"location":"deployment/google-cloud-run/#1-provision-cloud-sql-postgresql","title":"1. Provision Cloud SQL (PostgreSQL)","text":"<p>Create a PostgreSQL instance using the <code>db-f1-micro</code> tier for cost efficiency:</p> <pre><code># POSTGRES_16 and POSTGRES_17 default to Enterprise Plus; adding --edition=ENTERPRISE lets you pick db-f1-micro\ngcloud sql instances create mcpgw-db \\\n  --database-version=POSTGRES_17 \\\n  --edition=ENTERPRISE \\\n  --tier=db-f1-micro \\\n  --region=us-central1\n</code></pre> <p>Set the password for the <code>postgres</code> user:</p> <pre><code>gcloud sql users set-password postgres \\\n  --instance=mcpgw-db \\\n  --password=mysecretpassword\n</code></pre> <p>Create the <code>mcpgw</code> database:</p> <pre><code>gcloud sql databases create mcpgw --instance=mcpgw-db\n</code></pre> <p>Retrieve the IP address of the instance:</p> <pre><code>gcloud sql instances describe mcpgw-db \\\n  --format=\"value(ipAddresses.ipAddress)\"\n</code></pre> <p>Note: The <code>db-f1-micro</code> tier is a shared-core instance designed for low-cost development and testing environments. It is not covered by the Cloud SQL SLA.</p>"},{"location":"deployment/google-cloud-run/#2-provision-memorystore-redis","title":"2. Provision Memorystore (Redis)","text":"<p>Create a Redis instance using the Basic Tier with 1 GiB capacity:</p> <pre><code>gcloud redis instances create mcpgw-redis \\\n  --region=us-central1 \\\n  --tier=BASIC \\\n  --size=1\n</code></pre> <p>Retrieve the host IP address:</p> <pre><code>gcloud redis instances describe mcpgw-redis \\\n  --region=us-central1 \\\n  --format=\"value(host)\"\n</code></pre> <p>Note: The Basic Tier provides a standalone Redis instance suitable for applications that can tolerate potential data loss during failures.</p>"},{"location":"deployment/google-cloud-run/#3-deploy-to-google-cloud-run","title":"3. Deploy to Google Cloud Run","text":"<p>Cloud Run only accepts container images that live in Artifact Registry or the older Container Registry endpoints; anything pulled from the public internet (for example ghcr.io) must first be proxied or copied into Artifact Registry.</p>"},{"location":"deployment/google-cloud-run/#set-your-project-id","title":"Set Your Project ID","text":"<p>Begin by setting your Google Cloud project ID as an environment variable:</p> <pre><code>export PROJECT_ID=\"your-project-id\"\n</code></pre> <p>Replace <code>\"your-project-id\"</code> with your actual Google Cloud project ID.</p>"},{"location":"deployment/google-cloud-run/#enable-required-apis","title":"Enable Required APIs","text":"<p>Ensure that the necessary Google Cloud APIs are enabled:</p> <pre><code>gcloud services enable artifactregistry.googleapis.com\n</code></pre>"},{"location":"deployment/google-cloud-run/#create-a-remote-repository","title":"Create a Remote Repository","text":"<p>Set up a remote repository in Artifact Registry that proxies GitHub Container Registry (GHCR):</p> <pre><code>gcloud artifacts repositories create ghcr-remote \\\n  --project=$PROJECT_ID \\\n  --repository-format=docker \\\n  --location=us-central1 \\\n  --description=\"Proxy for GitHub Container Registry\" \\\n  --mode=remote-repository \\\n  --remote-docker-repo=https://ghcr.io\n</code></pre>"},{"location":"deployment/google-cloud-run/#retrieve-cloud-sql-instance-connection-name","title":"Retrieve Cloud SQL Instance Connection Name","text":"<pre><code>gcloud sql instances describe mcpgw-db \\\n  --format=\"value(connectionName)\"\n</code></pre> <p>It will output something like this:</p> <pre><code>your-project-id:us-central1:mcpgw-db\n</code></pre>"},{"location":"deployment/google-cloud-run/#allow-ingress-to-your-database","title":"Allow ingress to your database.","text":"<p>Consider only allowing the Cloud Run IP range.</p> <pre><code>gcloud sql instances patch mcpgw-db \\\n  --authorized-networks=0.0.0.0/0\n</code></pre>"},{"location":"deployment/google-cloud-run/#deploy-the-mcp-gateway-container-with-minimal-resource-allocation","title":"Deploy the MCP Gateway container with minimal resource allocation:","text":"<pre><code>gcloud run deploy mcpgateway \\\n  --image=us-central1-docker.pkg.dev/$PROJECT_ID/ghcr-remote/ibm/mcp-context-forge:latest\n  --region=us-central1 \\\n  --platform=managed \\\n  --allow-unauthenticated \\\n  --port=4444 \\\n  --cpu=1 \\\n  --memory=512i \\\n  --max-instances=1 \\\n  --set-env-vars=\\\nJWT_SECRET_KEY=jwt-secret-key,\\\nBASIC_AUTH_USER=admin,\\\nBASIC_AUTH_PASSWORD=changeme,\\\nAUTH_REQUIRED=true,\\\nDATABASE_URL=postgresql://postgres:mysecretpassword@&lt;SQL_IP&gt;:5432/mcpgw,\\\nREDIS_URL=redis://&lt;REDIS_IP&gt;:6379/0,\\\nCACHE_TYPE=redis,\\\nHOST=0.0.0.0,\\\nGUNICORN_WORKERS=1\n</code></pre> <p>Replace <code>&lt;SQL_IP&gt;</code> and <code>&lt;REDIS_IP&gt;</code> with the actual IP addresses obtained from the previous steps. Do not leave out the HOST=0.0.0.0 to ensure the container listens on all ports, or the container engine won't be able to reach the container. Setting the number of GUNICORN_WORKERS lets you control how much memory the service consumes.</p>"},{"location":"deployment/google-cloud-run/#check-the-logs","title":"Check the logs","text":""},{"location":"deployment/google-cloud-run/#gcloud-run-services-logs-read-mcpgateway-regionus-central1","title":"<pre><code>gcloud run services logs read mcpgateway --region=us-central1\n</code></pre>","text":""},{"location":"deployment/google-cloud-run/#check-that-the-database-is-created","title":"Check that the database is created:","text":"<p>You can use any PostgreSQL client, such as <code>psql</code>. You should see the list of tables when using <code>dt;</code></p> <pre><code>psql postgresql://postgres:mysecretpassword@&lt;SQL_IP&gt;:5432/mcpgw\n\nmcpgw=&gt; \\dt;\n                    List of relations\n Schema |             Name             | Type  |  Owner\n--------+------------------------------+-------+----------\n public | gateways                     | table | postgres\n public | mcp_messages                 | table | postgres\n public | mcp_sessions                 | table | postgres\n public | prompt_gateway_association   | table | postgres\n public | prompt_metrics               | table | postgres\n public | prompts                      | table | postgres\n public | resource_gateway_association | table | postgres\n public | resource_metrics             | table | postgres\n public | resource_subscriptions       | table | postgres\n public | resources                    | table | postgres\n public | server_metrics               | table | postgres\n public | server_prompt_association    | table | postgres\n public | server_resource_association  | table | postgres\n public | server_tool_association      | table | postgres\n public | servers                      | table | postgres\n public | tool_gateway_association     | table | postgres\n public | tool_metrics                 | table | postgres\n public | tools                        | table | postgres\n(18 rows)\n</code></pre>"},{"location":"deployment/google-cloud-run/#authentication-and-access","title":"\ud83d\udd12 Authentication and Access","text":""},{"location":"deployment/google-cloud-run/#generate-a-jwt-bearer-token","title":"Generate a JWT Bearer Token","text":"<p>Use the MCP Gateway container to generate a JWT token:</p> <pre><code>docker run -it --rm ghcr.io/ibm/mcp-context-forge:latest \\\n  python3 -m mcpgateway.utils.create_jwt_token -u admin --secret jwt-secret-key\n</code></pre> <p>Export the token as an environment variable:</p> <pre><code>export MCPGATEWAY_BEARER_TOKEN=&lt;paste-token-here&gt;\n</code></pre>"},{"location":"deployment/google-cloud-run/#perform-smoke-tests","title":"Perform Smoke Tests","text":"<p>Test the <code>/health</code>, <code>/version</code>, and <code>/tools</code> endpoints:</p> <pre><code># Check that the service is healthy\ncurl -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     https://&lt;your-cloud-run-url&gt;/health\n\n# Check that version reports the version and show Postgres/Redis as connected\ncurl -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     https://&lt;your-cloud-run-url&gt;/health\n\n# Check that tools return an empty list []\ncurl -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n     https://&lt;your-cloud-run-url&gt;/tools\n</code></pre> <p>Replace <code>&lt;your-cloud-run-url&gt;</code> with the URL provided after deploying the service.</p>"},{"location":"deployment/google-cloud-run/#logs-and-monitoring","title":"\ud83d\udcca Logs and Monitoring","text":""},{"location":"deployment/google-cloud-run/#view-logs-via-cli","title":"View Logs via CLI","text":"<p>Tailing real-time logs requires <code>google-cloud-cli-log-streaming</code>. Ex: <code>sudo apt-get install google-cloud-cli-log-streaming</code>:</p> <pre><code>gcloud beta run services logs tail mcpgateway --region=us-central1\n</code></pre>"},{"location":"deployment/google-cloud-run/#access-logs-via-console","title":"Access Logs via Console","text":"<p>Navigate to the Cloud Run Console and select your service to view logs and metrics.</p>"},{"location":"deployment/google-cloud-run/#github-actions-deployment-optional","title":"\ud83d\udce6 GitHub Actions Deployment (Optional)","text":"<p>Automate builds and deployments using GitHub Actions. Refer to the workflow file:</p> <pre><code>.github/workflows/google-cloud-run.yml\n</code></pre> <p>This workflow:</p> <ul> <li>Restores and updates a local BuildKit layer cache.</li> <li>Builds the Docker image from <code>Containerfile.lite</code>.</li> <li>Pushes the image to Google Artifact Registry.</li> <li>Deploys to Google Cloud Run with <code>--max-instances=1</code>.</li> </ul>"},{"location":"deployment/google-cloud-run/#setting-up-permissions-for-google-cloud-run-deployment","title":"Setting up permissions for Google Cloud Run deployment","text":"<p>Instead of project-wide permissions, grant permissions on specific resources:</p> <pre><code># Create service account\ngcloud iam service-accounts create github-mcpgateway \\\n  --display-name=\"GitHub MCP Gateway Deploy\"\n\n# Grant permission ONLY on the specific Cloud Run service\ngcloud run services add-iam-policy-binding mcpgateway \\\n  --region=us-central1 \\\n  --member=\"serviceAccount:github-mcpgateway@YOUR-PROJECT-ID.iam.gserviceaccount.com\" \\\n  --role=\"roles/run.developer\"\n\n# Grant permission ONLY on the specific Artifact Registry repository\ngcloud artifacts repositories add-iam-policy-binding mcpgateway \\\n  --location=us-central1 \\\n  --member=\"serviceAccount:github-mcpgateway@YOUR-PROJECT-ID.iam.gserviceaccount.com\" \\\n  --role=\"roles/artifactregistry.writer\"\n\n# Create the key\ngcloud iam service-accounts keys create restricted-key.json \\\n  --iam-account=github-mcpgateway@YOUR-PROJECT-ID.iam.gserviceaccount.com\n</code></pre>"},{"location":"deployment/google-cloud-run/#notes-and-tips","title":"\ud83d\udcd8 Notes and Tips","text":"<ul> <li> <p>HTTPS by Default: Cloud Run services are accessible over HTTPS without additional configuration.</p> </li> <li> <p>Custom Domains: You can map custom domains via the Cloud Run settings.</p> </li> <li> <p>Secret Management: Consider using Secret Manager for managing sensitive environment variables.</p> </li> <li> <p>Cold Starts: To reduce cold start latency, set a minimum number of instances:</p> </li> </ul> <pre><code>--min-instances=1\n</code></pre> <ul> <li>Monitoring: Utilize Cloud Monitoring for detailed metrics and alerts.</li> </ul>"},{"location":"deployment/google-cloud-run/#feature-summary","title":"\ud83e\udde9 Feature Summary","text":"Feature Supported HTTPS (built-in) \u2705 Custom domains \u2705 PostgreSQL (Cloud SQL) \u2705 Redis (Memorystore) \u2705 Auto-scaling \u2705 Scale-to-zero \u2705 Max instance limit \u2705"},{"location":"deployment/google-cloud-run/#additional-resources","title":"\ud83e\udde0 Additional Resources","text":"<ul> <li>Cloud Run Documentation</li> <li>Cloud SQL for PostgreSQL Documentation</li> <li>Memorystore for Redis Documentation</li> <li>Google Cloud SDK Installation Guide</li> <li>Cloud Run Pricing</li> <li>Cloud SQL Pricing</li> <li>Memorystore Pricing</li> </ul> <p>By following this guide, you can deploy MCP Gateway on Google Cloud Run using the most cost-effective configurations, ensuring efficient resource utilization and seamless scalability.</p>"},{"location":"deployment/helm/","title":"\ud83d\ude80 Deploying the MCP Gateway Stack with Helm","text":"<p>This guide walks you through installing, upgrading, and removing the full MCP Gateway Stack using Helm. The stack includes:</p> <ul> <li>\ud83e\udde0 MCP Context Forge (the gateway)</li> <li>\ud83d\uddc4 PostgreSQL database</li> <li>\u26a1 Redis cache</li> <li>\ud83e\uddd1\u200d\ud83d\udcbb PgAdmin UI (optional)</li> <li>\ud83e\uddf0 Redis Commander UI (optional)</li> </ul> <p>Everything is deployable via Helm on any Kubernetes cluster (Minikube, kind, EKS, AKS, GKE, OpenShift, etc.).</p> <p>\ud83d\udce6 Helm chart location: https://github.com/IBM/mcp-context-forge/tree/main/charts/mcp-stack</p>"},{"location":"deployment/helm/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"Requirement Notes Kubernetes \u2265 1.23 Local (Minikube/kind) or managed (EKS, AKS, GKE, etc.) Helm 3 Used for installing and managing releases kubectl Configured to talk to your target cluster Ingress Controller NGINX, Traefik, or cloud-native (or disable via values.yaml) StorageClass (RWX) Required for PostgreSQL PVC unless persistence is disabled"},{"location":"deployment/helm/#architecture","title":"\ud83e\udded Architecture","text":"<pre><code>flowchart TD\n    subgraph Ingress Layer\n        ingress[NGINX Ingress Controller]\n    end\n\n    subgraph Application Layer\n        mcp[MCP Context Forge]\n        pgadmin[PgAdmin UI&lt;br/&gt;optional]\n        rediscommander[Redis Commander UI&lt;br/&gt;optional]\n    end\n\n    subgraph Data Layer\n        postgres[(PostgreSQL)]\n        redis[(Redis)]\n    end\n\n    ingress --&gt; mcp\n    ingress --&gt; pgadmin\n    ingress --&gt; rediscommander\n\n    mcp --&gt; postgres\n    mcp --&gt; redis\n\n    pgadmin --&gt; postgres\n    rediscommander --&gt; redis</code></pre>"},{"location":"deployment/helm/#step-1-install-helm-kubectl","title":"\ud83d\udee0 Step 1 - Install Helm &amp; kubectl","text":""},{"location":"deployment/helm/#macos","title":"macOS","text":"<pre><code>brew install helm kubernetes-cli\n</code></pre>"},{"location":"deployment/helm/#linux","title":"Linux","text":"<pre><code># Helm\ncurl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\n\n# kubectl\ncurl -LO \"https://dl.k8s.io/release/$(curl -sSL https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\nchmod +x kubectl\nsudo mv kubectl /usr/local/bin\n</code></pre>"},{"location":"deployment/helm/#windows-powershell","title":"Windows (PowerShell)","text":"<pre><code>choco install -y kubernetes-helm kubernetes-cli\n</code></pre> <p>Verify installation:</p> <pre><code>helm version\nkubectl version --short\nkubectl config get-contexts\n</code></pre>"},{"location":"deployment/helm/#step-2-clone-and-inspect-the-chart","title":"\ud83d\udce6 Step 2 - Clone and inspect the chart","text":"<pre><code>git clone https://github.com/IBM/mcp-context-forge.git\ncd mcp-context-forge/charts/mcp-stack\nhelm lint .\n</code></pre>"},{"location":"deployment/helm/#step-3-customize-values","title":"\ud83e\uddfe Step 3 - Customize values","text":"<p>Copy and modify the default <code>values.yaml</code>:</p> <pre><code>cp values.yaml my-values.yaml\n</code></pre> <p>Then edit fields such as:</p> <pre><code>mcpContextForge:\n  image:\n    repository: ghcr.io/ibm/mcp-context-forge\n    tag: latest\n\n  ingress:\n    enabled: true\n    host: gateway.local\n    className: nginx\n\npostgres:\n  credentials:\n    user: admin\n    password: test123\n\npgadmin:\n  enabled: true\n\nredisCommander:\n  enabled: true\n</code></pre>"},{"location":"deployment/helm/#step-4-install-upgrade-the-stack","title":"\ud83d\ude80 Step 4 - Install / Upgrade the stack","text":"<pre><code>helm upgrade --install mcp-stack . \\\n  --namespace mcp --create-namespace \\\n  -f my-values.yaml \\\n  --wait\n</code></pre>"},{"location":"deployment/helm/#step-5-verify-deployment","title":"\u2705 Step 5 - Verify deployment","text":"<pre><code>kubectl get all -n mcp\nhelm status mcp-stack -n mcp\n</code></pre> <p>If using Ingress:</p> <pre><code>kubectl get ingress -n mcp\ncurl http://gateway.local/health\n</code></pre> <p>If not using Ingress:</p> <pre><code>kubectl port-forward svc/mcp-stack-app 8080:80 -n mcp\ncurl http://localhost:8080/health\n</code></pre>"},{"location":"deployment/helm/#step-6-upgrade-rollback","title":"\ud83d\udd04 Step 6 - Upgrade &amp; Rollback","text":""},{"location":"deployment/helm/#upgrade-eg-new-image-tag","title":"Upgrade (e.g. new image tag)","text":"<pre><code>helm upgrade mcp-stack . -n mcp \\\n  --set mcpContextForge.image.tag=v1.2.3 \\\n  --wait\n</code></pre>"},{"location":"deployment/helm/#preview-changes-diff-plugin","title":"Preview changes (diff plugin)","text":"<pre><code>helm plugin install https://github.com/databus23/helm-diff\nhelm diff upgrade mcp-stack . -n mcp -f my-values.yaml\n</code></pre>"},{"location":"deployment/helm/#rollback","title":"Rollback","text":"<pre><code>helm rollback mcp-stack 1 -n mcp\n</code></pre>"},{"location":"deployment/helm/#step-7-uninstall","title":"\ud83e\uddf9 Step 7 - Uninstall","text":"<pre><code>helm uninstall mcp-stack -n mcp\nkubectl delete ns mcp  # optional cleanup\n</code></pre>"},{"location":"deployment/helm/#cicd-packaging-oci-push","title":"\ud83e\uddea CI/CD: Packaging &amp; OCI Push","text":"<pre><code>helm lint .\nhelm package . -d dist/\nhelm push dist/mcp-stack-*.tgz oci://ghcr.io/&lt;your-org&gt;/charts\n</code></pre> <p>Used with GitOps tools like Argo CD or Flux.</p>"},{"location":"deployment/helm/#troubleshooting","title":"\ud83e\uddef Troubleshooting","text":"Symptom Command / Fix ImagePullBackOff Check pull secrets &amp; image name Ingress 404 / no IP `kubectl get svc -A grep ingress` - controller ready? CrashLoopBackOff <code>kubectl logs -n mcp deploy/mcp-stack-app</code> Job fails <code>kubectl get jobs -n mcp &amp;&amp; kubectl logs job/\u2026</code> Invalid values <code>helm lint . &amp;&amp; helm template . -f my-values.yaml</code>"},{"location":"deployment/helm/#valuesyaml-common-keys","title":"\ud83e\uddfe values.yaml - Common Keys","text":"Key Default Purpose <code>mcpContextForge.image.tag</code> <code>latest</code> Image version for the Gateway <code>mcpContextForge.ingress.enabled</code> <code>true</code> Enables ingress <code>mcpContextForge.service.type</code> <code>ClusterIP</code> Change to <code>LoadBalancer</code> if needed <code>postgres.persistence.enabled</code> <code>true</code> Enables a persistent volume claim <code>pgadmin.enabled</code> / <code>redisCommander.enabled</code> <code>false</code> Optional admin UIs <p>See full annotations in <code>values.yaml</code>.</p>"},{"location":"deployment/helm/#further-reading","title":"\ud83d\udcda Further Reading","text":"<ul> <li>Helm: https://helm.sh/docs/</li> <li>Kubernetes Ingress: https://kubernetes.io/docs/concepts/services-networking/ingress/</li> <li>Persistent Volumes: https://kubernetes.io/docs/concepts/storage/persistent-volumes/</li> <li>Helm OCI Registry: https://helm.sh/docs/topics/registries/</li> <li>Argo CD: https://argo-cd.readthedocs.io</li> </ul> <p>\u2705 You now have a production-ready Helm workflow for MCP Context Forge. It's CI-friendly, customizable, and tested across Kubernetes distributions.</p>"},{"location":"deployment/ibm-code-engine/","title":"\u2699\ufe0f IBM Code Engine","text":"<p>This guide covers two supported deployment paths for the MCP Gateway:</p> <ol> <li>Makefile automation \u2013 a single-command workflow that wraps <code>ibmcloud</code> CLI.</li> <li>Manual IBM Cloud CLI \u2013 the raw commands the Makefile executes, for fine-grained control.</li> </ol>"},{"location":"deployment/ibm-code-engine/#1-prerequisites","title":"1 \u00b7 Prerequisites","text":"Requirement Details IBM Cloud account Create one if needed Docker or Podman Builds the production container image locally IBM Cloud CLI \u2265 2.16 Installed automatically with <code>make ibmcloud-cli-install</code> Code Engine project Create or select one in the IBM Cloud console <code>.env</code> file Runtime secrets &amp; config for the gateway <code>.env.ce</code> file Deployment credentials &amp; metadata for Code Engine / Container Reg."},{"location":"deployment/ibm-code-engine/#2-environment-files","title":"2 \u00b7 Environment files","text":"<p>Both files are already in <code>.gitignore</code>. Template named <code>.env.example</code> <code>.env.ce.example</code> and are included; copy them:</p> <pre><code>cp .env.example .env         # runtime settings (inside the container)\ncp .env.ce.example .env.ce   # deployment credentials (CLI only)\n</code></pre>"},{"location":"deployment/ibm-code-engine/#env-runtime-settings","title":"<code>.env</code> \u2013 runtime settings","text":"<p>This file is mounted into the container (via <code>--env-file=.env</code>), so its keys live inside Code Engine at runtime. Treat it as an application secret store.</p> <pre><code># \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n#  Core gateway settings\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nAUTH_REQUIRED=true\n# Generate once:  openssl rand -hex 32\nJWT_SECRET_KEY=eef5e9f70ca7fe6f9677ad2acaf4d32c55e9d98e9cb74299b33f5c5d1a3c8ef\n\nHOST=0.0.0.0\nPORT=4444\n\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n#  Database configuration  \u2013 choose ONE block\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n## (A) Local SQLite  (good for smoke-tests / CI only)\n## --------------------------------------------------\n## \u2022 SQLite lives on the container's ephemeral file system.\n## \u2022 On Code Engine every new instance starts fresh; scale-out, restarts or\n##   deploys will wipe data.  **Not suitable for production.**\n## \u2022 If you still need file persistence, attach Code Engine's file-system\n##   mount or an external filesystem / COS bucket.\n#CACHE_TYPE=database\n#DATABASE_URL=sqlite:////tmp/mcp.db\n\n\n## (B) Managed PostgreSQL on IBM Cloud  (recommended for staging/production)\n## --------------------------------------------------------------------------\n## \u2022 Provision an IBM Cloud Databases for PostgreSQL instance (see below).\n## \u2022 Use the service credentials to build the URL.\n## \u2022 sslmode=require is mandatory for IBM Cloud databases.\nCACHE_TYPE=database\nDATABASE_URL=postgresql://pguser:pgpass@my-pg-host.databases.appdomain.cloud:32727/mcpgwdb?sslmode=require\n#            \u2502 \u2502      \u2502                                   \u2502           \u2502\n#            \u2502 \u2502      \u2502                                   \u2502           \u2514\u2500 database name\n#            \u2502 \u2502      \u2502                                   \u2514\u2500 hostname:port\n#            \u2502 \u2502      \u2514\u2500 password\n#            \u2502 \u2514\u2500 username\n#            \u2514\u2500 scheme\n</code></pre> <p>The <code>JWT_SECRET_KEY</code> variable is used to generate a Bearer token used to access the APIs. To access the APIs you need to generate your JWT token using the same <code>JWT_SECRET_KEY</code>, for example:</p> <pre><code># Generate a one-off token for the default admin user\nexport MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token -u admin)\necho ${MCPGATEWAY_BEARER_TOKEN} # Check that the key was generated\n</code></pre>"},{"location":"deployment/ibm-code-engine/#envce-code-engine-deployment-settings","title":"<code>.env.ce</code> \u2013 Code Engine deployment settings","text":"<p>These keys are only consumed by Makefile / CLI. They never reach the running container.</p> <pre><code># \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n#  IBM Cloud / Code Engine deployment variables\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nIBMCLOUD_REGION=us-south\nIBMCLOUD_RESOURCE_GROUP=default\nIBMCLOUD_PROJECT=my-codeengine-project\nIBMCLOUD_CODE_ENGINE_APP=mcpgateway\n\n# Image details\nIBMCLOUD_IMAGE_NAME=us.icr.io/myspace/mcpgateway:latest  # target in IBM Container Registry\nIBMCLOUD_IMG_PROD=mcpgateway/mcpgateway                  # local tag produced by Make\n\n# Authentication\nIBMCLOUD_API_KEY=***your-api-key***    # leave blank to use SSO flow at login\n\n# Resource combo \u2013 see https://cloud.ibm.com/docs/codeengine?topic=codeengine-mem-cpu-combo\nIBMCLOUD_CPU=1                         # vCPU for the container\nIBMCLOUD_MEMORY=4G                     # Memory (must match a valid CPU/MEM pair)\n\n# Registry secret in Code Engine (first-time creation is automated)\nIBMCLOUD_REGISTRY_SECRET=my-regcred\n</code></pre> <p>Tip: run <code>make ibmcloud-check-env</code> to verify every required <code>IBMCLOUD_*</code> key is present in <code>.env.ce</code>.</p>"},{"location":"deployment/ibm-code-engine/#3-workflow-a-makefile-targets","title":"3 \u00b7 Workflow A \u2013 Makefile targets","text":"Target Action it performs <code>podman</code> / <code>docker</code> Build the production image (<code>$IBMCLOUD_IMG_PROD</code>). <code>ibmcloud-cli-install</code> Install IBM Cloud CLI + container-registry and code-engine plugins. <code>ibmcloud-check-env</code> Ensure all <code>IBMCLOUD_*</code> vars exist in <code>.env.ce</code>; abort if any are missing. <code>ibmcloud-login</code> <code>ibmcloud login</code> \u2013 uses API key or interactive SSO. <code>ibmcloud-ce-login</code> <code>ibmcloud ce project select --name $IBMCLOUD_PROJECT</code>. <code>ibmcloud-list-containers</code> Show ICR images and existing Code Engine apps. <code>ibmcloud-tag</code> <code>podman tag $IBMCLOUD_IMG_PROD $IBMCLOUD_IMAGE_NAME</code>. <code>ibmcloud-push</code> <code>ibmcloud cr login</code> + <code>podman push</code> to ICR. <code>ibmcloud-deploy</code> Create or update the app, set CPU/MEM, attach registry secret, expose port 4444. <code>ibmcloud-ce-status</code> <code>ibmcloud ce application get</code> \u2013 see route URL, revisions, health. <code>ibmcloud-ce-logs</code> <code>ibmcloud ce application logs --follow</code> \u2013 live log stream. <code>ibmcloud-ce-rm</code> Delete the application entirely. <p>Typical first deploy</p> <pre><code>make ibmcloud-check-env\nmake ibmcloud-cli-install\nmake ibmcloud-login\nmake ibmcloud-ce-login\nmake podman            # or: make docker\nmake ibmcloud-tag\nmake ibmcloud-push\nmake ibmcloud-deploy\n</code></pre> <p>Redeploy after code changes</p> <pre><code>make podman ibmcloud-tag ibmcloud-push ibmcloud-deploy\n</code></pre>"},{"location":"deployment/ibm-code-engine/#4-workflow-b-manual-ibm-cloud-cli","title":"4 \u00b7 Workflow B \u2013 Manual IBM Cloud CLI","text":"<pre><code># 1 \u00b7 Install CLI + plugins\ncurl -fsSL https://clis.cloud.ibm.com/install/linux | sh\nibmcloud plugin install container-registry -f\nibmcloud plugin install code-engine      -f\n\n# 2 \u00b7 Login\nibmcloud login --apikey \"$IBMCLOUD_API_KEY\" -r \"$IBMCLOUD_REGION\" -g \"$IBMCLOUD_RESOURCE_GROUP\"\nibmcloud resource groups # list resource groups\n\n# 3 \u00b7 Target Code Engine project\nibmcloud ce project list # list current projects\nibmcloud ce project select --name \"$IBMCLOUD_PROJECT\"\n\n# 4 \u00b7 Build + tag image\npodman build -t \"$IBMCLOUD_IMG_PROD\" .\npodman tag \"$IBMCLOUD_IMG_PROD\" \"$IBMCLOUD_IMAGE_NAME\"\n\n# 5 \u00b7 Push image to ICR\nibmcloud cr login\nibmcloud cr namespaces       # Ensure your namespace exists\npodman push \"$IBMCLOUD_IMAGE_NAME\"\nibmcloud cr images # list images\n\n# 6 \u00b7 Create registry secret (first time)\nibmcloud ce registry create-secret --name \"$IBMCLOUD_REGISTRY_SECRET\" \\\n    --server \"$(echo \"$IBMCLOUD_IMAGE_NAME\" | cut -d/ -f1)\" \\\n    --username iamapikey --password \"$IBMCLOUD_API_KEY\"\nibmcloud ce secret list # list every secret (generic, registry, SSH, TLS, etc.)\nibmcloud ce secret get --name \"$IBMCLOUD_REGISTRY_SECRET\"         # add --decode to see clear-text values\n\n# 7 \u00b7 Deploy / update\nif ibmcloud ce application get --name \"$IBMCLOUD_CODE_ENGINE_APP\" &gt;/dev/null 2&gt;&amp;1; then\n  ibmcloud ce application update --name \"$IBMCLOUD_CODE_ENGINE_APP\" \\\n      --image \"$IBMCLOUD_IMAGE_NAME\" \\\n      --cpu \"$IBMCLOUD_CPU\" --memory \"$IBMCLOUD_MEMORY\" \\\n      --registry-secret \"$IBMCLOUD_REGISTRY_SECRET\"\nelse\n  ibmcloud ce application create --name \"$IBMCLOUD_CODE_ENGINE_APP\" \\\n      --image \"$IBMCLOUD_IMAGE_NAME\" \\\n      --cpu \"$IBMCLOUD_CPU\" --memory \"$IBMCLOUD_MEMORY\" \\\n      --port 4444 \\\n      --registry-secret \"$IBMCLOUD_REGISTRY_SECRET\"\nfi\n\n# 8 \u00b7 Status &amp; logs\nibmcloud ce application get --name \"$IBMCLOUD_CODE_ENGINE_APP\"\nibmcloud ce application events --name \"$IBMCLOUD_CODE_ENGINE_APP\"\nibmcloud ce application get   --name \"$IBMCLOUD_CODE_ENGINE_APP\"\nibmcloud ce application logs  --name \"$IBMCLOUD_CODE_ENGINE_APP\" --follow\n</code></pre>"},{"location":"deployment/ibm-code-engine/#5-accessing-the-gateway","title":"5 \u00b7 Accessing the gateway","text":"<pre><code>ibmcloud ce application get --name \"$IBMCLOUD_CODE_ENGINE_APP\" --output url\n</code></pre> <p>Open the returned URL (e.g. <code>https://mcpgateway.us-south.codeengine.appdomain.cloud/admin</code>) and log in with the basic-auth credentials from <code>.env</code>.</p> <p>Test the API endpoints with the generated <code>MCPGATEWAY_BEARER_TOKEN</code>:</p> <pre><code># Generate a one-off token for the default admin user\nexport MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token -u admin)\n\n# Call a protected endpoint. Since there are not tools, initially this just returns `[]`\ncurl -H \"Authorization: Bearer ${MCPGATEWAY_BEARER_TOKEN}\" \\\n     https://mcpgateway.us-south.codeengine.appdomain.cloud/tools\n\n# Check the logs\nmake ibmcloud-ce-logs\n</code></pre>"},{"location":"deployment/ibm-code-engine/#6-cleanup","title":"6 \u00b7 Cleanup","text":"<pre><code># via Makefile\nmake ibmcloud-ce-rm\n\n# or directly\nibmcloud ce application delete --name \"$IBMCLOUD_CODE_ENGINE_APP\" -f\n</code></pre>"},{"location":"deployment/ibm-code-engine/#7-using-ibm-cloud-databases-for-postgresql","title":"7 \u00b7 Using IBM Cloud Databases for PostgreSQL","text":"<p>Need durable data, high availability, and automated backups? Provision IBM Cloud Databases for PostgreSQL and connect MCP Gateway to it.</p> <pre><code>###############################################################################\n# 1 \u00b7 Provision PostgreSQL\n###############################################################################\n# Choose a plan:  standard (shared) or enterprise (dedicated). For small\n# workloads start with: standard / 1 member / 4 GB RAM.\nibmcloud resource service-instance-create mcpgw-db \\\n    databases-for-postgresql standard $IBMCLOUD_REGION\n\n###############################################################################\n# 2 \u00b7 Create service credentials\n###############################################################################\nibmcloud resource service-key-create mcpgw-db-creds Administrator \\\n    --instance-name mcpgw-db\n\n###############################################################################\n# 3 \u00b7 Retrieve credentials &amp; craft DATABASE_URL\n###############################################################################\ncreds_json=$(ibmcloud resource service-key mcpgw-db-creds --output json)\nhost=$(echo \"$creds_json\" | jq -r '.[0].credentials.connection.postgres.hosts[0].hostname')\nport=$(echo \"$creds_json\" | jq -r '.[0].credentials.connection.postgres.hosts[0].port')\nuser=$(echo \"$creds_json\" | jq -r '.[0].credentials.connection.postgres.authentication.username')\npass=$(echo \"$creds_json\" | jq -r '.[0].credentials.connection.postgres.authentication.password')\ndb=$(echo \"$creds_json\"   | jq -r '.[0].credentials.connection.postgres.database')\n\nDATABASE_URL=\"postgresql://${user}:${pass}@${host}:${port}/${db}?sslmode=require\"\n\n###############################################################################\n# 4 \u00b7 Store DATABASE_URL as a Code Engine secret\n###############################################################################\nibmcloud ce secret create --name mcpgw-db-url \\\n    --from-literal DATABASE_URL=\"$DATABASE_URL\"\n\n###############################################################################\n# 5 \u00b7 Mount the secret into the application\n###############################################################################\nibmcloud ce application update --name \"$IBMCLOUD_CODE_ENGINE_APP\" \\\n    --env-from-secret mcpgw-db-url\n</code></pre>"},{"location":"deployment/ibm-code-engine/#choosing-the-right-postgresql-size","title":"Choosing the right PostgreSQL size","text":"Workload profile Suggested plan Members \u00d7 RAM Notes Dev / PoC <code>standard</code> 1 \u00d7 4 GB Cheapest; no HA; easy to scale later Prod small <code>standard</code> 2 \u00d7 8 GB Two members enable HA &amp; automatic fail-over Prod heavy <code>enterprise</code> 3 \u00d7 16 GB Dedicated bare-metal; highest performance &amp; isolation <p>Scale up at any time with:</p> <pre><code>ibmcloud cdb deployment-scaling-set mcpgw-db \\\n    --members 3 --memory-gb 16\n\n# Update the number of maximum connections:\nibmcloud cdb deployment-configuration YOUR_DB_CRN '{\"configuration\":{\"max_connections\":215}}'\n\n# show max_connections;\n</code></pre> <p>The gateway will reconnect transparently because the host name remains stable. See the documentation for more details.</p>"},{"location":"deployment/ibm-code-engine/#local-sqlite-vs-managed-postgresql","title":"Local SQLite vs. Managed PostgreSQL","text":"Aspect Local SQLite (<code>sqlite:////tmp/mcp.db</code>) Managed PostgreSQL Persistence None \u2013 lost on restarts / scale-out Durable &amp; backed-up Concurrency Single-writer lock Multiple writers Scale-out ready No - state is per-pod Yes Best for Unit tests, CI pipelines Staging &amp; production <p>For production workloads you must switch to a managed database or mount a persistent file system.</p>"},{"location":"deployment/ibm-code-engine/#8-adding-ibm-cloud-databases-for-redis-optional-cache-layer","title":"8 \u00b7 Adding IBM Cloud Databases for Redis (optional cache layer)","text":"<p>Need a high-performance shared cache? Provision IBM Cloud Databases for Redis and point MCP Gateway at it.</p> <pre><code>###############################################################################\n# 1 \u00b7 Provision Redis\n###############################################################################\n# Choose a plan: standard (shared) or enterprise (dedicated).\nibmcloud resource service-instance-create mcpgw-redis \\\n    databases-for-redis standard $IBMCLOUD_REGION\n\n###############################################################################\n# 2 \u00b7 Create service credentials\n###############################################################################\nibmcloud resource service-key-create mcpgw-redis-creds Administrator \\\n    --instance-name mcpgw-redis\n\n###############################################################################\n# 3 \u00b7 Retrieve credentials &amp; craft REDIS_URL\n###############################################################################\ncreds_json=$(ibmcloud resource service-key mcpgw-redis-creds --output json)\nhost=$(echo \"$creds_json\" | jq -r '.[0].credentials.connection.rediss.hosts[0].hostname')\nport=$(echo \"$creds_json\" | jq -r '.[0].credentials.connection.rediss.hosts[0].port')\npass=$(echo \"$creds_json\" | jq -r '.[0].credentials.connection.rediss.authentication.password')\n\nREDIS_URL=\"rediss://:${pass}@${host}:${port}/0\"   # rediss = TLS-secured Redis\n\n###############################################################################\n# 4 \u00b7 Store REDIS_URL as a Code Engine secret\n###############################################################################\nibmcloud ce secret create --name mcpgw-redis-url \\\n    --from-literal REDIS_URL=\"$REDIS_URL\"\n\n###############################################################################\n# 5 \u00b7 Mount the secret and switch cache backend\n###############################################################################\nibmcloud ce application update --name \"$IBMCLOUD_CODE_ENGINE_APP\" \\\n    --env-from-secret mcpgw-redis-url \\\n    --env CACHE_TYPE=redis\n</code></pre>"},{"location":"deployment/ibm-code-engine/#choosing-the-right-redis-size","title":"Choosing the right Redis size","text":"Use-case Plan Memory Notes Dev / CI <code>standard</code> 256 MB Minimum footprint, single member Small production <code>standard</code> 1 GB Two-member HA cluster High-throughput <code>enterprise</code> \u22654 GB Dedicated nodes, persistence, AOF <p>Scale later with:</p> <pre><code>ibmcloud cdb deployment-scaling-set mcpgw-redis --memory-gb 4\n</code></pre> <p>Once redeployed, the gateway will use Redis for request-level caching, reducing latency and database load.</p>"},{"location":"deployment/ibm-code-engine/#9-gunicorn-configuration-optional-tuning","title":"9. Gunicorn configuration (optional tuning)","text":"<p>The container starts <code>gunicorn</code> with the settings defined in <code>gunicorn.conf.py</code> found at the project root. If you need to change worker counts, ports, or time-outs, edit this file before you build the image (<code>make podman</code> or <code>make docker</code>). The settings are baked into the container at build time.</p> <pre><code># -*- coding: utf-8 -*-\n\"\"\"\nGunicorn configuration\nDocs: https://docs.gunicorn.org/en/stable/settings.html\n\"\"\"\n\n# Network interface / port \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nbind = \"0.0.0.0:4444\"        # Listen on all interfaces, port 4444\n\n# Worker processes \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nworkers = 8                  # Rule of thumb: 2\u20134 \u00d7 NUM_CPU_CORES\n\n# Request/worker life-cycle \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ntimeout = 600                # Kill a worker after 600 s of no response\nmax_requests = 10000         # Restart worker after N requests\nmax_requests_jitter = 100    # Add randomness to avoid synchronized restarts\n\n# Logging &amp; verbosity \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nloglevel = \"info\"            # \"debug\", \"info\", \"warning\", \"error\", \"critical\"\n\n# Optimisations \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\npreload_app = True           # Load app code once in parent, fork workers (saves RAM)\nreuse_port  = True           # SO_REUSEPORT for quicker restarts\n\n# Alternative worker models (uncomment ONE and install extras) ----------\n# worker_class = \"gevent\"     # pip install \"gunicorn[gevent]\"\n# worker_class = \"eventlet\"   # pip install \"gunicorn[eventlet]\"\n# worker_class = \"tornado\"    # pip install \"gunicorn[tornado]\"\n# threads = 2                 # If using the 'sync' worker with threads\n\n# TLS certificates (if you terminate HTTPS inside the container)\n# certfile = 'certs/cert.pem'\n# keyfile  = 'certs/key.pem'\n\n# Server hooks (logging examples) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef when_ready(server):\n    server.log.info(\"Server is ready. Spawning workers\")\n\ndef post_fork(server, worker):\n    server.log.info(\"Worker spawned (pid: %s)\", worker.pid)\n\ndef worker_exit(server, worker):\n    server.log.info(\"Worker exit (pid: %s)\", worker.pid)\n</code></pre> <p>Typical tweaks</p> Scenario Setting(s) to adjust High-latency model calls \u2192 time-outs <code>timeout</code> (e.g. 1200 s) CPU-bound workload on 4-core instance <code>workers = 8</code> \u2192 <code>workers = 16</code> Memory-limited instance Reduce <code>workers</code> or disable <code>preload_app</code> Websocket / async traffic Switch <code>worker_class</code> to <code>gevent</code> or <code>eventlet</code> <p>After changing the file, rebuild and redeploy:</p> <pre><code>make podman ibmcloud-tag ibmcloud-push ibmcloud-deploy\n</code></pre>"},{"location":"deployment/kubernetes/","title":"\u2638\ufe0f Kubernetes / OpenShift Deployment","text":"<p>You can deploy MCP Gateway to any K8s-compliant platform \u2014 including vanilla Kubernetes, OpenShift, and managed clouds like GKE, AKS, and EKS.</p>"},{"location":"deployment/kubernetes/#quick-start-with-manifest-yaml","title":"\ud83d\ude80 Quick Start with Manifest (YAML)","text":"<p>A basic Kubernetes deployment might look like:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mcpgateway\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mcpgateway\n  template:\n    metadata:\n      labels:\n        app: mcpgateway\n    spec:\n      containers:\n        - name: gateway\n          image: ghcr.io/YOUR_ORG/mcpgateway:latest\n          ports:\n            - containerPort: 4444\n          envFrom:\n            - configMapRef:\n                name: mcpgateway-env\n          volumeMounts:\n            - mountPath: /app/.env\n              name: env-volume\n              subPath: .env\n      volumes:\n        - name: env-volume\n          configMap:\n            name: mcpgateway-env\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: mcpgateway\nspec:\n  selector:\n    app: mcpgateway\n  ports:\n    - port: 80\n      targetPort: 4444\n</code></pre> <p>Replace <code>ghcr.io/YOUR_ORG/mcpgateway</code> with your built image.</p>"},{"location":"deployment/kubernetes/#tls-ingress","title":"\ud83d\udd10 TLS &amp; Ingress","text":"<p>You can add:</p> <ul> <li>Cert-manager with TLS secrets</li> <li>An Ingress resource that routes to <code>/admin</code>, <code>/tools</code>, etc.</li> </ul> <p>Example Ingress snippet:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: mcpgateway\n  annotations:\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\nspec:\n  rules:\n    - host: gateway.example.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: mcpgateway\n                port:\n                  number: 80\n  tls:\n    - hosts:\n        - gateway.example.com\n      secretName: mcpgateway-tls\n</code></pre>"},{"location":"deployment/kubernetes/#configuration-via-configmap","title":"\ud83d\udce6 Configuration via ConfigMap","text":"<p>You can load your <code>.env</code> as a ConfigMap:</p> <pre><code>kubectl create configmap mcpgateway-env --from-env-file=.env\n</code></pre> <p>Make sure it includes <code>JWT_SECRET_KEY</code>, <code>AUTH_REQUIRED</code>, etc.</p>"},{"location":"deployment/kubernetes/#openshift-considerations","title":"\ud83d\udca1 OpenShift Considerations","text":"<ul> <li>Use <code>Route</code> instead of Ingress</li> <li>You may need to run the container as an unprivileged user</li> <li>Set <code>SECURITY_CONTEXT_RUNASUSER</code> if needed</li> </ul>"},{"location":"deployment/kubernetes/#health-check-probes","title":"\ud83e\uddea Health Check Probes","text":"<pre><code>livenessProbe:\n  httpGet:\n    path: /health\n    port: 4444\n  initialDelaySeconds: 10\n  periodSeconds: 15\n</code></pre>"},{"location":"deployment/local/","title":"\ud83d\udc0d Local Deployment","text":"<p>This guide walks you through running MCP Gateway on your local machine using a virtual environment or directly via Python.</p>"},{"location":"deployment/local/#one-liner-setup","title":"\ud83d\ude80 One-Liner Setup","text":"<p>The easiest way to start the server in development mode:</p> <pre><code>make venv install serve\n</code></pre> <p>This does the following:</p> <ol> <li>Creates a <code>.venv/</code> virtual environment</li> <li>Installs all dependencies (including dev tools)</li> <li>Launches Gunicorn on <code>http://localhost:4444</code></li> </ol>"},{"location":"deployment/local/#development-mode-with-live-reload","title":"\ud83e\uddea Development Mode with Live Reload","text":"<p>If you want auto-reload on code changes:</p> <pre><code>make run        # or:\n./run.sh --reload --log debug\n</code></pre> <p>Ensure your <code>.env</code> file includes:</p> <pre><code>DEV_MODE=true\nRELOAD=true\nDEBUG=true\n</code></pre>"},{"location":"deployment/local/#health-test","title":"\ud83e\uddea Health Test","text":"<pre><code>curl http://localhost:4444/health\n</code></pre> <p>Expected output:</p> <pre><code>{\"status\": \"healthy\"}\n</code></pre>"},{"location":"deployment/local/#admin-ui","title":"\ud83d\udd10 Admin UI","text":"<p>Visit http://localhost:4444/admin and login using your <code>BASIC_AUTH_USER</code> and <code>BASIC_AUTH_PASSWORD</code> from <code>.env</code>.</p>"},{"location":"deployment/local/#quick-jwt-setup","title":"\ud83d\udd01 Quick JWT Setup","text":"<pre><code>export MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token -u admin)\ncurl -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" http://localhost:4444/tools\n</code></pre>"},{"location":"deployment/minikube/","title":"\u26a1\ufe0f Minikube","text":"<ol> <li>Install Minikube and kubectl (Docker or Podman driver required).</li> <li>Start a local cluster with Ingress and DNS addons.</li> <li>Load the <code>ghcr.io/ibm/mcp-context-forge:latest</code> image into Minikube.</li> <li>Apply your Kubernetes manifests.</li> <li>Access the Gateway at http://gateway.local or <code>127.0.0.1:80</code> via NGINX Ingress.</li> </ol> <p>Minikube provides a self-contained environment, enabling you to replicate production features like persistent volumes and TLS on your local machine.</p>"},{"location":"deployment/minikube/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"Requirement Notes CPU / RAM Minimum 2 vCPU + 2 GiB; recommended 4 vCPU / 6 GiB for smoother operation. Disk At least 20 GiB of free space. Container driver Docker 20.10+ or Podman 4.7+; Docker is the simplest choice on macOS and Windows. kubectl Automatically configured by <code>minikube start</code>; alternatively, use <code>minikube kubectl -- \u2026</code> if not installed."},{"location":"deployment/minikube/#architecture","title":"Architecture","text":"<pre><code>          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u2502      NGINX Ingress          \u2502\n          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502/          \u2502/\n      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n      \u2502  MCP Context Forge \u2502 \u2502 PgAdmin (opt.) \u2502\n      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502                 \u2502\n   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502    PostgreSQL     \u2502 \u2502 Redis Commander(opt)\u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502                     \u2502\n      \u250c\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510\n      \u2502   PV     \u2502          \u2502  Redis   \u2502\n      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"deployment/minikube/#step-1-install-minikube-and-kubectl","title":"\ud83d\ude80 Step 1 \u2013 Install Minikube and kubectl","text":"<p>Make target</p> <pre><code>make minikube-install\n</code></pre> <p>This target checks for existing installations of <code>minikube</code> and <code>kubectl</code>. If missing, it installs them using:</p> <ul> <li>Homebrew on macOS</li> <li>The official binary on Linux</li> <li>Chocolatey on Windows</li> </ul> Manual installation (optional)  ### macOS (Homebrew)  <pre><code>brew install minikube kubernetes-cli\n</code></pre>  ### Linux (Generic binary)  <pre><code># Minikube\ncurl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64\nsudo install minikube-linux-amd64 /usr/local/bin/minikube &amp;&amp; rm minikube-linux-amd64\n\n# kubectl (latest stable)\ncurl -LO \"https://dl.k8s.io/release/$(curl -sL https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\nchmod +x kubectl &amp;&amp; sudo mv kubectl /usr/local/bin/\n</code></pre>  ### Windows (PowerShell + Chocolatey)  <pre><code>choco install -y minikube kubernetes-cli\n</code></pre>"},{"location":"deployment/minikube/#step-2-start-the-cluster","title":"\u2699\ufe0f Step 2 \u2013 Start the cluster","text":"<p>Make target</p> <pre><code>make minikube-start\n</code></pre> Equivalent manual command <pre><code>minikube start \\\n  --driver=docker \\\n  --cpus=4 --memory=6g \\\n  --addons=ingress,ingress-dns \\\n  --profile=mcpgw\n</code></pre> <ul> <li><code>--driver=docker</code> avoids nested virtualization on macOS and Windows Home.</li> <li><code>ingress</code> provides an NGINX LoadBalancer on localhost.</li> <li><code>ingress-dns</code> resolves <code>*.local</code> domains when you add the Minikube IP to your OS DNS list.</li> <li><code>--cpus</code> and <code>--memory</code> can be set to <code>max</code> to utilize all available resources.</li> </ul> <p>Check cluster status:</p> <pre><code>make minikube-status\n# or:\nminikube status -p mcpgw\nkubectl get pods -n ingress-nginx\n</code></pre>"},{"location":"deployment/minikube/#step-3-load-the-gateway-image","title":"\ud83c\udfd7 Step 3 \u2013 Load the Gateway image","text":"<p>Make target</p> <pre><code>make minikube-image-load\n</code></pre> <p>This target builds the <code>ghcr.io/ibm/mcp-context-forge:latest</code> image and loads it into Minikube.</p>"},{"location":"deployment/minikube/#alternative-methods","title":"Alternative methods","text":"<ul> <li>Pre-cache a remote image:</li> </ul> <pre><code>minikube cache add ghcr.io/ibm/mcp-context-forge:latest\nminikube cache reload\n</code></pre> <ul> <li>Load a local tarball:</li> </ul> <pre><code>docker save ghcr.io/ibm/mcp-context-forge:latest | minikube image load -\n</code></pre>"},{"location":"deployment/minikube/#step-4-apply-kubernetes-manifests","title":"\ud83d\udcc4 Step 4 \u2013 Apply Kubernetes manifests","text":"<p>Make target</p> <pre><code>make minikube-k8s-apply\n</code></pre> <p>This applies the Kubernetes manifests. Alternative manual step:</p> <pre><code># PostgreSQL\nkubectl apply -f k8s/postgres-config.yaml\nkubectl apply -f k8s/postgres-pv.yaml\nkubectl apply -f k8s/postgres-pvc.yaml\nkubectl apply -f k8s/postgres-deployment.yaml\nkubectl apply -f k8s/postgres-service.yaml\n\n# Redis\nkubectl apply -f k8s/redis-deployment.yaml\nkubectl apply -f k8s/redis-service.yaml\n\n# MCP Gateway\nkubectl apply -f k8s/mcp-context-forge-deployment.yaml\nkubectl apply -f k8s/mcp-context-forge-service.yaml\nkubectl apply -f k8s/mcp-context-forge-ingress.yaml\n</code></pre> <p>If you've enabled <code>ingress-dns</code>, set the Ingress <code>host:</code> to <code>gateway.local</code>. Otherwise, omit the <code>host:</code> and access via NodePort.</p> <p>Note: Minikube automatically configures the <code>kubectl</code> context upon cluster creation. If not, set it manually:</p> <pre><code>kubectl config use-context minikube\n# or:\nminikube kubectl -- apply -f \u2026\n</code></pre>"},{"location":"deployment/minikube/#step-5-verify-deployment-status","title":"\ud83e\uddea Step 5 \u2013 Verify deployment status","text":"<p>Before hitting your endpoint, confirm the application is up and healthy.</p>"},{"location":"deployment/minikube/#check-pod-status","title":"\ud83d\udd0d Check pod status","text":"<pre><code>kubectl get pods\n</code></pre> <p>Expect output like:</p> <pre><code>NAME                                      READY   STATUS    RESTARTS   AGE\npostgres-5b66bdf445-rp8kl                 1/1     Running   0          15s\nredis-668976c4f9-2hljd                    1/1     Running   0          15s\nmcp-context-forge-6d87f8c5d8-nnmgx        1/1     Running   0          10s\n</code></pre>"},{"location":"deployment/minikube/#check-logs-optional","title":"\ud83d\udcdc Check logs (optional)","text":"<pre><code>kubectl logs deploy/mcp-context-forge\n</code></pre> <p>This can help diagnose startup errors or missing dependencies (e.g. bad env vars, Postgres connection issues).</p>"},{"location":"deployment/minikube/#wait-for-rollout-optional","title":"\ud83d\udea5 Wait for rollout (optional)","text":"<pre><code>kubectl rollout status deploy/mcp-context-forge\n</code></pre> <p>If the pod gets stuck in <code>CrashLoopBackOff</code>, run:</p> <pre><code>kubectl describe pod &lt;pod-name&gt;\n</code></pre> <p>And:</p> <pre><code>kubectl logs &lt;pod-name&gt;\n</code></pre>"},{"location":"deployment/minikube/#confirm-ingress-is-live","title":"\u2705 Confirm Ingress is live","text":"<pre><code>kubectl get ingress\n</code></pre> <p>Should show something like:</p> <pre><code>NAME                        CLASS    HOSTS           ADDRESS        PORTS   AGE\nmcp-context-forge-ingress   nginx    gateway.local   192.168.49.2   80      1m\n</code></pre> <p>If <code>ADDRESS</code> is empty, the ingress controller may still be warming up.</p> <p>You may want to add this to <code>/etc/hosts</code>. Ex:</p> <pre><code>192.168.49.2 gateway.local\n</code></pre>"},{"location":"deployment/minikube/#step-6-test-access","title":"\ud83c\udf10 Step 6 \u2013 Test access","text":"<pre><code># Via NodePort:\ncurl $(minikube service mcp-context-forge --url)/health\n\n# Via DNS:\ncurl http://gateway.local/health\n</code></pre>"},{"location":"deployment/minikube/#cleaning-up","title":"\ud83e\uddf9 Cleaning up","text":"Action Make target Manual command Pause cluster <code>make minikube-stop</code> <code>minikube stop -p mcpgw</code> Delete cluster <code>make minikube-delete</code> <code>minikube delete -p mcpgw</code> Remove cached image \u2014 <code>minikube cache delete ghcr.io/ibm/mcp-context-forge:latest</code>"},{"location":"deployment/minikube/#non-make-cheatsheet","title":"\ud83d\udee0 Non-Make cheatsheet","text":"Task Command Start with Podman driver <code>minikube start --driver=podman --network-plugin=cni</code> Open dashboard <code>minikube dashboard</code> SSH into node <code>minikube ssh</code> Enable metrics-server <code>minikube addons enable metrics-server</code> Upgrade Minikube (macOS) <code>minikube delete &amp;&amp; brew upgrade minikube</code>"},{"location":"deployment/minikube/#further-reading","title":"\ud83d\udcda Further reading","text":"<ol> <li> <p>Minikube Quick Start guide (official)    https://minikube.sigs.k8s.io/docs/start/</p> </li> <li> <p>Minikube Docker driver docs    https://minikube.sigs.k8s.io/docs/drivers/docker/</p> </li> <li> <p>Enable NGINX Ingress in Minikube    https://kubernetes.io/docs/tasks/access-application-cluster/ingress-minikube/</p> </li> <li> <p>Load / cache images inside Minikube    https://minikube.sigs.k8s.io/docs/handbook/pushing/</p> </li> <li> <p>Using Minikube's built-in kubectl    https://minikube.sigs.k8s.io/docs/handbook/kubectl/</p> </li> <li> <p>Allocate max CPU/RAM flags    https://minikube.sigs.k8s.io/docs/faq/#how-can-i-allocate-maximum-resources-to-minikube</p> </li> <li> <p>Ingress-DNS addon overview    https://minikube.sigs.k8s.io/docs/handbook/addons/ingress-dns/</p> </li> <li> <p>Stack Overflow: loading local images into Minikube    https://stackoverflow.com/questions/42564058/how-can-i-use-local-docker-images-with-minikube</p> </li> </ol> <p>Minikube gives you the fastest, vendor-neutral sandbox for experimenting with MCP Gateway\u2014and everything above doubles as CI instructions for self-hosted GitHub runners or ephemeral integration tests.</p>"},{"location":"deployment/openshift/","title":"\u2728 Red Hat OpenShift","text":"<p>OpenShift (both OKD and Red Hat OpenShift Container Platform) adds opinionated security (SCC), integrated routing, and optional build pipelines on top of Kubernetes.  Deploying MCP Gateway therefore means (1) building or pulling a compatible image, (2) wiring database + cache back-ends, (3) obeying the default restricted-v2 SCC, and (4) exposing the service through a Route instead of an Ingress.  This guide walks through each step, offers ready-made YAML snippets, and explains the differences from the vanilla Kubernetes.</p>"},{"location":"deployment/openshift/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"<ul> <li><code>oc</code> CLI \u2014 log in as a developer to a project/namespace you can create objects in.</li> <li>A storage class for PVCs (or local PVs) to back the Postgres template.</li> <li>Either Podman or Docker on your workstation if you build locally.</li> <li>Access to an image registry that your cluster can pull from (e.g. <code>quay.io</code>).</li> </ul>"},{"location":"deployment/openshift/#build-push-images","title":"\ud83d\udee0\ufe0f Build &amp; push images","text":""},{"location":"deployment/openshift/#option-a-use-make","title":"Option A \u2014 Use Make","text":"Target Builds Dockerfile Notes <code>make podman</code> <code>mcpgateway-dev:latest</code> Containerfile Rootless Podman build <code>make podman-prod</code> <code>mcpgateway:latest</code> Containerfile.lite UBI 9-micro, multi-stage <code>make docker</code> <code>mcpgateway-dev:latest</code> Containerfile Docker Desktop <code>make docker-prod</code> <code>mcpgateway:latest</code> Containerfile.lite Same slim image <p>Push afterwards, for example:</p> <pre><code>podman tag mcpgateway:latest quay.io/YOUR_NS/mcpgateway:latest\npodman push quay.io/YOUR_NS/mcpgateway:latest\n</code></pre> <p>Apple-silicon note \u2013 <code>Containerfile.lite</code> uses <code>ubi9-micro</code> (x86_64). Buildx/QEMU works, but the image will run under emulation on macOS. If you need native arm64 choose the dev image or add <code>--platform linux/arm64</code>.</p>"},{"location":"deployment/openshift/#option-b-raw-cli-equivalents","title":"Option B \u2014 Raw CLI equivalents","text":"<pre><code># Dev (Containerfile)\npodman build -t mcpgateway-dev:latest -f Containerfile .\n\n# Prod (UBI micro, AMD64, squashed layers)\ndocker build --platform=linux/amd64 --squash \\\n  -t mcpgateway:latest -f Containerfile.lite .\n</code></pre>"},{"location":"deployment/openshift/#secrets-configmaps","title":"\ud83d\udd11 Secrets &amp; ConfigMaps","text":"<p>Create a ConfigMap from your <code>.env</code> file:</p> <pre><code>oc create configmap mcpgateway-env --from-env-file=.env   # Populates envFrom\n</code></pre> <p>OpenShift lets you inject all keys via <code>envFrom:</code> in the pod template.</p> <p>If you keep sensitive values (e.g. <code>JWT_SECRET_KEY</code>) separate, store them in a Secret and reference both resources under <code>envFrom:</code>.</p>"},{"location":"deployment/openshift/#postgresql-redis-back-ends","title":"\ud83d\uddc4 PostgreSQL &amp; Redis back-ends","text":""},{"location":"deployment/openshift/#postgresql-persistent-template","title":"PostgreSQL (persistent template)","text":"<pre><code>oc new-app -f https://raw.githubusercontent.com/openshift/origin/master/examples/db-templates/postgresql-persistent-template.json \\\n  -p POSTGRESQL_USER=postgres,POSTGRESQL_PASSWORD=secret,POSTGRESQL_DATABASE=mcp\n</code></pre> <p>The template creates a DeploymentConfig, Service and a 1 Gi PVC bound to the cluster's default storage class.</p>"},{"location":"deployment/openshift/#redis","title":"Redis","text":"<p>On OpenShift 4.x use the Redis Enterprise Operator from OperatorHub (UI or CLI) then create a RedisEnterpriseCluster CR; it provisions StatefulSets plus PVCs out-of-the-box.</p>"},{"location":"deployment/openshift/#deployment-service-gateway","title":"\ud83d\udce6 Deployment &amp; Service (gateway)","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mcpgateway\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mcpgateway\n  template:\n    metadata:\n      labels:\n        app: mcpgateway\n    spec:\n      securityContext:            # Must satisfy restricted-v2 SCC\n        runAsNonRoot: true\n      containers:\n      - name: gateway\n        image: quay.io/YOUR_NS/mcpgateway:latest\n        ports:\n        - containerPort: 4444\n        envFrom:\n        - configMapRef:\n            name: mcpgateway-env\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 4444\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 4444\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        securityContext:\n          allowPrivilegeEscalation: false\n          runAsUser: 1001        # UBI non-root UID works with restricted SCC\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: mcpgateway\nspec:\n  selector:\n    app: mcpgateway\n  ports:\n  - port: 80\n    targetPort: 4444\n</code></pre> <p>The readiness/liveness probes follow OpenShift's health-check guidance.</p>"},{"location":"deployment/openshift/#route-public-url","title":"\ud83c\udf0d Route (public URL)","text":"<pre><code>apiVersion: route.openshift.io/v1\nkind: Route\nmetadata:\n  name: mcpgateway\nspec:\n  to:\n    kind: Service\n    name: mcpgateway\n  port:\n    targetPort: 80\n  tls:\n    termination: edge\n</code></pre> <p>Routes are OpenShift's native form of ingress; the router automatically provisions a hostname such as <code>mcpgateway-myproj.apps.cluster.example.com</code>.</p>"},{"location":"deployment/openshift/#putting-it-together","title":"\ud83d\udcd1 Putting it together","text":"<pre><code># Apply manifests\noc apply -f postgres-template.yaml        # or Operator YAML\noc apply -f redis-operator.yaml           # if using Redis Operator\noc apply -f mcpgateway-deployment.yaml\noc apply -f mcpgateway-route.yaml\n</code></pre> <p>Verify:</p> <pre><code>oc get pods\noc get route mcpgateway -o jsonpath='{.spec.host}{\"\\n\"}'\ncurl https://$(oc get route mcpgateway -o jsonpath='{.spec.host}')/health\n</code></pre>"},{"location":"deployment/openshift/#openshift-buildconfig-optional","title":"\ud83d\udd04 OpenShift BuildConfig (optional)","text":"<p>If you prefer in-cluster builds, create a <code>BuildConfig</code> with the docker strategy. You can override the Dockerfile path via <code>spec.strategy.dockerStrategy.dockerfilePath</code>. Then trigger:</p> <pre><code>oc start-build mcpgateway --from-dir=.\n</code></pre> <p>The resulting image lands in an internal ImageStream, and the Deployment can auto-deploy the new tag.</p>"},{"location":"deployment/openshift/#persistence-pvcs","title":"\ud83d\uddc3 Persistence &amp; PVCs","text":"<p>The Postgres template already generates a PVC; you can create extra PVCs manually or via the web console. A general PVC manifest is shown in OpenShift Storage docs.</p>"},{"location":"deployment/openshift/#non-make-cheat-sheet","title":"\ud83d\udea6 Non-Make cheat-sheet","text":"Action Command Build dev image (local) <code>podman build -t mcpgateway-dev -f Containerfile .</code> Build prod (UBI lite) <code>docker build -t mcpgateway -f Containerfile.lite .</code> Push to Quay <code>podman push mcpgateway quay.io/NS/mcpgateway</code> Create project <code>oc new-project mcp-demo</code> Load .env <code>oc create configmap mcpgateway-env --from-env-file=.env</code> Deploy <code>oc apply -f mcpgateway-deployment.yaml</code> Expose <code>oc apply -f mcpgateway-route.yaml</code> Tail logs <code>oc logs -f deployment/mcpgateway</code>"},{"location":"deployment/openshift/#troubleshooting","title":"\ud83d\udee0 Troubleshooting","text":"Issue Fix <code>Error: container has runAsNonRoot and image has non-numeric user</code> Add <code>runAsUser: 1001</code> or pick <code>nonroot-v2</code> SCC. PVC stuck in <code>Pending</code> Check storage class or request size &gt; quota. Route returns 503 Verify pod readiness probe passes and the Service targets port 80 -&gt; 4444."},{"location":"deployment/openshift/#further-reading","title":"\ud83d\udcda Further reading","text":"<ol> <li>OpenShift Route documentation \u2013 creation &amp; TLS</li> <li>SCC and restricted-v2 / nonroot-v2 behaviour</li> <li>ConfigMap envFrom patterns</li> <li>Postgres persistent template example</li> <li>Redis Enterprise Operator on OCP (OperatorHub)</li> <li>Health-check probes in OpenShift</li> <li>BuildConfig Docker strategy &amp; <code>dockerfilePath</code></li> </ol>"},{"location":"development/","title":"Development","text":"<p>Welcome! This guide is for developers contributing to MCP Gateway. Whether you're fixing bugs, adding features, or extending federation or protocol support, this doc will help you get up and running quickly and consistently.</p>"},{"location":"development/#what-youll-find-here","title":"\ud83e\uddf0 What You'll Find Here","text":"Page Description Building Locally How to install dependencies, set up a virtual environment, and run the gateway Packaging How to build a release, container image, or prebuilt binary DEVELOPING.md Coding standards, commit conventions, and review workflow"},{"location":"development/#developer-environment","title":"\ud83d\udee0 Developer Environment","text":"<p>MCP Gateway is built with:</p> <ul> <li>Python 3.10+</li> <li>FastAPI + SQLAlchemy (async) + Pydantic Settings</li> <li>HTMX, Alpine.js, TailwindCSS for the Admin UI</li> </ul> <p>Development tools:</p> <ul> <li>Linters: <code>ruff</code>, <code>mypy</code>, <code>black</code>, <code>isort</code></li> <li>Testing: <code>pytest</code>, <code>httpx</code></li> <li>Serving: <code>uvicorn</code>, <code>gunicorn</code></li> </ul> <p>Code style and consistency is enforced via:</p> <pre><code>make lint          # runs ruff, mypy, black, isort\nmake pre-commit    # runs pre-commit hooks on staged files\n</code></pre> <p>As well as GitHub Actions code scanning.</p>"},{"location":"development/#testing","title":"\ud83e\uddea Testing","text":"<p>Test coverage includes:</p> <ul> <li>Unit tests under <code>tests/unit/</code></li> <li>Integration tests under <code>tests/integration/</code></li> <li>End-to-end tests under <code>tests/e2e/</code></li> <li>Example payload performance testing under <code>tests/hey/</code></li> </ul> <p>Use:</p> <pre><code>make test          # run all tests\nmake test-unit     # run only unit tests\nmake test-e2e      # run end-to-end\n</code></pre>"},{"location":"development/#linting-and-hooks","title":"\ud83d\udd0d Linting and Hooks","text":"<p>CI will fail your PR if code does not pass lint checks.</p> <p>You should manually run:</p> <pre><code>make lint\nmake pre-commit\n</code></pre> <p>Enable hooks with:</p> <pre><code>pre-commit install\n</code></pre>"},{"location":"development/#containers","title":"\ud83d\udc33 Containers","text":"<p>Build and run with Podman or Docker:</p> <pre><code>make podman            # build production image\nmake podman-run-ssl    # run with self-signed TLS at https://localhost:4444\n</code></pre>"},{"location":"development/#authentication","title":"\ud83d\udd10 Authentication","text":"<p>Admin UI and API are protected by Basic Auth or JWT.</p> <p>To generate a JWT:</p> <pre><code>python3 -m mcpgateway.utils.create_jwt_token \\\n  -u admin \\\n  -e 10080 | tee token.txt\n\nexport MCPGATEWAY_BEARER_TOKEN=$(cat token.txt)\n</code></pre> <p>Then test:</p> <pre><code>curl -k -sX GET \\\n  -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\n  https://localhost:4444/tools | jq\n</code></pre>"},{"location":"development/#configuration","title":"\ud83d\udce6 Configuration","text":"<p>Edit <code>.env</code> or set environment variables. A complete list is documented in the README.</p> <p>Use:</p> <pre><code>cp .env.example .env\n</code></pre> <p>Key configs include:</p> Variable Purpose <code>DATABASE_URL</code> Database connection <code>JWT_SECRET_KEY</code> Signing key for JWTs <code>DEV_MODE=true</code> Enables hot reload and debug <code>CACHE_TYPE=memory</code> Options: memory, redis, none"},{"location":"development/#contribution-tips","title":"\ud83d\udea7 Contribution Tips","text":"<ul> <li>Pick a <code>good first issue</code></li> <li>Read the <code>CONTRIBUTING.md</code></li> <li>Fork, branch, commit with purpose</li> <li>Submit PRs against <code>main</code> with clear titles and linked issues</li> </ul>"},{"location":"development/#cicd","title":"\u2705 CI/CD","text":"<p>GitHub Actions enforce:</p> <ul> <li>CodeQL security scanning</li> <li>Pre-commit linting</li> <li>Dependency audits</li> <li>Docker image builds</li> </ul> <p>CI configs live in <code>.github/workflows/</code>.</p>"},{"location":"development/building/","title":"Building Locally","text":"<p>Follow these instructions to set up your development environment, build the gateway from source, and run it interactively.</p>"},{"location":"development/building/#prerequisites","title":"\ud83e\udde9 Prerequisites","text":"<ul> <li>Python \u2265 3.10</li> <li><code>make</code></li> <li>(Optional) Docker or Podman for container builds</li> </ul>"},{"location":"development/building/#one-liner-setup-recommended","title":"\ud83d\udd27 One-Liner Setup (Recommended)","text":"<pre><code>make venv install serve\n</code></pre> <p>This will:</p> <ol> <li>Create a virtual environment in <code>.venv/</code></li> <li>Install Python dependencies including dev extras</li> <li>Run the gateway using Gunicorn</li> </ol>"},{"location":"development/building/#manual-python-setup","title":"\ud83d\udc0d Manual Python Setup","text":"<pre><code>python3 -m venv .venv\nsource .venv/bin/activate\npip install -e \".[dev]\"\n</code></pre> <p>This installs:</p> <ul> <li>Core app dependencies</li> <li>Dev tools (<code>ruff</code>, <code>black</code>, <code>mypy</code>, etc.)</li> <li>Test runners (<code>pytest</code>, <code>coverage</code>)</li> </ul>"},{"location":"development/building/#running-the-app","title":"\ud83d\ude80 Running the App","text":"<p>You can run the gateway with:</p> <pre><code>make serve         # production-mode Gunicorn (http://localhost:4444)\nmake run           # dev-mode Uvicorn (reloads on change)\n./run.sh --reload  # same as 'make run', with CLI flags\n</code></pre> <p>Use <code>make run</code> or <code>./run.sh</code> during development for auto-reload.</p>"},{"location":"development/building/#live-reload-tips","title":"\ud83d\udd04 Live Reload Tips","text":"<p>Ensure <code>RELOAD=true</code> and <code>DEV_MODE=true</code> are set in your <code>.env</code> during development.</p> <p>Also set:</p> <pre><code>DEBUG=true\nLOG_LEVEL=debug\n</code></pre>"},{"location":"development/building/#test-it","title":"\ud83e\uddea Test It","text":"<pre><code>curl http://localhost:4444/health\ncurl http://localhost:4444/tools\n</code></pre> <p>You should see <code>[]</code> or registered tools (once added).</p>"},{"location":"development/documentation/","title":"Writing &amp; Publishing Documentation","text":"<p>Follow this guide when you need to add or update markdown pages under <code>docs/</code> and preview the documentation locally.</p>"},{"location":"development/documentation/#prerequisites","title":"\ud83e\udde9 Prerequisites","text":"<ul> <li>Python \u2265 3.10 (only for the initial virtual env \u2013 not required if you already have one)</li> <li><code>make</code> (GNU Make 4+)</li> <li>(First-time only) <code>mkdocs-material</code> and plugins are installed automatically by the docs <code>Makefile</code>.</li> <li>One-time GitHub setup, e.g. gitconfig setup</li> </ul>"},{"location":"development/documentation/#one-liner-for-a-live-preview","title":"\u26a1 One-liner for a live preview","text":"<pre><code>cd docs\nmake venv     # First-time only, installs dependencies into a venv under `~/.venv/mcpgateway-docs`\nmake serve    # http://localhost:8000 (auto-reload on save)\n</code></pre> <p>The <code>serve</code> target automatically creates a project-local virtual environment (under <code>~/.venv/mcpgateway-docs</code>) the first time you run it and installs all doc dependencies before starting MkDocs in live-reload mode.</p>"},{"location":"development/documentation/#folder-layout","title":"\ud83d\udcc2 Folder layout","text":"<pre><code>repo-root/\n\u251c\u2500 docs/              # MkDocs project (DO NOT put .md files here!)\n\u2502  \u251c\u2500 docs/           # &lt;-- \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6  place Markdown pages here\n\u2502  \u2502  \u2514\u2500 ...\n\u2502  \u251c\u2500 mkdocs.yml      # MkDocs config &amp; navigation\n\u2502  \u2514\u2500 Makefile        # build / serve / clean targets\n\u2514\u2500 Makefile           # repo-wide helper targets (lint, spellcheck, \u2026)\n</code></pre> <ul> <li>Add new pages inside <code>docs/docs/</code> \u2013 organise them in folders that make sense for navigation.</li> <li>Update navigation: edit <code>.pages</code> for your section so your page shows up in the left-hand nav.</li> </ul> <p>Tip: MkDocs Material auto-generates \"Edit this page\" links \u2013 keep file names lowercase-hyphen-case.</p>"},{"location":"development/documentation/#editing-tips","title":"\u270f\ufe0f Editing tips","text":"<ol> <li>Write in standard Markdown; we also support admonitions, call-outs, and Mermaid diagrams.</li> <li>Use relative links between pages: <code>[Gateway API](../api/index.md)</code>.</li> <li>For local images place them under <code>docs/docs/images/</code> and reference with <code>![](../images/example.png)</code>.</li> <li>Never edit <code>mkdocs.yml</code> - all nav structure is defined in <code>.pages</code> files (one per directory).</li> </ol>"},{"location":"development/documentation/#writing-docs","title":"\u270f\ufe0f Writing docs","text":"<p>Start each new Markdown file with a clear <code># Heading 1</code> title \u2013 this becomes the visible page title and is required for proper rendering in MkDocs.</p> <p>Follow the conventions and layout guidelines from the official MkDocs Material reference for callouts, tables, code blocks, and more. This ensures consistent formatting across the docs.</p> <p>Keep file names in <code>lowercase-hyphen-case.md</code> and use relative links when referencing other docs or images.</p>"},{"location":"development/documentation/#ordering-pages-with-pages","title":"\ud83d\uddc2\ufe0f Ordering pages with <code>.pages</code>","text":"<p>For directories that contain multiple Markdown files, we rely on the awesome-pages MkDocs plugin.</p> <p>Creating a <code>.pages</code> file inside a folder lets you:</p> <ul> <li>Set the section title (different from the folder name).</li> <li>Control the left\u2011nav order without touching the root <code>mkdocs.yml</code>.</li> <li>Hide specific files from the navigation.</li> </ul> <p>We do not auto-generate the <code>nav:</code> structure \u2013 you must create <code>.pages</code> manually.</p> <p>Example \u2013 docs for the development section:</p> <pre><code># docs/docs/development/.pages\n# This file affects ONLY this folder and its sub\u2011folders\n\n# Optional: override the title shown in the nav\n# title: Development Guide\n\nnav:\n  - index.md        # \u279f /development/ (landing page)\n  - github.md       # contribution workflow\n  - building.md     # local build guide\n  - packaging.md    # release packaging steps\n</code></pre> <p>Guidelines:</p> <ol> <li>Always include <code>index.md</code> first so the folder has a clean landing URL.</li> <li>List files in the exact order you want them to appear; anything omitted is still built but won't show in the nav.</li> <li>You can nest <code>.pages</code> files in deeper folders \u2013 rules apply hierarchically.</li> <li>Avoid circular references: do not include files from other directories.</li> </ol> <p>After saving a <code>.pages</code> file, simply refresh the browser running <code>make serve</code>; MkDocs will hot\u2011reload and the navigation tree will update instantly.</p>"},{"location":"development/documentation/#pre-commit-checklist","title":"\u2705 Pre-commit checklist","text":"<p>From the repository root run all lint &amp; QA checks before pushing:</p> <pre><code>make spellcheck           # Spell-check the codebase\nmake spellcheck-sort      # Sort local spellcheck dictionary\nmake markdownlint         # Lint Markdown files with markdownlint (requires markdownlint-cli)\nmake pre-commit           # Run all configured pre-commit hooks\n</code></pre> <p>These targets are defined in the top-level <code>Makefile</code>. Make sure you're in the repository root when running these targets.</p>"},{"location":"development/documentation/#cleaning-up","title":"\ud83e\uddf9 Cleaning up","text":"<pre><code>cd docs\nmake clean       # remove generated site/\nmake git-clean   # remove ignored files per .gitignore\nmake git-scrub   # blow away *all* untracked files \u2013 use with care!\n</code></pre>"},{"location":"development/documentation/#rebuilding-the-static-site","title":"\ud83d\udd04 Rebuilding the static site","text":"<p>This is not necessary, as this will be done automatically when publishing.</p> <pre><code>cd docs\nmake build    # outputs HTML into docs/site/\n</code></pre> <p>The <code>build</code> target produces a fully-static site (used by CI for docs previews and by GitHub Pages).</p>"},{"location":"development/documentation/#publishing-ci","title":"\ud83d\udce4 Publishing (CI)","text":"<p>Docs are tested, but not deployed automatically by GitHub Actions on every push to <code>main</code>. The workflow runs <code>cd docs &amp;&amp; make build</code>.</p> <p>Publishing is done manually by repo maintainers with <code>make deploy</code> which publishes the generated site to GitHub Pages.</p>"},{"location":"development/documentation/#related-reading","title":"\ud83d\udd17 Related reading","text":"<ul> <li>Building Locally \u2013 how to run the gateway itself</li> </ul>"},{"location":"development/github/","title":"GitHub Workflow Guide","text":"<p>This mini\u2011handbook covers the daily Git tasks we use on mcp-context-forge - from the first clone to the last merge.</p>"},{"location":"development/github/#1-onetime-setup","title":"1. One\u2011Time Setup","text":"<pre><code># Fork on GitHub from https://github.com/IBM/mcp-context-forge.git first, then:\ngit clone https://github.com/&lt;your\u2011user&gt;/mcp-context-forge.git\ncd mcp-context-forge\n\n# Add the canonical repo so you can pull upstream changes\ngit remote add upstream https://github.com/IBM/mcp-context-forge.git\ngit remote -v   # sanity\u2011check remotes\n</code></pre>"},{"location":"development/github/#15-installing-github-cli-gh","title":"1.5 Installing GitHub CLI (<code>gh</code>)","text":""},{"location":"development/github/#macos-homebrew","title":"macOS (Homebrew)","text":"<pre><code>brew install gh\n</code></pre>"},{"location":"development/github/#windows-winget","title":"Windows (winget)","text":"<p>While you can run all this through Powershell, the recommended way to develop on Windows is through WSL2 and Visual Studio Code. The same steps as Ubuntu/Debian apply.</p> <pre><code>winget install GitHub.cli\n</code></pre>"},{"location":"development/github/#ubuntu-debian","title":"Ubuntu / Debian","text":"<pre><code>curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | \\\n  sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg\nsudo chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg\n\necho \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main\" | \\\n  sudo tee /etc/apt/sources.list.d/github-cli.list\n\nsudo apt update\nsudo apt install gh\n</code></pre>"},{"location":"development/github/#fedora-rhel","title":"Fedora / RHEL","text":"<pre><code>sudo dnf install 'https://github.com/cli/cli/releases/download/v2.74.0/gh_2.74.0_linux_amd64.rpm'\n</code></pre> <p>Tip: Replace the version number (<code>2.74.0</code>) with the latest release from https://github.com/cli/cli/releases.</p>"},{"location":"development/github/#firsttime-authentication","title":"First\u2011time authentication","text":"<pre><code>gh auth login             # follow the interactive prompts\n</code></pre> <p>Choose:</p> <ol> <li>GitHub.com</li> <li>HTTPS</li> <li>Either Paste an authentication token or Authorize in browser.</li> </ol>"},{"location":"development/github/#verify-configuration","title":"Verify configuration","text":"<pre><code>gh auth status            # should say \"Logged in to github.com as &lt;your\u2011user&gt;\"\ngh repo view              # shows repo info if run inside a clone\n</code></pre>"},{"location":"development/github/#everyday-commands","title":"Everyday commands","text":"Command Purpose <code>gh pr checkout &lt;id&gt;</code> Fetch &amp; switch to a PR locally (used in \u00a74). <code>gh pr create -w</code> Create a PR and open it in the browser. <code>gh pr status</code> Show which PR is checked out and any requested reviews. <code>gh pr merge &lt;id&gt;</code> Squash / rebase / merge the PR from the terminal."},{"location":"development/github/#16-personal-git-configuration-recommended","title":"1.6 Personal Git Configuration (Recommended)","text":"<p>Setting a few global Git options makes everyday work friction\u2011free and guarantees that every commit passes DCO checks.</p>"},{"location":"development/github/#161-commit-template","title":"1.6.1 Commit template","text":"<p>Create a single\u2011line template that Git pre\u2011pends to every commit message so you never forget the sign\u2011off:</p> <pre><code>echo 'Signed-off-by: &lt;Your Name&gt; &lt;you@example.com&gt;' &gt; ~/.git-commit-template\n</code></pre>"},{"location":"development/github/#162-gitconfig-example","title":"1.6.2 <code>~/.gitconfig</code> example","text":"<p>Put this in <code>~/.gitconfig</code> (or append the bits you're missing):</p> <pre><code># ~/.gitconfig\n[user]\n    name = &lt;Your Name&gt;\n    email = &lt;you@example.com&gt;\n\n[init]\n    defaultBranch = main  # Use 'main' instead of 'master' when creating new repos\n\n[core]\n    autocrlf = input       # On commit: convert CRLF to LF (Windows \u2192 Linux)\n    eol = lf               # Ensure all files in the repo use LF internally\n\n[alias]\n    cm = commit -s -m      # `git cm \"message\"` \u2192 signed commit\n    ca = commit --amend -s # `git ca` \u2192 amend + sign\u2011off\n\n[commit]\n    template = ~/.git-commit-template\n</code></pre> <p>Or run the one\u2011liners:</p> <pre><code>git config --global user.name  \"Your Name\"\ngit config --global user.email \"you@example.com\"\ngit config --global alias.cm   \"commit -s -m\"\ngit config --global alias.ca   \"commit --amend -s\"\ngit config --global commit.template ~/.git-commit-template\n</code></pre> <p>Replace placeholders with your real details, and you're good to go.</p>"},{"location":"development/github/#2-staying-in-sync-with-upstream","title":"2. Staying in Sync with Upstream","text":"<pre><code># From any branch:\ngit fetch upstream\ngit switch main                 # or master, depending on the project\ngit merge --ff-only upstream/main\n\ngit push origin main             # keep your fork up to date\n</code></pre>"},{"location":"development/github/#3-creating-your-own-work-branch","title":"3. Creating Your Own Work Branch","text":"<pre><code>git switch -c feat/my-great-idea\n# \u2026hack away\u2026\ngit add .\n# Always sign your commits for DCO compliance:\ngit commit -s -m \"feat: explain context\u2011merging algorithm\"\n\ngit push -u origin HEAD          # publishes the branch\n# Then open a Pull Request (PR) on GitHub.\n</code></pre> <p>Why <code>-s</code>? The <code>-s / --signoff</code> flag appends a <code>Signed-off-by: Your Name &lt;email&gt;</code> trailer that lets CI verify Developer Certificate of Origin (DCO) compliance.</p>"},{"location":"development/github/#4-fetching-reviewing-an-existing-pr","title":"4. Fetching &amp; Reviewing an Existing PR","text":""},{"location":"development/github/#41-with-plain-git-works-everywhere","title":"4.1 With Plain Git (works everywhere)","text":"<pre><code>git fetch upstream pull/29/head:pr-29   # Pull Request #29\ngit switch pr-29\n</code></pre>"},{"location":"development/github/#42-with-github-cli-fastest-if-installed","title":"4.2 With GitHub CLI (fastest if installed)","text":"<pre><code>gh pr checkout 29\n</code></pre>"},{"location":"development/github/#5-smoketesting-every-pr-before-you-comment","title":"5. Smoke\u2011Testing Every PR Before You Comment \ud83c\udf0b","text":"<p>Hard rule: No PR gets a \"Looks good to me\" without passing both the local and container builds below.</p>"},{"location":"development/github/#51-local-build-sqlite-selfsigned-https","title":"5.1 Local build (SQLite + self\u2011signed HTTPS)","text":"<pre><code>make venv install install-dev serve-ssl\n</code></pre> <ul> <li>Sets up a Python virtualenv</li> <li>Installs runtime + dev dependencies</li> <li>Runs the HTTPS dev server against SQLite</li> </ul>"},{"location":"development/github/#52-container-build-postgresql-redis","title":"5.2 Container build (PostgreSQL + Redis)","text":"<pre><code>make compose-up\n</code></pre> <ul> <li>Spins up the full Docker Compose stack</li> <li>Uses PostgreSQL for persistence and Redis for queueing</li> <li>Rebuilds images so you catch Docker\u2011specific issues</li> </ul>"},{"location":"development/github/#53-gateway-jwt-local-api-access","title":"5.3 Gateway JWT (local API access)","text":"<p>Quickly confirm that authentication works and the gateway is healthy:</p> <pre><code>export MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token -u admin --secret my-test-key)\ncurl -s -k -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" https://localhost:4444/health\n</code></pre> <p>Expected output:</p> <pre><code>{\"status\": \"ok\"}\n</code></pre> <p>If you see anything other than <code>{\"status\":\"ok\"}</code>, investigate before approving the PR.</p> <p>Quickly confirm that the MCP Gateway is configured with the correct database, and it is reachable:</p> <pre><code>curl -s -k -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" https://localhost:4444/version | jq\n</code></pre> <p>Then proceed to register an MCP Server under Gateways using the UI, ensuring that Tools work, creating a Virtual Server and testing that from UI, API and a MCP Client.</p> <p>These steps are described in Basic Testing.</p>"},{"location":"development/github/#54-run-the-automated-test-suite","title":"5.4 Run the automated test suite","text":"<pre><code>make test         # or `pytest` directly\n</code></pre> <p>All tests must pass locally. If you add or modify functionality, ensure new tests cover the change.</p>"},{"location":"development/github/#55-lint-static-analysis","title":"5.5 Lint &amp; static analysis","text":"<pre><code>make lint         # runs ruff, mypy, black --check, etc.\n</code></pre> <p>Code should come back clean. Fix any warnings before pushing.</p> <p>If any of the above steps fail, leave a review requesting fixes and paste the relevant logs inline or as a gist.</p>"},{"location":"development/github/#6-squashing-commits","title":"6. Squashing Commits \ud83e\udd5e","text":"<p>Keeping a clean, single\u2011commit history per PR makes <code>git bisect</code> and blame easier.</p>"},{"location":"development/github/#61-squash-interactively-local-recommended","title":"6.1 Squash interactively (local, recommended)","text":"<pre><code># In your feature branch, before pushing OR after addressing review feedback:\n\ngit fetch upstream  # make sure refs are fresh\ngit rebase -i upstream/main\n</code></pre> <p>In the interactive list, mark the first commit as <code>pick</code> and every subsequent one as <code>squash</code> (or <code>fixup</code> for no extra message). Save &amp; quit; Git opens an editor so you can craft the final commit message\u2014remember to keep the <code>Signed-off-by</code> line!</p> <p>If the branch is already on GitHub and you've squashed locally, force\u2011push the updated, single\u2011commit branch:</p> <pre><code>git push --force-with-lease\n</code></pre>"},{"location":"development/github/#62-squash-via-github-ui-simple-but-lastminute","title":"6.2 Squash via GitHub UI (simple, but last\u2011minute)","text":"<ol> <li>In the PR, click \"Merge\" \u2192 \"Squash and merge.\"</li> <li>Tweak the commit title/description as needed.</li> <li>Ensure the <code>Signed-off-by:</code> trailer is present (GitHub adds it automatically if you enabled DCO in the repo).</li> </ol> <p>Use the UI method only if reviewers are done\u2014every push re\u2011triggers CI.</p>"},{"location":"development/github/#7-functional-code-review-checklist","title":"7. Functional &amp; Code Review Checklist","text":"Check Why it matters Does it build locally? Fastest signal that the code even compiles. Does it build in Docker? Catches missing OS packages or env\u2011var mishaps. Unit tests green? Ensures regressions are caught immediately. No new lint errors? Keeps the CI pipeline and codebase clean. Commits squashed &amp; signed? One commit history + DCO compliance. Docs / comments updated? Future devs will thank you."},{"location":"development/github/#8-merging-the-pr","title":"8. Merging the PR","text":"<ul> <li>Squash\u2011and\u2011merge is the default merge strategy.</li> <li>Confirm the final commit message follows Conventional Commits and retains a <code>Signed-off-by:</code> trailer.</li> <li>GitHub automatically deletes the source branch after a successful merge\u2014no manual cleanup required.</li> </ul> <p>Verify GitHub CI status checks</p> <p>Before requesting review, confirm that all required status checks on the PR page are green \u2705 (\"All checks have passed\"). You should now see something like:</p> <pre><code>Bandit / bandit (pull_request)                  \u2705  Successful in 21s\nBuild Python Package / build-package (3.10)     \u2705  Successful in 12s\nCode scanning results / Bandit                  \u2705  No new alerts in code changed by this pull request\nCode scanning results / Dockle                  \u2705  No new alerts in code changed by this pull request\nCode scanning results / Hadolint                \u2705  No new alerts in code changed by this pull request\nCode scanning results / Trivy                   \u2705  No new alerts in code changed by this pull request\nCodeQL Advanced / CodeQL (javascript-typescript)\u2705  Successful in 1m\nCodeQL Advanced / CodeQL (python)               \u2705  Successful in 1m\nDCO                                             \u2705  Passed\nDependency Review / dependency-review           \u2705  Successful in 4s\nSecure Docker Build / build-scan-sign           \u2705  Successful in 4m\nTravis CI - Branch                              \u2705  Build Passed\nTravis CI - Pull Request                        \u2705  Build Passed\n</code></pre> <p>If anything is red or still running, wait or push a fix in the same PR until every line is green. Ensure that a CODEOWNER is assigned to review the PR.</p> <p>Once the PR is merged, double\u2011check that the CI/CD pipeline deploys the change to all environments without errors.</p> <p>If any of the above steps fail after the PR is merged or cannot deploy, leave a review requesting fixes and paste the relevant logs inline or as a gist.</p>"},{"location":"development/github/#9-cleaning-up-locally","title":"9. Cleaning Up Locally","text":"<p>After the PR is merged: * Switch back to the main branch * Delete the local feature branch * Prune deleted remote branches <pre><code>git switch main\ngit branch -D pr-29                # or the feature branch name (replace pr-29 with your branch name)\ngit fetch -p                       # prune remotes that GitHub deleted\n</code></pre> This removes references to remote branches that GitHub deleted after the merge. This keeps your local environment clean and up to date.</p>"},{"location":"development/github/#10-handy-git-aliases-optional","title":"10. Handy Git Aliases (Optional)","text":"<p><pre><code>git config --global alias.co checkout\ngit config --global alias.cm 'commit -s -m'\ngit config --global alias.ca 'commit --amend -s'\ngit config --global alias.rb \"rebase -i --autosquash\"\ngit config --global alias.pr '!f() { git fetch upstream pull/$1/head:pr-$1 &amp;&amp; git switch pr-$1; }; f'\n</code></pre> Now you can run <code>git pr 42</code> to fetch-and-switch to PR #42 in one go. These aliases are optional, but they save time and make Git commands easier to type.</p>"},{"location":"development/github/#11-troubleshooting-faq","title":"11. Troubleshooting FAQ","text":"Symptom Fix <code>error: cannot lock ref</code> Run <code>git gc --prune=now</code> and retry. <code>docker: no space left</code> <code>docker system prune -af &amp;&amp; docker volume prune</code> Unit tests hang on macOS Ensure you aren't on an Apple\u2011Silicon image that needs platform flags."},{"location":"development/github/#happy-hacking","title":"Happy hacking! \ud83d\udee0\ufe0f","text":"<p>Submit improvements to this doc via another signed, squashed PR so everyone benefits.</p>"},{"location":"development/packaging/","title":"Packaging &amp; Distribution","text":"<p>This guide covers how to package MCP Gateway for deployment in various environments, including building production containers and generating releases.</p>"},{"location":"development/packaging/#production-container-podman-or-docker","title":"\ud83d\udce6 Production Container (Podman or Docker)","text":"<p>Build an OCI-compliant container image using:</p> <pre><code>make podman\npodman build -t mcpgateway:latest -f Containerfile .\n</code></pre> <p>Or with Docker (if Podman is not available):</p> <pre><code>make docker\n# or manually\ndocker build -t mcpgateway:latest -f Containerfile .\n</code></pre> <p>A lite image is also available for use in production, see <code>Containerfile.lite</code></p>"},{"location":"development/packaging/#run-with-tls-self-signed","title":"\ud83d\udd10 Run with TLS (self-signed)","text":"<pre><code>make podman-run-ssl\n</code></pre> <p>This uses self-signed certs from <code>./certs/</code> and runs HTTPS on port <code>4444</code>.</p>"},{"location":"development/packaging/#container-run-http","title":"\ud83d\udee0 Container Run (HTTP)","text":"<pre><code>make podman-run\n</code></pre> <p>This runs the container without TLS on port <code>4444</code>.</p>"},{"location":"development/packaging/#versioning","title":"\ud83d\udcdd Versioning","text":"<p>MCP Gateway uses semantic versioning (<code>MAJOR.MINOR.PATCH</code>) and the version is defined in:</p> <pre><code>mcpgateway/__init__.py\n</code></pre> <p>You can bump the version manually or automate it via Git tags or CI/CD.</p>"},{"location":"development/packaging/#release-artifacts","title":"\ud83d\udcc1 Release Artifacts","text":"<p>If you need to ship ZIPs, wheels, or a full binary:</p> <pre><code>python3 -m build\n</code></pre> <p>Outputs will be under <code>dist/</code>. You can then:</p> <ul> <li>Push to PyPI (internal or public)</li> <li>Upload to GitHub Releases</li> <li>Package in a <code>.deb</code>, <code>.rpm</code>, etc.</li> </ul>"},{"location":"development/packaging/#whats-in-the-container","title":"\ud83d\udcc2 What's in the Container?","text":"<p>A typical image includes:</p> <ul> <li>Gunicorn running with <code>mcpgateway.main:app</code></li> <li>All code, static files, and compiled assets</li> </ul> <p>You can override settings using environment variables at runtime.</p>"},{"location":"development/review/","title":"Reviewing a Pull Request","text":"<p>This guide explains the day-to-day steps for reviewing a PR on GitHub, using both Git and the GitHub CLI (<code>gh</code>). It assumes you have already completed the one-time setup from the main workflow guide.</p>"},{"location":"development/review/#1-prerequisites","title":"1. Prerequisites","text":"<p>You should already have:</p> <ul> <li>A local clone of the forked repository, with <code>origin</code> pointing to your fork and <code>upstream</code> pointing to the canonical repo.</li> <li>The GitHub CLI (<code>gh</code>) installed and authenticated.</li> <li>Your <code>main</code> branch up to date with upstream:</li> </ul> <pre><code>  git fetch upstream\n  git switch main\n  git merge --ff-only upstream/main\n</code></pre>"},{"location":"development/review/#2-fetching-checking-out-the-pr","title":"2. Fetching &amp; Checking Out the PR","text":""},{"location":"development/review/#21-using-github-cli","title":"2.1 Using GitHub CLI","text":"<pre><code>gh pr checkout &lt;PR-number&gt;\n</code></pre> <p>This automatically fetches the PR and switches to a branch named <code>pr-&lt;PR-number&gt;</code>.</p>"},{"location":"development/review/#22-using-plain-git","title":"2.2 Using Plain Git","text":"<pre><code>git fetch upstream pull/&lt;PR-number&gt;/head:pr-&lt;PR-number&gt;\ngit switch pr-&lt;PR-number&gt;\n</code></pre>"},{"location":"development/review/#3-smoke-testing-the-changes","title":"3. Smoke-Testing the Changes","text":"<p>Before you read code or leave comments, always verify the PR builds and tests cleanly.</p>"},{"location":"development/review/#31-local-build","title":"3.1 Local Build","text":"<pre><code>make venv install install-dev serve   # Install into a fresh venv, and test it runs locally\n</code></pre>"},{"location":"development/review/#32-container-build-if-applicable","title":"3.2 Container Build (if applicable)","text":"<pre><code>make docker-prod    # Build a new image\nmake compose-up     # spins up the Docker Compose stack\n</code></pre>"},{"location":"development/review/#33-automated-tests","title":"3.3 Automated Tests","text":"<pre><code>make test           # or `pytest`, `npm test`, etc.\n</code></pre>"},{"location":"development/review/#34-lint-static-analysis","title":"3.4 Lint &amp; Static Analysis","text":"<pre><code>make lint           # runs ruff, mypy, black --check, eslint, etc.\n</code></pre> <p>If any step fails, request changes and paste the relevant error logs.</p>"},{"location":"development/review/#4-functional-code-review-checklist","title":"4. Functional &amp; Code Review Checklist","text":"<p>Use this checklist as you browse the changes:</p> Check Why it matters Does it build locally? Ensures no missing dependencies or compile errors. Does it build in Docker? Catches environment-specific issues. Tests are green? Guards against regressions. No new lint errors? Maintains code quality and consistency. Commits are clean &amp; signed? One-commit history &amp; DCO compliance. Code follows style guidelines Consistency in formatting, naming, and patterns. Security checks passed No secrets leaked, inputs validated, etc. Docs / comments updated? Documentation stays in sync with code. Edge cases &amp; error handling Robustness against invalid inputs or failures."},{"location":"development/review/#5-leaving-feedback","title":"5. Leaving Feedback","text":""},{"location":"development/review/#51-inline-comments","title":"5.1 Inline Comments","text":"<p>Use <code>gh pr review</code> to leave comments:</p> <pre><code># To comment without approving\ngh pr review --comment --body \"Nit: rename this variable for clarity.\"\n\n# To request changes\ngh pr review --request-changes --body \"Tests are failing on CI, please fix.\"\n\n# To approve\ngh pr review --approve --body \"Looks good to me!\"\n</code></pre>"},{"location":"development/review/#52-approving-in-the-ui","title":"5.2 Approving in the UI","text":"<ol> <li>On the PR page, click \"Files changed\".</li> <li>Hover over a line and click the + to leave an inline comment.</li> <li>After addressing all comments, click Review changes \u2192 Approve.</li> </ol>"},{"location":"development/review/#6-merging-the-pr-as-a-maintainer","title":"6. Merging the PR (as a Maintainer)","text":"<p>Only merge once all approvals, status checks, and CI jobs are green.</p> <ol> <li>On GitHub, click Merge pull request.</li> <li>Choose Squash and merge (default) or Rebase and merge.</li> <li>Verify the commit title and body follow Conventional Commits.</li> <li>Confirm the Signed-off-by trailer is present.</li> <li>Click Confirm merge.</li> </ol> <p>GitHub will delete the <code>pr-&lt;number&gt;</code> branch automatically.</p>"},{"location":"development/review/#7-cleaning-up-locally","title":"7. Cleaning Up Locally","text":"<p>After the PR is merged: * Switch back to the main branch * Delete the local feature branch * Prune deleted remote branches <pre><code>git switch main\ngit branch -D pr-&lt;PR-number&gt;             # replace &lt;PR-number&gt; with your branch name\ngit fetch -p                             # prune deleted remotes\n</code></pre> This removes references to remote branches that GitHub deleted after the merge. This keeps your local environment clean and up to date.</p>"},{"location":"faq/","title":"ContextForge MCP Gateway \u2013 Frequently Asked Questions","text":""},{"location":"faq/#quickstart","title":"\u26a1 Quickstart","text":"\ud83d\ude80 How can I install and run MCP Gateway in one command? <p>PyPI (pipx / uvenv makes an isolated venv):</p> <pre><code># Using pipx - pip install pipx\npipx run mcp-contextforge-gateway\n\n# Or uvenv - pip install uvenv (default: admin/changeme)\nuvenv run mcp-contextforge-gateway --port 4444\n</code></pre> <p>OCI image (Docker/Podman) \u2013 shares host network so localhost works:</p> <pre><code>podman run --network=host -p 4444:4444 ghcr.io/ibm/mcp-context-forge:latest\n</code></pre> \ud83d\uddc2\ufe0f What URLs are available for the admin interface and API docs? <ul> <li>Admin UI \u2192 https://localhost:4444</li> <li>Swagger \u2192 https://localhost:4444/docs</li> <li>ReDoc \u2192 https://localhost:4444/redoc</li> </ul>"},{"location":"faq/#what-is-mcp-model-context-protocol","title":"\ud83e\udd14 What is MCP (Model Context Protocol)?","text":"\ud83d\udca1 What is MCP in a nutshell? <p>MCP is an open\u2011source protocol released by Anthropic in Nov 2024 that lets language models invoke external tools via a typed JSON\u2011RPC envelope. Community folks call it \"USB\u2011C for AI\"\u2014one connector for many models.</p> \ud83c\udf0d Who supports MCP and what's the ecosystem like? <ul> <li>Supported by GitHub &amp; Microsoft Copilot, AWS Bedrock, Google Cloud Vertex AI, IBM watsonx, AgentBee, LangChain, CrewAI and 15,000+ community servers.</li> <li>Contracts enforced via JSON Schema.</li> <li>Multiple transports (STDIO, SSE, HTTP) \u2014 still converging.</li> </ul>"},{"location":"faq/#media-kit","title":"\ud83e\uddf0 Media Kit","text":"\ud83d\uddbc\ufe0f I want to make a social media post, where can I find samples and logos? <p>See the provided media kit</p> \ud83d\udcc4 How do I describe the gateway in boilerplate copy? <p>\"ContextForge MCP Gateway is an open\u2011source reverse\u2011proxy that unifies MCP and REST tool servers under a single secure HTTPS endpoint with discovery, auth and observability baked in.\"</p>"},{"location":"faq/#installation-configuration","title":"\ud83d\udee0\ufe0f Installation &amp; Configuration","text":"\ud83d\udd27 What is the minimal .env setup required? <pre><code>cp .env.example .env\n</code></pre> <p>Then edit:</p> <pre><code>BASIC_AUTH_USER=admin\nBASIC_AUTH_PASSWORD=changeme\nJWT_SECRET_KEY=my-test-key\n</code></pre> \ud83e\ude9b What are some advanced environment variables I can configure? <ul> <li>Basic: <code>HOST</code>, <code>PORT</code>, <code>APP_ROOT_PATH</code></li> <li>Auth: <code>AUTH_REQUIRED</code>, <code>BASIC_AUTH_*</code>, <code>JWT_SECRET_KEY</code></li> <li>Logging: <code>LOG_LEVEL</code>, <code>LOG_FORMAT</code>, <code>LOG_FILE</code></li> <li>Transport: <code>TRANSPORT_TYPE</code>, <code>WEBSOCKET_PING_INTERVAL</code>, <code>SSE_RETRY_TIMEOUT</code></li> <li>Tools: <code>TOOL_TIMEOUT</code>, <code>MAX_TOOL_RETRIES</code>, <code>TOOL_RATE_LIMIT</code>, <code>TOOL_CONCURRENT_LIMIT</code></li> <li>Federation: <code>FEDERATION_ENABLED</code>, <code>FEDERATION_PEERS</code>, <code>FEDERATION_SYNC_INTERVAL</code></li> </ul>"},{"location":"faq/#running-deployment","title":"\ud83d\ude80 Running &amp; Deployment","text":"\ud83c\udfe0 How do I run MCP Gateway locally using PyPI? <pre><code>python3 -m venv .venv &amp;&amp; source .venv/bin/activate\npip install mcp-contextforge-gateway\nmcpgateway\n</code></pre> \ud83d\udc33 How do I use the provided Makefile and Docker/Podman setup? <pre><code>make podman # or make docker\nmake podman-run-ssl # or make docker-run-ssl\nmake podman-run-ssl-host # or make docker-run-ssl-host\n</code></pre> <p>Docker Compose is also available, ex: <code>make compose-up</code>.</p> \u2601\ufe0f How can I deploy MCP Gateway on Google Cloud Run, Code Engine, Kubernetes, AWS, etc? <p>See the Deployment Documentation for detailed deployment instructions across local, docker, podman, compose, AWS, Azure, GCP, IBM Cloud, Helm, Minikube, Kubernetes, OpenShift and more.</p>"},{"location":"faq/#databases-persistence","title":"\ud83d\udcbe Databases &amp; Persistence","text":"\ud83d\uddc4\ufe0f What databases are supported for persistence? <ul> <li>SQLite (default) - used for development / small deployments.</li> <li>PostgreSQL / MySQL / MariaDB via <code>DATABASE_URL</code></li> <li>Redis (optional) for high performance session management. Sessions can also be stored in the DB or memory.</li> <li>Other databases supported by SQLAlchemy.</li> </ul> \ud83d\udce6 How do I persist SQLite across container restarts? <p>Include a persistent volume with your container or Kubernetes deployment. Ex:</p> <pre><code>docker run -v $(pwd)/data:/app ghcr.io/ibm/mcp-context-forge:latest\n</code></pre> <p>For production use, we recommend PostgreSQL. A Docker Compose target with PostgreSQL and Redis is provided.</p>"},{"location":"faq/#security-auth","title":"\ud83d\udd10 Security &amp; Auth","text":"\ud83c\udd93 How do I disable authentication for development? <p>Set <code>AUTH_REQUIRED=false</code> \u2014 disables login for local testing.</p> \ud83d\udd11 How do I generate and use a JWT token? <pre><code>export MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token -u admin -exp 0 --secret my-test-key)\ncurl -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" https://localhost:4444/tools\n</code></pre> <p>The token is used for all API interactions and can be configured to expire using <code>-exp</code>.</p> \ud83d\udee1\ufe0f How do I enable TLS and configure CORS? <ul> <li>Use <code>make podman-run-ssl</code> for self-signed certs or drop your own certificate under <code>certs</code>.</li> <li>Set <code>ALLOWED_ORIGINS</code> or <code>CORS_ENABLED</code> for CORS headers.</li> </ul>"},{"location":"faq/#tools-servers-federation","title":"\ud83d\udce1 Tools, Servers &amp; Federation","text":"\u2795 How do I register a tool with the gateway? <pre><code>curl -X POST -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\\\n     -H \"Content-Type: application/json\" \\\\\n     -d '{\"name\":\"clock_tool\",\"url\":\"http://localhost:9000/rpc\",\"input_schema\":{\"type\":\"object\"}}' \\\\\n     http://localhost:4444/tools\n</code></pre> \ud83c\udf09 How do I add a peer MCP gateway? <p>A \"Gateway\" is another MCP Server. The MCP Gateway itself is an MCP Server. This means you can add any MCP Server under \"Gateways\" and it will retrieve Tools/Resources/Prompts.</p> <pre><code>curl -X POST -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" \\\\\n     -d '{\"name\":\"peer\",\"url\":\"http://peer:4444\"}' \\\\\n     http://localhost:4444/gateways\n</code></pre> \ud83d\udd87\ufe0f What are virtual servers and how do I use them? <p>A Virtual Server is a MCP Server composed from Tools/Resources/Prompts from multiple servers. Add one or more MCP Servers under \"Gateways\", then select which Tools/Prompts/Resources to use to create your Virtual Server.</p>"},{"location":"faq/#performance-tuning-scaling","title":"\ud83c\udfce\ufe0f Performance Tuning &amp; Scaling","text":"\u2699\ufe0f What environment variables affect performance? <ul> <li><code>TOOL_CONCURRENT_LIMIT</code></li> <li><code>TOOL_RATE_LIMIT</code></li> <li><code>WEBSOCKET_PING_INTERVAL</code></li> <li><code>SSE_RETRY_TIMEOUT</code></li> </ul> \ud83e\uddf5 How do I scale the number of worker processes? <ul> <li><code>GUNICORN_WORKERS</code> (for Gunicorn)</li> <li><code>UVICORN_WORKERS</code> (for Uvicorn)</li> </ul> \ud83d\udcca How can I benchmark performance? <p>Use <code>ab</code> or <code>wrk</code> against <code>/health</code> to measure raw latency. Check out the detail performance testing harness under <code>tests/hey</code>.</p>"},{"location":"faq/#observability-logging","title":"\ud83d\udcc8 Observability &amp; Logging","text":"\ud83d\udd0d What metrics are available? <ul> <li>Prometheus-style <code>/metrics</code> endpoint</li> <li>Tool/server/prompt stats via Admin UI</li> </ul> \ud83d\udcdc What log formats are supported? <ul> <li><code>LOG_FORMAT=json</code> or <code>text</code></li> <li>Adjust with <code>LOG_LEVEL</code></li> </ul>"},{"location":"faq/#smoke-tests-troubleshooting","title":"\ud83e\uddea Smoke Tests &amp; Troubleshooting","text":"\ud83d\udeeb Is there a full test script I can run? <p>Yes \u2014 see <code>docs/basic.md</code>.</p> \ud83d\udea8 What common errors should I watch for? Symptom Resolution 401 Unauthorized Refresh token / check Authorization database is locked Use Postgres / increase DB_POOL_SIZE already exists errors Use Show inactive toggle in UI SSE drops every 30 s Raise <code>SSE_RETRY_TIMEOUT</code>"},{"location":"faq/#integration-recipes","title":"\ud83d\udcbb Integration Recipes","text":"\ud83e\udd9c How do I use MCP Gateway with LangChain? <pre><code>from langchain.tools import MCPTool\ntool = MCPTool(endpoint=\"https://localhost:4444/json-rpc\",\n               token=os.environ[\"MCPGATEWAY_BEARER_TOKEN\"])\n</code></pre> \ud83e\uddbe How do I connect GitHub's mcp-server-git via SuperGateway? <pre><code>npx -y supergateway --stdio \"uvx run mcp-server-git\"\n</code></pre>"},{"location":"faq/#roadmap","title":"\ud83d\uddfa\ufe0f Roadmap","text":"\ud83e\udded What features are planned for future versions? <ul> <li>\ud83d\udd10 OAuth2 client-credentials upstream auth with full spec compliance</li> <li>\ud83c\udf19 Dark-mode UI</li> <li>\ud83e\uddfe Add \"Version and Environment Info\" tab to Admin UI</li> <li>\ud83d\udd12 Fine-grained role-based access control (RBAC) for Admin UI and API routes and per-virtual-server API keys</li> <li>\ud83d\udce6 Marketplace-style tool catalog with categories, tags, and search</li> <li>\ud83d\udd01 Support for long-running / async tool executions with polling endpoints</li> <li>\ud83d\udcc2 UI-driven prompt and resource file management (upload/edit from browser)</li> <li>\ud83d\udee0\ufe0f Visual \"tool builder\" UI to design new tools with schema and auth interactively</li> <li>\ud83e\uddea Auto-validation tests for registered tools (contract + mock invocation)</li> <li>\ud83d\udea8 Event subscription framework: trigger hooks or alerts on Gateway changes</li> <li>\ud83e\uddf5 Real-time tool logs and debug traces in Admin UI</li> <li>\ud83e\udde0 Adaptive routing based on tool health, model, or load</li> <li>\ud83d\udd0d Filterable tool invocation history with replay support</li> <li>\ud83d\udce1 Plugin-based architecture for custom transports or auth methods</li> </ul> <p>Check out the Feature issues tagged <code>enhancement</code> on GitHub for more upcoming features!</p>"},{"location":"faq/#rarely-asked-questions-raq","title":"\u2753 Rarely Asked Questions (RAQ)","text":"\ud83d\udc19 Does MCP Gateway work on a Raspberry Pi? <p>Yes \u2014 build as <code>arm64</code> and reduce RAM/workers.</p>"},{"location":"faq/#contributing-community","title":"\ud83e\udd1d Contributing &amp; Community","text":"\ud83d\udc69\u200d\ud83d\udcbb How can I file issues or contribute? <p>Use GitHub Issues and <code>CONTRIBUTING.md</code>.</p> \ud83e\uddd1\u200d\ud83c\udf93 What code style and CI tools are used? <ul> <li>Pre-commit: <code>ruff</code>, <code>black</code>, <code>mypy</code>, <code>isort</code></li> <li>Run <code>make lint</code> before PRs</li> </ul> \ud83d\udcac Where can I chat or ask questions? <p>Join the GitHub Discussions board.</p>"},{"location":"faq/#need-more-help","title":"\ud83d\ude4b Need more help?","text":"<p>Open an Issue or discussion on GitHub.</p>"},{"location":"manage/","title":"Management Overview","text":"<p>This section provides operational guidance for running and maintaining a production instance of MCP Gateway.</p> <p>Whether you're self-hosting, running in the cloud, or deploying to Kubernetes, this section helps you monitor, back up, and maintain the system.</p>"},{"location":"manage/#whats-covered","title":"\ud83e\udded What's Covered","text":"Page Description Backups How to persist and restore your database, configs, and resource state Logging Configure structured logging, log destinations, and log rotation"},{"location":"manage/#runtime-config-via-env","title":"\ud83d\udd10 Runtime Config via <code>.env</code>","text":"<p>Most operational settings (logging level, database pool size, auth mode) are controlled through <code>.env</code> or environment variables.</p> <p>Update the file and restart the container or process to apply changes.</p>"},{"location":"manage/#health-readiness","title":"\ud83e\uddea Health &amp; Readiness","text":"<p>Expose the <code>/health</code> endpoint for use with:</p> <ul> <li>Cloud load balancer health checks</li> <li>Kubernetes probes</li> <li>CI/CD smoke tests</li> </ul> <p>Sample check:</p> <pre><code>curl http://localhost:4444/health\n</code></pre> <p>Expected response:</p> <pre><code>{ \"status\": \"healthy\"}\n</code></pre>"},{"location":"manage/#service-restart-commands","title":"\ud83d\udd01 Service Restart Commands","text":"<p>Depending on your environment:</p> <ul> <li><code>docker restart mcpgateway</code></li> <li><code>kubectl rollout restart deployment/mcpgateway</code></li> </ul>"},{"location":"manage/backup/","title":"Backups","text":"<p>MCP Gateway stores its runtime state in a SQL database and optionally in Redis (for sessions and caching). This guide explains how to persist and restore that state safely.</p>"},{"location":"manage/backup/#what-needs-to-be-backed-up","title":"\ud83d\udce6 What Needs to Be Backed Up","text":"Component What It Contains Database (<code>mcp.db</code> or PostgreSQL) All tools, prompts, resources, servers, metrics <code>.env</code> file Environment variables and secrets (e.g. JWT secret, DB URL) Volume-mounted uploads (if any) User-uploaded data or TLS certs Redis (optional) Session tokens, cached resources (only if using <code>CACHE_TYPE=redis</code>)"},{"location":"manage/backup/#backup-strategies","title":"\ud83d\udcbe Backup Strategies","text":""},{"location":"manage/backup/#for-sqlite-default","title":"For SQLite (default)","text":"<pre><code>cp mcp.db backups/mcp-$(date +%F).db\n</code></pre>"},{"location":"manage/backup/#for-postgresql","title":"For PostgreSQL","text":"<pre><code>pg_dump -U youruser -h yourhost -F c -f backups/mcp-$(date +%F).pgdump\n</code></pre> <p>You can also automate this via <code>cron</code> or a container sidecar.</p>"},{"location":"manage/backup/#restore-instructions","title":"\ud83d\udd01 Restore Instructions","text":""},{"location":"manage/backup/#sqlite","title":"SQLite","text":"<pre><code>cp backups/mcp-2024-05-10.db mcp.db\n</code></pre> <p>Restart the gateway afterward.</p>"},{"location":"manage/backup/#postgresql","title":"PostgreSQL","text":"<pre><code>pg_restore -U youruser -d mcp -h yourhost backups/mcp-2024-05-10.pgdump\n</code></pre>"},{"location":"manage/backup/#storing-secrets","title":"\ud83d\uddc3 Storing Secrets","text":"<p>Use a secrets manager (e.g., AWS Secrets Manager, Azure Key Vault, or Kubernetes Secrets) to manage <code>.env</code> contents securely in production.</p>"},{"location":"manage/backup/#verify-your-backup","title":"\ud83e\uddea Verify Your Backup","text":"<p>Run smoke tests:</p> <pre><code>curl -s -k -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" http://localhost:4444/tools\ncurl -s -k -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" http://localhost:4444/prompts\n</code></pre> <p>You should see previously registered tools and templates.</p>"},{"location":"manage/backup/#understanding-the-database-schema","title":"\ud83e\uddec Understanding the Database Schema","text":"<p>MCP Gateway uses a relational database (e.g. SQLite or PostgreSQL) to persist all registered entities and track tool/server usage. When session storage is configured as <code>CACHE_TYPE=database</code>, it also persists active user sessions and streamed message content.</p>"},{"location":"manage/backup/#key-tables","title":"Key Tables","text":"Table Purpose <code>tools</code> Stores registered tools, including schemas and auth configs <code>tool_metrics</code> Tracks execution stats per tool (latency, success/fail) <code>resources</code> Stores static or dynamic URI-based resources <code>resource_metrics</code> Logs usage of resources (access count, latency, etc.) <code>resource_subscriptions</code> Tracks SSE client subscriptions to resources <code>prompts</code> Jinja2 prompt templates with input arguments <code>prompt_metrics</code> Usage metrics for each prompt <code>servers</code> Virtual servers that group tools/resources under an SSE stream <code>server_metrics</code> Invocation stats per server <code>gateways</code> External federated MCP servers added by the admin <code>mcp_sessions</code> Persistent session registry when using <code>CACHE_TYPE=database</code> <code>mcp_messages</code> Persisted streamed content (text/image/etc.) tied to sessions <code>*_association</code> tables Many-to-many mapping between tools/resources/prompts and their servers/gateways"},{"location":"manage/backup/#session-and-message-tables","title":"Session and Message Tables","text":"<p>These only appear when session/messaging backend is set to <code>database</code>:</p> <ul> <li><code>mcp_sessions</code>: Each record is an open session ID (used for SSE streams and client context).</li> <li><code>mcp_messages</code>: Stores streamed messages (text, image, resource) linked to a session\u2014useful for debugging or offline playback.</li> </ul> <p>You can query active sessions:</p> <pre><code>SELECT session_id, created_at FROM mcp_sessions ORDER BY created_at DESC;\n</code></pre> <p>Or inspect message content (JSON-encoded):</p> <pre><code>SELECT content FROM mcp_messages WHERE session_id = 'abc123';\n</code></pre> <p>These tables are cleaned automatically when session TTLs expire, but can also be purged manually if needed.</p>"},{"location":"manage/logging/","title":"Logging","text":"<p>MCP Gateway emits structured logs that can be viewed locally or forwarded to a log aggregation service. This guide shows how to configure log levels, formats, and destinations.</p>"},{"location":"manage/logging/#log-structure","title":"\ud83e\uddfe Log Structure","text":"<p>Logs are emitted in JSON or text format, depending on your configuration.</p> <p>Example (JSON format):</p> <pre><code>{\n  \"timestamp\": \"2025-05-15T10:32:10Z\",\n  \"level\": \"INFO\",\n  \"module\": \"gateway_service\",\n  \"message\": \"Registered gateway: peer-gateway-1\"\n}\n</code></pre>"},{"location":"manage/logging/#configuring-logs","title":"\ud83d\udd27 Configuring Logs","text":"<p>You can control logging behavior using <code>.env</code> settings:</p> Variable Description Example <code>LOG_LEVEL</code> Minimum log level <code>INFO</code>, <code>DEBUG</code>, <code>ERROR</code> <code>LOG_FORMAT</code> Log output format <code>json</code> or <code>text</code> <code>LOG_FILE</code> Write logs to a file (optional) <code>/var/log/mcpgateway.log</code>"},{"location":"manage/logging/#streaming-logs-containers","title":"\ud83d\udce1 Streaming Logs (Containers)","text":"<pre><code>docker logs -f mcpgateway\n# or with Podman\npodman logs -f mcpgateway\n</code></pre>"},{"location":"manage/logging/#shipping-logs-to-external-services","title":"\ud83d\udce4 Shipping Logs to External Services","text":"<p>MCP Gateway can write to stdout or a file. To forward logs to services like:</p> <ul> <li>ELK (Elastic Stack)</li> <li>LogDNA / IBM Log Analysis</li> <li>Datadog</li> <li>Fluentd / Loki</li> </ul> <p>You can:</p> <ul> <li>Mount log files to a sidecar container</li> <li>Use a logging agent (e.g., Filebeat)</li> <li>Pipe logs to syslog-compatible services</li> </ul>"},{"location":"manage/logging/#debug-mode","title":"\ud83e\uddea Debug Mode","text":"<p>For development, enable verbose logs by setting:</p> <pre><code>LOG_LEVEL=debug\nLOG_FORMAT=text\nDEBUG=true\n</code></pre> <p>This enables detailed request traces and internal service logs.</p>"},{"location":"manage/tuning/","title":"Gateway Tuning Guide","text":"<p>This page collects practical levers for squeezing the most performance, reliability, and observability out of MCP Gateway\u2014no matter where you run the container (Code Engine, Kubernetes, Docker Compose, Nomad, etc.).</p> <p>TL;DR</p> <ol> <li>Tune the runtime environment via <code>.env</code> and configure mcpgateway to use PostgreSQL and Redis.</li> <li>Adjust Gunicorn workers &amp; time\u2011outs in <code>gunicorn.conf.py</code>.</li> <li>Right\u2011size CPU/RAM for the container or spin up more instances (with shared Redis state) and change the database settings (ex: connection limits).</li> <li>Benchmark with hey (or your favourite load\u2011generator) before &amp; after. See also: performance testing guide</li> </ol>"},{"location":"manage/tuning/#1-environment-variables-env","title":"1 \u00b7 Environment variables (<code>.env</code>)","text":"Variable Default Why you might change it <code>AUTH_REQUIRED</code> <code>true</code> Disable for internal/behind\u2011VPN deployments to shave a few ms per request. <code>JWT_SECRET_KEY</code> random Longer key \u279c slower HMAC verify; still negligible\u2014leave as is. <code>CACHE_TYPE</code> <code>database</code> Switch to <code>redis</code> or <code>memory</code> if your workload is read\u2011heavy and latency\u2011sensitive. <code>DATABASE_URL</code> SQLite Move to managed PostgreSQL + connection pooling for anything beyond dev tests. <code>HOST</code>/<code>PORT</code> <code>0.0.0.0:4444</code> Expose a different port or bind only to <code>127.0.0.1</code> behind a reverse\u2011proxy. <p>Tip  Any change here requires rebuilding or restarting the container if you pass the file with <code>--env\u2011file</code>.</p>"},{"location":"manage/tuning/#2-gunicorn-settings-gunicornconfpy","title":"2 \u00b7 Gunicorn settings (<code>gunicorn.conf.py</code>)","text":"Knob Purpose Rule of thumb <code>workers</code> Parallel processes <code>2\u20134 \u00d7 vCPU</code> for CPU\u2011bound work; fewer if memory\u2011bound. <code>threads</code> Per\u2011process threads Use only with <code>sync</code> worker; keeps memory low for I/O workloads. <code>timeout</code> Kill stuck worker Set \u2265 end\u2011to\u2011end model latency. E.g. 600 s for LLM calls. <code>preload_app</code> Load app once Saves RAM; safe for pure\u2011Python apps. <code>worker_class</code> Async workers <code>gevent</code> or <code>eventlet</code> for many concurrent requests / websockets. <code>max_requests(+_jitter)</code> Self\u2011healing Recycle workers to mitigate memory leaks. <p>Edit the file before building the image, then redeploy.</p>"},{"location":"manage/tuning/#3-container-resources","title":"3 \u00b7 Container resources","text":"vCPU \u00d7 RAM Good for Notes <code>0.5 \u00d7 1 GB</code> Smoke tests / CI Smallest footprint; likely CPU\u2011starved under load. <code>1 \u00d7 4 GB</code> Typical dev / staging Handles a few hundred RPS with default 8 workers. <code>2 \u00d7 8 GB</code> Small prod Allows ~16\u201320 workers; good concurrency. <code>4 \u00d7 16 GB</code>+ Heavy prod Combine with async workers or autoscaling. <p>Always test with your workload; JSON\u2011RPC payload size and backend model latency change the equation.</p> <p>To change your database connection settings, see the respective documentation for your selected database or managed service. For example, when using IBM Cloud Databases for PostgreSQL - you can raise the maximum number of connections.</p>"},{"location":"manage/tuning/#4-performance-testing","title":"4 \u00b7 Performance testing","text":""},{"location":"manage/tuning/#41-tooling-hey","title":"4.1 Tooling: hey","text":"<p>Install one of:</p> <pre><code>brew install hey            # macOS\nsudo apt install hey         # Debian/Ubuntu\n# or build from source\ngo install github.com/rakyll/hey@latest  # $GOPATH/bin must be in PATH\n</code></pre>"},{"location":"manage/tuning/#42-sample-loadtest-script-testsheysh","title":"4.2 Sample load\u2011test script (<code>tests/hey.sh</code>)","text":"<pre><code>#!/usr/bin/env bash\n# Run 10 000 requests with 200 concurrent workers.\nJWT=\"$(cat jwt.txt)\"   # &lt;- place a valid token here\nhey -n 10000 -c 200 \\\n    -m POST \\\n    -T application/json \\\n    -H \"Authorization: Bearer ${JWT}\" \\\n    -D tests/hey/payload.json \\\n    http://localhost:4444/rpc\n</code></pre> <p>Payload (<code>tests/hey/payload.json</code>)</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"convert_time\",\n  \"params\": {\n    \"source_timezone\": \"Europe/Berlin\",\n    \"target_timezone\": \"Europe/Dublin\",\n    \"time\": \"09:00\"\n  }\n}\n</code></pre>"},{"location":"manage/tuning/#43-reading-the-output","title":"4.3 Reading the output","text":"<p><code>hey</code> prints latency distribution, requests/second, and error counts. Focus on:</p> <ul> <li>99<sup>th</sup> percentile latency \u2013 adjust <code>timeout</code> if it clips.</li> <li>Errors \u2013 5xx under load often mean too few workers or DB connections.</li> <li>Throughput (RPS) \u2013 compare before/after tuning.</li> </ul>"},{"location":"manage/tuning/#44-common-bottlenecks-fixes","title":"4.4 Common bottlenecks &amp; fixes","text":"Symptom Likely cause Mitigation High % of 5xx under load Gunicorn workers exhausted Increase <code>workers</code>, switch to async workers, raise CPU. Latency &gt; timeout Long model call / external API Increase <code>timeout</code>, add queueing, review upstream latency. Memory OOM Too many workers / large batch size Lower <code>workers</code>, disable <code>preload_app</code>, add RAM."},{"location":"manage/tuning/#5-logging-observability","title":"5 \u00b7 Logging &amp; observability","text":"<ul> <li>Set <code>loglevel = \"debug\"</code> in <code>gunicorn.conf.py</code> during tests; revert to <code>info</code> in prod.</li> <li>Forward <code>stdout</code>/<code>stderr</code> from the container to your platform's log stack (e.g. <code>kubectl logs</code>, <code>docker logs</code>).</li> <li>Expose <code>/metrics</code> via Prometheus exporter (coming soon) for request timing &amp; queue depth.</li> </ul>"},{"location":"manage/tuning/#6-security-tips-while-tuning","title":"6 \u00b7 Security tips while tuning","text":"<ul> <li>Never commit real <code>JWT_SECRET_KEY</code>, DB passwords, or tokens\u2014use <code>.env.example</code> as a template.</li> <li>Prefer platform secrets (K8s Secrets, Code Engine secrets) over baking creds into the image.</li> <li>If you enable <code>gevent</code>/<code>eventlet</code>, pin their versions and run bandit or trivy scans.</li> </ul>"},{"location":"manage/upgrade/","title":"Upgrading MCP Gateway and Managing Database Migrations","text":"<p>This guide provides step-by-step instructions for upgrading the MCP Gateway and handling associated database migrations to ensure a smooth transition with minimal downtime.</p>"},{"location":"manage/upgrade/#upgrade-overview","title":"\ud83d\udd04 Upgrade Overview","text":"<p>MCP Gateway is under active development, and while we strive for backward compatibility, it's essential to review version changes carefully when upgrading. Due to rapid iterations, documentation updates may sometimes lag. If you encounter issues, consult our GitHub repository or reach out via GitHub Issues.</p>"},{"location":"manage/upgrade/#upgrade-steps","title":"\ud83d\udee0 Upgrade Steps","text":""},{"location":"manage/upgrade/#1-backup-current-configuration-and-data","title":"1. Backup Current Configuration and Data","text":"<p>Before initiating an upgrade:</p> <ul> <li>Export Configuration: Backup your current configuration files.</li> <li>Database Backup: Create a full backup of your database to prevent data loss.</li> </ul>"},{"location":"manage/upgrade/#2-review-release-notes","title":"2. Review Release Notes","text":"<p>Check the release notes for:</p> <ul> <li>Breaking Changes: Identify any changes that might affect your current setup.</li> <li>Migration Scripts: Look for any provided scripts or instructions for database migrations.</li> </ul>"},{"location":"manage/upgrade/#3-update-mcp-gateway","title":"3. Update MCP Gateway","text":"<p>Depending on your deployment method: podman, docker, kubernetes, etc.</p>"},{"location":"manage/upgrade/#4-apply-database-migrations","title":"4. Apply Database Migrations","text":"<p>If the new version includes database schema changes:</p> <ul> <li>Migration Scripts: Execute any provided migration scripts.</li> <li>Manual Migrations: If no scripts are provided, consult the release notes for manual migration instructions.</li> </ul>"},{"location":"manage/upgrade/#5-verify-the-upgrade","title":"5. Verify the Upgrade","text":"<p>Post-upgrade, ensure:</p> <ul> <li>Service Availability: MCP Gateway is running and accessible.</li> <li>Functionality: All features and integrations are working as expected.</li> <li>Logs: Check logs for any errors or warnings.</li> </ul>"},{"location":"manage/upgrade/#testing-and-validation","title":"\ud83e\uddea Testing and Validation","text":"<ul> <li>Staging Environment: Test the upgrade process in a staging environment before applying to production.</li> <li>Automated Tests: Run your test suite to catch any regressions.</li> <li>User Acceptance Testing (UAT): Engage end-users to validate critical workflows.</li> </ul>"},{"location":"manage/upgrade/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>MCP Gateway GitHub Repository</li> <li>MCP Gateway Documentation</li> </ul>"},{"location":"media/","title":"Media","text":"<p>This section collects press coverage, social-media highlights, customer testimonials, and a ready-to-use media kit:</p> <ul> <li>Press Coverage</li> <li>Social Highlights</li> <li>Testimonials</li> <li>Media Kit</li> </ul>"},{"location":"media/#other-catalogs","title":"Other catalogs:","text":"<ul> <li>https://mcp.so/server/mcp-context-forge/IBM</li> </ul>"},{"location":"media/kit/","title":"\ud83e\uddf0 Media Kit","text":"<p>Everything you need to write about ContextForge MCP Gateway\u2014assets, ready-to-use copy, badges, images, and quick-start commands.</p>"},{"location":"media/kit/#what-is-mcp-model-context-protocol","title":"\ud83e\udd14 What is MCP (Model Context Protocol)?","text":"<p>MCP is an open-source protocol released by Anthropic in November 2024 that lets AI agents communicate with external tools through a standard JSON-RPC envelope. It's often described as the \"USB-C of AI\"\u2014a universal connector for language models.</p> <p>It's widely supported by GitHub Copilot, Microsoft Copilot, AWS Bedrock, Google Cloud AI, IBM watsonx, and 15,000+ servers in the community.</p>"},{"location":"media/kit/#why-it-matters","title":"\u26a1 Why it matters","text":"<ul> <li>\u2705 Standardized interface contracts via typed JSON Schema</li> <li>\u2705 Supported across the ecosystem \u2014 GitHub/Microsoft Copilot, AWS Bedrock, Google Cloud AI, IBM watsonx, AgentBee, LangChain, CrewAI, and more</li> <li>\u2705 Strong ecosystem - 15,000+ MCP-compatible servers and multiple clients, with announcements from multiple major vendors</li> </ul>"},{"location":"media/kit/#current-challenges","title":"\u274c Current challenges","text":"<ul> <li>\u274c Fragmented transports: STDIO, SSE, HTTP \u2014 with some methods already deprecated</li> <li>\u274c Inconsistent authentication: none, JWT, OAuth</li> <li>\u274c Operational overhead: managing endpoints, credentials, retries, and logs for each tool</li> <li>\u274c Version mismatch: clients and servers may support different MCP versions</li> </ul>"},{"location":"media/kit/#why-contextforge-mcp-gateway","title":"\ud83d\udca1 Why ContextForge MCP Gateway?","text":"<p>Problem: Most teams build one-off adapters for each tool or model, leading to maintenance burden and slow development.</p> <p>ContextForge MCP Gateway solves this by proxying all MCP and REST tool servers through a single HTTPS + JSON-RPC endpoint, with discovery, security, and observability built in.</p> <p>It lets you create Virtual Servers - remixing tools/prompts/resources from multiple servers, introduce strong Auth - and change protocol versions on the fly. It lets you easily create new MCP Servers without having to write any code - by proxing existing REST services.</p> <p>And is readily available as open source, published a container image and as a Python module published on PyPi - so you can get started with a single command - and scale all the way up to multi-regional Kubernetes clusters.</p> Pain Point How Gateway Solves It Transport fragmentation (STDIO/SSE/HTTP) Unifies everything under HTTPS + JSON-RPC DIY wrappers &amp; retry logic Automatic, schema-validated retry handling Weak auth layers Built-in JWT (or OAuth) &amp; rate limiting No visibility Per-call and per-server metrics &amp; logging Onboarding difficulties Built-in admin UI for tools, prompts, and resources <p></p>"},{"location":"media/kit/#sample-announcements","title":"\ud83d\udcd1 Sample Announcements","text":"\ud83d\udce3 Non-Technical Post \ud83d\udee0\ufe0f Technical Post \ud83d\udee0\ufe0f Connect Cline VS Code Extension to ContextForge MCP Gateway <p>A great idea is to create posts, videos or articles on using specific clients or with MCP Gateway. Provide details on how to run and register a number of useful MCP Servers, adding them to the gateway, then using specific clients to connect. For example, Visual Studio Cline, GitHub Copilot, Langchain, etc. Example:</p>"},{"location":"media/kit/#meet-contextforge-mcp-gateway-simplify-ai-tool-connections","title":"Meet ContextForge MCP Gateway: Simplify AI Tool Connections","text":"<p>Building AI agents should be easy\u2014but each tool speaks a different dialect.</p> <p>ContextForge MCP Gateway is a universal hub: one secure endpoint that discovers your tools and works seamlessly with Copilot, CrewAI, LangChain, and more.</p> <p>\"What should be simple often becomes a debugging nightmare. The ContextForge MCP Gateway solves that.\" \u2014 Mihai Criveti</p> <p>Try it in 60 seconds: <pre><code>docker run -d --name mcpgateway \\\n  -p 4444:4444 \\\n  -e JWT_SECRET_KEY=YOUR_KEY \\\n  ghcr.io/ibm/mcp-context-forge:latest\n</code></pre></p> <p>Please \u2b50 the project on GitHub if you find this useful, it helps us grow!</p>"},{"location":"media/kit/#introducing-contextforge-mcp-gateway-the-missing-proxy-for-ai-agents-and-tools","title":"Introducing ContextForge MCP Gateway: The Missing Proxy for AI Agents and Tools","text":"<p>ContextForge MCP Gateway normalizes STDIO, SSE, REST, and HTTP MCP servers into one HTTPS + JSON-RPC interface with full MCP support.</p> <p>It includes schema-validated retries, JWT auth, and a built-in catalog UI.</p> <p>Docker: <pre><code>docker run -d --name mcpgateway \\\n  -p 4444:4444 \\\n  -e JWT_SECRET_KEY=YOUR_KEY \\\n  ghcr.io/ibm/mcp-context-forge:latest\n</code></pre></p> <p>PyPI: <pre><code>pip install mcp-gateway\nmcpgateway --host 0.0.0.0 --port 4444\n</code></pre></p> <p>Please \u2b50 the project on GitHub if you find this useful, it helps us grow!</p>"},{"location":"media/kit/#connect-your-cline-extension-to-mcp-gateway","title":"Connect your Cline extension to MCP Gateway","text":"<p>ContextForge MCP Gateway offers a unified HTTPS + JSON\u2011RPC endpoint for AI tools, making integration seamless\u2014including with Cline, a VS Code extension that supports MCP.</p> <p>Start the Gateway (Docker): <pre><code>docker run -d --name mcpgateway \\\n  -p 4444:4444 \\\n  -e JWT_SECRET_KEY=YOUR_KEY \\\n  ghcr.io/ibm/mcp-context-forge:latest\n</code></pre></p> <p>Or install via PyPI:</p> <pre><code>pip install mcp-gateway\nmcpgateway --host 0.0.0.0 --port 4444\n</code></pre> <p>\u2b50 Enjoying this? Leave a star on GitHub!</p>"},{"location":"media/kit/#what-is-cline","title":"\ud83d\udd0d What is Cline?","text":"<p>Cline is a powerful AI coding assistant for VS Code. It supports MCP, allowing it to discover and use tools provided through MCP Gateway.</p>"},{"location":"media/kit/#set-up-jwt-authentication","title":"\ud83d\udd10 Set up JWT Authentication","text":"<p>In your Cline settings, add an MCP server:</p> <pre><code>{\n  \"name\": \"MCP Gateway\",\n  \"url\": \"http://localhost:4444\",\n  \"auth\": {\n    \"type\": \"bearer\",\n    \"token\": \"&lt;YOUR_JWT_TOKEN&gt;\"\n  }\n}\n</code></pre> <p>Enable the server in Cline\u2014you should see a green \"connected\" indicator when authentication succeeds.</p>"},{"location":"media/kit/#using-mcp-tools-in-cline","title":"\ud83d\ude80 Using MCP Tools in Cline","text":"<p>With the connection live, Cline can:</p> <ul> <li>Automatically list tools exposed by the Gateway</li> <li>Use simple prompts to invoke tools, e.g.:</li> </ul> <p><pre><code>Run the `list_files` tool with path: \"./src\"\n</code></pre> * Display results and JSON output directly within the VS Code interface</p> <p>Try it yourself\u2014and don't forget to \u2b50 the project at ContextForge MCP Gateway!</p>"},{"location":"media/kit/#logo-images","title":"\ud83d\uddbc\ufe0f Logo &amp; Images","text":"Asset URL Transparent PNG logo <code>https://ibm.github.io/mcp-context-forge/logo.png</code> Hero demo GIF <code>https://ibm.github.io/mcp-context-forge/images/mcpgateway.gif</code> Architecture overview SVG"},{"location":"media/kit/#social-snippets","title":"\ud83d\udce3 Social Snippets","text":"<p>Tweet / X</p> <p>Twitter / X</p> <p>\ud83d\ude80 ContextForge MCP Gateway is now open source! One endpoint to unify &amp; secure AI-tool connections (STDIO, SSE, REST). Give it a spin and drop a \u2b50 \u2192 IBM/mcp-context-forge #mcp #ai #tools</p> <p>LinkedIn</p> <p>Example</p> <p>Thrilled to share ContextForge MCP Gateway\u2014an open-source hub that turns fragmented AI-tool integrations into a single secure interface with discovery, observability, and a live catalog UI. Check it out on GitHub and leave us a star \u2b50! <code>#mcp #ai #tools</code></p> <p>Tip</p> <p>See Social for example articles and social media posts - and add your own there once published!</p>"},{"location":"media/press/","title":"Press Highlights","text":"<p>Coverage from industry publications, press, and news media about MCP Gateway, ACP, and IBM's agentic AI initiatives.</p>"},{"location":"media/press/#articles","title":"Articles","text":"<p>IBM MCP Gateway: Revolutionizing GenAI Integration for Startups and Enterprises (Pitangent)</p> <p>Author: Miltan Chaudhury | Publication: Pitangent | Date: June 11, 2025 Read the article</p> <p>Quote</p> <p>\"IBM's MCP Gateway is more than a bridge\u2014it's a platform for accelerating GenAI transformation with agility and confidence. For startups and enterprises navigating the complex AI tool landscape, this innovation brings a modular, future-proof path to build smarter, scalable, and context-aware applications.\"</p> <p>The article breaks down the technical benefits of the MCP Gateway and positions it as a game-changer for reducing integration overhead, improving developer productivity, and democratizing AI access for early-stage companies.</p> <p>IBM Introduces MCP Gateway to Simplify GenAI Tool Integration (Analytics India Magazine)</p> <p>Author: Ankush Das | Publication: Analytics India Magazine | Date: June 10, 2025 Read the article</p> <p>Quote</p> <p>\"IBM has launched MCP Gateway, a FastAPI-based component designed to streamline the integration and orchestration of generative AI tools and services. It is an open-source project made available under the Apache 2.0 license\u2026 Armand Ruiz, VP of AI Platform at IBM, stated on LinkedIn, 'I think this is a great step forward for those building agentic systems, orchestrating tools, or deploying complex GenAI apps.'\"</p> <p>The article also notes IBM's draft Agent Communication Protocol (ACP) as a complementary innovation to MCP, aimed at enabling standardized AI agent interaction as part of the BeeAI initiative.</p> <p>IBM Launches MCP Gateway to Merge and Manage AI Tools (Geekflare)</p> <p>Author: Keval Vachharajani | Publication: Geekflare | Date: June 10, 2025 Read the article</p> <p>Quote</p> <p>\"Built on FastAPI, the MCP Gateway is designed to act as a unified entry point for the Model Context Protocol (MCP)\u2026 According to Ruiz, this launch is particularly relevant for teams working on agent-based systems or orchestrating multiple AI tools within enterprise environments.\"</p> <p>The article highlights MCP Gateway's support for JSON-Schema validation, transport layer management, and its production-ready admin UI. It also mentions IBM Consulting's influence in shaping the tool and situates the launch within IBM's broader innovation efforts, including the new Watsonx AI Labs.</p>"},{"location":"media/social/","title":"Social Highlights","text":"<p>Check out these social media highlights, and write your own!</p>"},{"location":"media/social/#linkedin-posts","title":"LinkedIn Posts:","text":"<p>IBM's Armand Ruiz on MCP Gateway &amp; ACP (LinkedIn)</p> <p>Author: Analytics India Magazine | Date: June 10, 2025 View on LinkedIn</p> <p>Quote</p> <p>\"Armand Ruiz, IBM's VP of AI Platform, hails the open-source MCP Gateway as 'a great step forward for those building agentic systems, orchestrating tools, or deploying complex GenAI apps.' \u2026 With MCP Gateway streamlining tool orchestration and ACP redefining agent interactions, IBM is pushing to standardize AI infrastructure. As Ruiz emphasizes, this dual approach reduces deployment friction, empowering developers to scale GenAI applications efficiently.\"</p> <p>MCP Gateway Overview Post (LinkedIn)</p> <p>Author: Armand Ruiz - VP of AI Platform @ IBM | Date: June 9, 2025 View on LinkedIn</p> <p>Quote</p> <p>\"Introducing MCP Gateway, a powerful, FastAPI-based gateway for the Model Context Protocol, designed to unify and scale your AI toolchain\u2026 It does a lot\u2026 I think this is a great step forward for those building agentic systems, orchestrating tools, or deploying complex GenAI apps.\"</p> <p>MCP Gateway Launch Announcement (LinkedIn)</p> <p>Author: Mihai Criveti - Distinguished Engineer, Agentic AI @ IBM | Date: June 5, 2025 View on LinkedIn</p> <p>Quote</p> <p>\"Just open-sourced something I've been building \u2013 the MCP Gateway: turn any REST API into an MCP server, connect multiple MCP servers, combine tools into virtual servers, swap them on the fly, and adds observability and security \u2013 all in one container that can be deployed anywhere.\"</p>"},{"location":"media/social/#articles","title":"Articles","text":"<p>MCP Gateway: The Missing Proxy for AI Tools (Medium)</p> <p>Author: Mihai Criveti - Distinguished Engineer, Agentic AI @ IBM | Date: June 8, 2025 | 6 min read Read on Medium</p> <p>Quote</p> <p>\"AI agents and tool integration are exciting \u2014 until you actually try to connect them. Different authentication systems (or none), fragmented documentation, and incompatible protocols quickly turn what should be simple integrations into debugging nightmares. MCP Gateway solves this.\"</p> <p>Model Context Protocol (MCP) Gateway \u2014 a middleware meant to productionize MCP for an enterprise</p> <p>Author: Manoj Jahgirdar - AI Engineer, Agentic AI @ IBM | Date: June 13, 2025 | 6 min read Read on Medium</p> <p>Quote</p> <p>\"Learn how ContextForge MCP Gateway works \u2014 a secure, unified middleware for scaling agentic AI integrations in the enterprise.\"</p>"},{"location":"media/testimonials/","title":"Testimonials","text":""},{"location":"media/testimonials/#platforms","title":"Platforms","text":"<ul> <li>IBM Consulting Advantage IBM Consulting Advantage - AI-tooling platform, equipping 160,000 expert consultants with role, industry and business domain-specific AI assistants, agents, and applications.</li> </ul>"},{"location":"overview/","title":"Overview","text":"<p>Welcome to the MCP Gateway documentation.</p> <p>This section introduces what the Gateway is, how it fits into the MCP ecosystem, and what core features and capabilities it offers out of the box.</p>"},{"location":"overview/#what-is-mcp-gateway","title":"What is MCP Gateway?","text":"<p>MCP Gateway is an orchestration and federation layer for the Model Context Protocol (MCP). It provides:</p> <ul> <li>A unified entrypoint for tools, resources, prompts, and agents</li> <li>Federation of multiple MCP servers into one composable catalog</li> <li>Protocol enforcement, health monitoring, and registry centralization</li> <li>A visual Admin UI to manage everything in real time</li> </ul> <p>Whether you're integrating REST APIs, local functions, or full LLM agents, MCP Gateway standardizes access and transport \u2014 over HTTP, WebSockets, SSE, or stdio.</p>"},{"location":"overview/#whats-in-this-section","title":"What's in This Section","text":"Page Description Features Breakdown of supported features including federation, transports, and tool wrapping Admin UI Screenshots and explanation of the interactive web dashboard Quick Start Quick Installation and Start up"},{"location":"overview/features/","title":"\u2728 Features Overview","text":"<p>MCP Gateway is a gateway + registry + proxy purpose-built for the Model Context Protocol (MCP). It unifies REST, MCP, and stdio worlds while adding auth, caching, federation, and an HTMX-powered Admin UI.</p>"},{"location":"overview/features/#multi-transport-core","title":"\ud83c\udf10 Multi-Transport Core","text":"Supported Transports Transport Description Typical Use-case HTTP / JSON-RPC Low-latency request-response, default for most REST clients Simple tool invocations WebSocket Bi-directional, full-duplex Streaming chat or incremental tool results Server-Sent Events (SSE) Uni-directional server \u2192 client stream LLM completions or real-time updates STDIO Local process pipes via <code>mcpgateway-wrapper</code> Editor plugins, headless CLI clients Try it: SSE from curl <pre><code>curl -N -H \"Accept: text/event-stream\" \\\n     -H \"Authorization: Bearer $TOKEN\" \\\n     http://localhost:4444/servers/1/sse\n</code></pre>"},{"location":"overview/features/#federation-discovery","title":"\ud83c\udf0d Federation &amp; Discovery","text":"Features <ul> <li>Auto-discovery \u2013 DNS-SD (<code>_mcp._tcp.local.</code>) or static peer list</li> <li>Health checks \u2013 fail-over + removal of unhealthy gateways</li> <li>Capability sync \u2013 merges remote tool catalogs into the local DB</li> <li>Request forwarding \u2013 automatic routing to the correct gateway</li> </ul> Architecture <pre><code>graph TD\n  subgraph Local_Gateway\n    A[MCP Gateway Core]\n  end\n  subgraph Remote_Gateway_1\n    B[Peer 1]\n  end\n  subgraph Remote_Gateway_2\n    C[Peer 2]\n  end\n  A &lt;-- ping / register --&gt; B\n  A &lt;-- ping / register --&gt; C</code></pre> Configuration <p>Enable or tweak discovery via <code>.env</code>:</p> <pre><code>FEDERATION_ENABLED=true\nFEDERATION_DISCOVERY=true\nFEDERATION_PEERS=https://remote.example.com\nHEALTH_CHECK_INTERVAL=30\n</code></pre>"},{"location":"overview/features/#security","title":"\ud83d\udd10 Security","text":"Auth mechanisms <ul> <li>JWT bearer (default, signed with <code>JWT_SECRET_KEY</code>)</li> <li>HTTP Basic for the Admin UI</li> <li>Custom headers (e.g., API keys) per tool or gateway</li> </ul> Rate limiting <p>Set <code>MAX_TOOL_CALLS_PER_MINUTE</code> to throttle abusive clients. Exceeding the limit returns HTTP 429 with a <code>Retry-After</code> header.</p> Generate a 24 h token <pre><code>python -m mcpgateway.utils.create_jwt_token \\\n  --username alice --exp 1440 --secret \"$JWT_SECRET_KEY\"\n</code></pre>"},{"location":"overview/features/#tool-server-registry","title":"\ud83d\udee0 Tool &amp; Server Registry","text":"What you can register Registry Entities Notes Tools Native MCP tools or wrapped REST / CLI functions JSON Schema input validation Resources URIs for blobs, text, images Optional SSE change notifications Prompts Jinja2 templates + multimodal content Versioning &amp; rollback Servers Virtual collections of tools/prompts/resources Exposed as full MCP servers REST tool example <pre><code>curl -X POST -H \"Authorization: Bearer $TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n           \"name\": \"joke_api\",\n           \"url\": \"https://icanhazdadjoke.com/\",\n           \"requestType\": \"GET\",\n           \"integrationType\": \"REST\",\n           \"headers\": {\"Accept\":\"application/json\"}\n         }' \\\n     http://localhost:4444/tools\n</code></pre>"},{"location":"overview/features/#admin-ui","title":"\ud83d\udda5 Admin UI","text":"Built with <ul> <li>FastAPI + Jinja2 + HTMX + Alpine.js</li> <li>Tailwind CSS for styling</li> </ul>"},{"location":"overview/features/#persistence-caching-observability","title":"\ud83d\uddc4 Persistence, Caching &amp; Observability","text":"Storage options <ul> <li>SQLite (default dev)</li> <li>PostgreSQL, MySQL/MariaDB, MongoDB \u2014 via <code>DATABASE_URL</code></li> </ul> Redis cache <pre><code>CACHE_TYPE=redis\nREDIS_URL=redis://localhost:6379/0\n</code></pre> Observability <ul> <li>Structured JSON logs (tap with <code>jq</code>)</li> <li><code>/metrics</code> \u2013 Prometheus-friendly counters (<code>tool_calls_total</code>, <code>gateway_up</code>)</li> <li><code>/health</code> \u2013 readiness + dependency checks</li> </ul>"},{"location":"overview/features/#dev-extensibility","title":"\ud83e\udde9 Dev &amp; Extensibility","text":"Highlights <ul> <li>Makefile targets \u2013 <code>make dev</code>, <code>make test</code>, <code>make lint</code></li> <li>400+ unit tests \u2013 Pytest + HTTPX TestClient</li> <li>VS Code Dev Container \u2013 Python 3.11 + Docker/Podman CLI</li> <li>Plug-in friendly \u2013 drop-in FastAPI routers or Pydantic models</li> </ul>"},{"location":"overview/features/#next-steps","title":"Next Steps","text":"<ul> <li>Hands-on Walk-through \u2192 Quick Start</li> <li>Deployment Guides \u2192 Compose, K8s &amp; Cloud</li> <li>Admin UI deep dive \u2192 UI Guide</li> </ul> <p>Ready to explore</p> <p>With transports, federation, and security handled for you, focus on building great MCP tools, prompts, and agents\u2014the gateway has your back.</p>"},{"location":"overview/quick_start/","title":"\ud83d\ude80 Quick Start","text":"<p>MCP Gateway can be running on your laptop or server in &lt; 5 minutes. Pick an install method below, generate an auth token, then walk through a real tool + server demo.</p>"},{"location":"overview/quick_start/#installing-and-starting-mcp-gateway","title":"Installing and starting MCP Gateway","text":"PyPI / virtual-envDocker / PodmanDocker Compose"},{"location":"overview/quick_start/#local-install-via-pypi","title":"Local install via PyPI","text":"<p>Note</p> <p>Prereqs: Python \u2265 3.10, plus <code>curl</code> &amp; <code>jq</code> for the smoke test.</p> <ol> <li> <p>Create an isolated environment and upgrade pip if required</p> <pre><code>mkdir mcpgateway &amp;&amp; cd mcpgateway\npython3 -m venv .venv &amp;&amp; source .venv/bin/activate\npython -m pip install --upgrade pip\n</code></pre> </li> <li> <p>Install the gateway from pypi</p> <pre><code>pip install mcp-contextforge-gateway\nmcpgateway --version\n</code></pre> </li> <li> <p>Launch it, listening on all interfaces</p> <pre><code>export BASIC_AUTH_PASSWORD=changeme\nexport JWT_SECRET_KEY=my-test-key\nmcpgateway --host 0.0.0.0 --port 4444\n</code></pre> <p>The terminal shows startup logs; keep it running.</p> </li> <li> <p>Generate a bearer token with an expiration time of 10080 seconds (1 week)</p> <pre><code>export MCP_BEARER_TOKEN=$(python -m mcpgateway.utils.create_jwt_token \\\n    --username admin --exp 10080 --secret my-test-key)\n</code></pre> <p>Use <code>--exp 0</code> for tokens that don't expire</p> </li> <li> <p>Smoke-test health + version</p> <pre><code>curl -s http://localhost:4444/health | jq\ncurl -s -H \"Authorization: Bearer $MCP_BEARER_TOKEN\" http://localhost:4444/version | jq\n</code></pre> </li> </ol>"},{"location":"overview/quick_start/#dockerpodman-container-install","title":"Docker/Podman Container install","text":"<p>Note</p> <p>Substitute <code>docker</code> with <code>podman</code> if preferred.</p> <ol> <li> <p>Run the image</p> <pre><code>docker run -d --name mcpgateway \\\n  -p 4444:4444 \\\n  -e HOST=0.0.0.0 \\\n  -e JWT_SECRET_KEY=my-test-key \\\n  -e BASIC_AUTH_USER=admin \\\n  -e BASIC_AUTH_PASSWORD=changeme \\\n  ghcr.io/ibm/mcp-context-forge:0.1.1\n</code></pre> </li> <li> <p>(Optional) persist the DB</p> <pre><code>mkdir -p $(pwd)/data\ndocker run -d --name mcpgateway \\\n  -p 4444:4444 \\\n  -v $(pwd)/data:/data \\\n  -e DATABASE_URL=sqlite:////data/mcp.db \\\n  -e JWT_SECRET_KEY=my-test-key \\\n  -e BASIC_AUTH_USER=admin \\\n  -e BASIC_AUTH_PASSWORD=changeme \\\n  ghcr.io/ibm/mcp-context-forge:0.1.1\n</code></pre> </li> <li> <p>Generate a token inside the container</p> <pre><code>docker exec mcpgateway python -m mcpgateway.utils.create_jwt_token \\\n  --username admin --exp 10080 --secret my-test-key\n</code></pre> </li> <li> <p>Smoke-test</p> <pre><code>export MCP_BEARER_TOKEN=&lt;paste_from_previous_step&gt;\ncurl -s http://localhost:4444/health | jq\ncurl -s -H \"Authorization: Bearer $MCP_BEARER_TOKEN\" http://localhost:4444/version | jq\n</code></pre> </li> </ol>"},{"location":"overview/quick_start/#run-the-full-stack-with-compose","title":"Run the full stack with Compose","text":"<p>Typical Compose file includes Gateway + Postgres + Redis and optional PgAdmin / Redis Commander. See the complete sample and advanced scenarios in Deployment \u203a Compose.</p> <ol> <li> <p>Install Compose v2 (if needed)</p> <pre><code># Ubuntu example\nsudo apt install docker-buildx docker-compose-v2\n# Tell the Makefile / docs which command to use\nexport COMPOSE_CMD=\"docker compose\"\n</code></pre> </li> <li> <p>Pull the published image</p> <pre><code>docker pull ghcr.io/ibm/mcp-context-forge:0.1.1\n</code></pre> </li> <li> <p>Start the stack</p> <pre><code># Uses podman or docker automatically\nmake compose-up\n# \u2014or\u2014 raw CLI\ndocker compose -f podman-compose.yml up -d\n</code></pre> </li> <li> <p>Verify</p> <pre><code>curl -s http://localhost:4444/health | jq\n</code></pre> </li> </ol> <p>Tip : The sample Compose file has multiple database blocks (Postgres, MariaDB, MySQL, MongoDB) and admin tools. Uncomment one and align <code>DATABASE_URL</code> for your preferred backend.</p>"},{"location":"overview/quick_start/#registering-mcp-tools-creating-a-virtual-server","title":"Registering MCP tools &amp; creating a virtual server","text":"<pre><code># Spin up a sample MCP time server (SSE, port 8002)\npip install uvenv\nnpx -y supergateway --stdio \"uvenv run mcp_server_time -- --local-timezone=Europe/Dublin\" --port 8002 &amp;\n</code></pre> <pre><code># Register that server with your gateway\ncurl -s -X POST -H \"Authorization: Bearer $MCP_BEARER_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"name\":\"local_time\",\"url\":\"http://localhost:8002/sse\"}' \\\n     http://localhost:4444/gateways | jq\n</code></pre> <pre><code># Bundle the imported tool(s) into a virtual MCP server\ncurl -s -X POST -H \"Authorization: Bearer $MCP_BEARER_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"name\":\"demo_server\",\"description\":\"Time tools\",\"associatedTools\":[\"1\"]}' \\\n     http://localhost:4444/servers | jq\n</code></pre> <pre><code># Verify catalog entries\ncurl -s -H \"Authorization: Bearer $MCP_BEARER_TOKEN\" http://localhost:4444/tools   | jq\ncurl -s -H \"Authorization: Bearer $MCP_BEARER_TOKEN\" http://localhost:4444/servers | jq\n</code></pre> <pre><code># Optional: Connect interactively via MCP Inspector\nnpx -y @modelcontextprotocol/inspector\n# Transport SSE \u2192 URL http://localhost:4444/servers/1/sse\n# Header Authorization \u2192 Bearer $MCP_BEARER_TOKEN\n</code></pre>"},{"location":"overview/quick_start/#connect-via-mcpgateway-wrapper-stdio","title":"Connect via <code>mcpgateway-wrapper</code> (stdio)","text":"<pre><code>export MCP_AUTH_TOKEN=$MCP_BEARER_TOKEN\nexport MCP_SERVER_CATALOG_URLS=http://localhost:4444/servers/1\npython -m mcpgateway.wrapper   # behaves as a local MCP stdio server - run from MCP client\n</code></pre> <p>Use this in GUI clients (Claude Desktop, Continue, etc.) that prefer stdio. Example:</p> <pre><code>{\n  \"mcpServers\": {\n    \"mcpgateway-wrapper\": {\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"mcpgateway.wrapper\"],\n      \"env\": {\n        \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/1\",\n        \"MCP_AUTH_TOKEN\": \"&lt;YOUR_JWT_TOKEN&gt;\",\n        \"MCP_TOOL_CALL_TIMEOUT\": \"120\"\n      }\n    }\n  }\n}\n</code></pre> <p>For more information see MCP Clients</p>"},{"location":"overview/quick_start/#4-useful-urls","title":"4 \u00b7 Useful URLs","text":"URL Description <code>http://localhost:4444/admin</code> Admin UI (Basic Auth: <code>admin</code> / <code>changeme</code>) <code>http://localhost:4444/tools</code> Tool registry (GET) <code>http://localhost:4444/servers</code> Virtual servers (GET) <code>/servers/&lt;id&gt;/sse</code> SSE endpoint for that server <code>/docs</code>, <code>/redoc</code> Swagger / ReDoc (JWT-protected)"},{"location":"overview/quick_start/#5-next-steps","title":"5 \u00b7 Next Steps","text":"<ul> <li>Features Overview \u2013 deep dive on transports, federation, caching</li> <li>Admin UI Guide</li> <li>Deployment to K8s / AWS / GCP / Azure</li> <li>Wrap any client via <code>mcpgateway-wrapper</code></li> <li>Tweak <code>.env</code> \u2013 see example</li> </ul> <p>Gateway is ready!</p> <p>You now have an authenticated MCP Gateway proxying a live tool, exposed via SSE and stdio. Jump into the Admin UI or start wiring it into your agents and clients!</p>"},{"location":"overview/ui-concepts/","title":"Admin Console Concepts","text":"<p>This guide introduces each major section of the Gateway Admin UI and how it connects to the Model Context Protocol (MCP).</p>"},{"location":"overview/ui-concepts/#setting-up-a-new-mcp-server-to-federate-to-the-gateway","title":"\ud83c\udd95 Setting up a new MCP Server to federate to the gateway","text":"\ud83d\udd0c How do I expose an MCP server over SSE? <p>To federate a new MCP Server to your gateway, it must run over Server-Sent Events (SSE) so the gateway can communicate with it.</p> <p>You can use <code>supergateway</code> to wrap any <code>stdio</code>-only MCP server and expose it over SSE. Here are example commands:</p> <pre><code>npx -y supergateway --stdio \"uvenv run mcp-server-git\" --port 8001\nnpx -y supergateway --stdio \"uvenv run mcp_server_time -- --local-timezone=Europe/Dublin\"\n</code></pre> <p>\u2705 Important: The gateway must be able to reach the MCP server's network address.</p> <p>If you're running services inside Docker (or other containerized environments), ensure networking is configured properly: - Use <code>host</code> networking when needed. - Expose ports to the host machine. - Make sure internal container IPs are reachable from the gateway.</p>"},{"location":"overview/ui-concepts/#virtual-servers","title":"\ud83d\udce6 Virtual Servers","text":"<p>A virtual server is a logical wrapper that combines selected tools, resources, and prompts under one context-specific endpoint.</p> \ud83d\udd17 What are Virtual Servers? <ul> <li>A Virtual Server defines a project-specific toolset.</li> <li>Each one is backed by a real SSE or STDIO interface.</li> <li>You can activate/deactivate, view metrics, and invoke tools from this server.</li> </ul>"},{"location":"overview/ui-concepts/#global-tools","title":"\ud83d\udee0 Global Tools","text":"<p>Tools are remote functions that an LLM can invoke, either via MCP or REST. Think of them like typed APIs with schemas and optional auth.</p> \u2699\ufe0f What do Tools represent? <ul> <li>Integration Types: <code>MCP</code>, <code>REST</code></li> <li>Request Types: <code>STDIO</code>, <code>SSE</code>, <code>GET</code>, <code>POST</code>, etc.</li> <li>Input Schema: JSON Schema defines valid input.</li> <li>Supports Basic Auth, Bearer, or Custom headers.</li> </ul>"},{"location":"overview/ui-concepts/#global-resources","title":"\ud83d\udcc1 Global Resources","text":"<p>Resources expose read-only data like files, database rows, logs, or screenshots. LLMs can read this content through a URI.</p> \ud83d\udcd6 How do Resources work? <ul> <li>Text and Binary data supported.</li> <li>Exposed via unique URI (<code>file:///</code>, <code>db://</code>, etc.).</li> <li>Resources can be listed, templated, or subscribed to.</li> </ul>"},{"location":"overview/ui-concepts/#global-prompts","title":"\ud83e\uddfe Global Prompts","text":"<p>Prompts are reusable message templates with arguments. They define system prompts, user instructions, or chainable inputs.</p> \ud83d\uddd2 What's in a Prompt? <ul> <li>Each prompt has a name, template, and arguments.</li> <li>Arguments are defined with name, description, and required status.</li> <li>Used to enforce consistency across tool use or system messaging.</li> </ul>"},{"location":"overview/ui-concepts/#gateways-mcp-servers","title":"\ud83c\udf10 Gateways (MCP Servers)","text":"<p>Gateways are other MCP-compatible servers. When registered, their tools/resources/prompts become usable locally.</p> \ud83c\udf09 What is a federated Gateway? <ul> <li>Syncs public tools from a remote MCP server.</li> <li>Peer tools show up in your catalog with <code>gateway_id</code>.</li> <li>Can be toggled active/inactive.</li> </ul>"},{"location":"overview/ui-concepts/#roots","title":"\ud83d\udcc2 Roots","text":"<p>Roots define base folders for file-based resources. They control what files MCP clients can access from your local system.</p> \ud83d\udcc1 What are Roots used for? <ul> <li>Restrict access to specific folders (<code>file:///workspace</code>)</li> <li>Prevent tools from referencing outside their sandbox.</li> <li>Deleting a root invalidates its associated resources.</li> </ul>"},{"location":"overview/ui-concepts/#metrics","title":"\ud83d\udcc8 Metrics","text":"<p>Track tool calls, resource reads, prompt renders, and overall usage in one place.</p> \ud83d\udcca What does the Metrics tab show? <ul> <li>Overall executions by server/tool/prompt.</li> <li>Latency, failure rate, and hot paths.</li> <li>Top tools, resources, prompts, and servers.</li> </ul>"},{"location":"overview/ui-concepts/#version-diagnostics","title":"\ud83e\uddea Version &amp; Diagnostics","text":"<p>The <code>/version</code> endpoint returns structured JSON diagnostics including system info, DB/Redis health, and Git SHA.</p> \ud83e\ude7a What does the Version panel include? <ul> <li>MCP protocol version and server metadata.</li> <li>Live system metrics (CPU, memory).</li> <li>Environment checks and service readiness.</li> </ul>"},{"location":"overview/ui-concepts/#learn-more","title":"\ud83d\udcda Learn More","text":"<ul> <li>\ud83d\udd17 MCP Specification</li> </ul>"},{"location":"overview/ui/","title":"Admin UI","text":"<p>MCP Gateway includes a built-in Admin UI for managing all entities in real time via a web browser.</p>"},{"location":"overview/ui/#accessing-the-ui","title":"\ud83d\udda5\ufe0f Accessing the UI","text":"<p>After launching the gateway (<code>make serve</code> or <code>make podman-run</code>), open your browser and go to:</p> <p>http://localhost:4444/admin - or the corresponding URL / port / protocol (ex: https when launching with <code>make podman-run-ssl</code>)</p> <p>Login using the <code>BASIC_AUTH_USER</code> and <code>BASIC_AUTH_PASSWORD</code> set in your <code>.env</code>.</p>"},{"location":"overview/ui/#ui-overview","title":"\ud83e\udded UI Overview","text":"<p>The Admin UI is built with HTMX, Alpine.js, and Tailwind CSS, offering a dynamic, SPA-like experience without JavaScript bloat.</p> <p>It provides tabbed access to:</p> <ul> <li>Servers Catalog: Define or edit MCP servers (real or virtual)</li> <li>Tools: Register REST or native tools, configure auth/rate limits, test responses</li> <li>Resources: Add templated or static resources, set MIME types, enable caching</li> <li>Prompts: Define Jinja2 prompt templates with argument schemas and preview rendering</li> <li>Gateways: View and manage federated peers, toggle activity status</li> <li>Roots: Register root URIs for agent or resource scoping</li> <li>Metrics: Real-time usage and performance metrics for all entities</li> </ul>"},{"location":"overview/ui/#common-actions","title":"\u270d\ufe0f Common Actions","text":"Action How Register a tool Use the Tools tab \u2192 Add Tool form View prompt output Go to Prompts \u2192 click View Toggle server activity Use the \"Activate/Deactivate\" buttons in Servers tab Delete a resource Navigate to Resources \u2192 click Delete (after confirming) <p>All actions are reflected in the live API via <code>/tools</code>, <code>/prompts</code>, etc.</p>"},{"location":"overview/ui/#auth-jwt-from-ui","title":"\ud83d\udd10 Auth + JWT from UI","text":"<p>Upon successful login, the UI automatically sets a secure JWT token as an HTTP-only cookie (<code>jwt_token</code>).</p> <p>This token is reused for all Admin API calls from within the UI.</p>"},{"location":"overview/ui/#live-reloading-dev-only","title":"\ud83d\udd04 Live Reloading (Dev Only)","text":"<p>If running in development mode (<code>DEV_MODE=true</code> or <code>make run</code>), changes to templates and routes reload automatically.</p>"},{"location":"testing/","title":"\ud83e\uddea Testing MCP Gateway","text":"<p>This section contains guides for testing your MCP Gateway deployment.</p>"},{"location":"testing/#basic-smoke-test","title":"\ud83d\udd39 Basic Smoke Test","text":"<p>Use the Basic Smoke Test to verify:</p> <ul> <li>JWT token generation and authentication</li> <li>Gateway registration</li> <li>Tool registration</li> <li>Server creation and event streaming</li> <li>Tool invocation via JSON-RPC</li> </ul> <p>This test is ideal for validating local development environments or freshly deployed test instances.</p> <p>For additional scenarios (e.g., completion APIs, multi-hop toolchains), expand the test suite as needed.</p>"},{"location":"testing/basic/","title":"MCP Gateway - Basic","text":"<p>Test script for MCP Gateway development environments. Verifies API readiness, JWT auth, Gateway/Tool/Server lifecycle, and RPC invocation.</p>"},{"location":"testing/basic/#environment-setup","title":"\ud83d\udd27 Environment Setup","text":""},{"location":"testing/basic/#0-bootstrap-env","title":"0. Bootstrap <code>.env</code>","text":"<pre><code>cp .env.example .env\n</code></pre>"},{"location":"testing/basic/#1-start-the-gateway","title":"1. Start the Gateway","text":"<pre><code>make podman podman-run-ssl\n# or\nmake venv install serve-ssl\n</code></pre> <p>Gateway will listen on:</p> <ul> <li>Admin UI \u2192 https://localhost:4444/admin</li> <li>Swagger   \u2192 https://localhost:4444/docs</li> <li>ReDoc     \u2192 https://localhost:4444/redoc</li> </ul>"},{"location":"testing/basic/#authentication","title":"\ud83d\udd11 Authentication","text":""},{"location":"testing/basic/#2-generate-and-export-tokens","title":"2. Generate and export tokens","text":""},{"location":"testing/basic/#gateway-jwt-for-local-api-access","title":"Gateway JWT (for local API access)","text":"<pre><code>export MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token -u admin)\ncurl -s -k -H \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\" https://localhost:4444/health\n</code></pre> <p>Expected: <code>{\"status\":\"ok\"}</code></p>"},{"location":"testing/basic/#remote-gateway-token-peer","title":"Remote gateway token (peer)","text":"<pre><code>export MY_MCP_TOKEN=\"sse-bearer-token-here...\"\n</code></pre>"},{"location":"testing/basic/#optional-local-test-server-token-github-mcp-server","title":"Optional: local test server token (GitHub MCP server)","text":"<pre><code>export LOCAL_MCP_URL=\"http://localhost:8000/sse\"\nexport LOCAL_MCP_TOOL_URL=\"http://localhost:9000/rpc\"\n</code></pre>"},{"location":"testing/basic/#3-set-convenience-variables","title":"3. Set convenience variables","text":"<pre><code>export BASE_URL=\"https://localhost:4444\"\nexport AUTH_HEADER=\"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\"\nexport JSON=\"Content-Type: application/json\"\n</code></pre>"},{"location":"testing/basic/#smoke-tests","title":"\ud83e\uddea Smoke Tests","text":""},{"location":"testing/basic/#4-ping-json-rpc-system","title":"4. Ping JSON-RPC system","text":"<pre><code>curl -s -k -X POST $BASE_URL/protocol/ping \\\n  -H \"$AUTH_HEADER\" -H \"$JSON\" \\\n  -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"ping\"}'\n</code></pre> <p>Expected:</p> <pre><code>{\"jsonrpc\":\"2.0\",\"id\":1,\"result\":{}}\n</code></pre>"},{"location":"testing/basic/#5-add-a-peer-gateway","title":"5. Add a Peer Gateway","text":"<pre><code>curl -s -k -X POST $BASE_URL/gateways \\\n  -H \"$AUTH_HEADER\" -H \"$JSON\" \\\n  -d '{\n        \"name\": \"my-mcp\",\n        \"url\": \"https://link-to-remote-mcp-server/sse\",\n        \"description\": \"My MCP Servers\",\n        \"auth_type\": \"bearer\",\n        \"auth_token\": \"'\"$MY_MCP_TOKEN\"'\"\n      }'\n</code></pre> <p>List gateways:</p> <pre><code>curl -s -k -H \"$AUTH_HEADER\" $BASE_URL/gateways\n</code></pre>"},{"location":"testing/basic/#6-add-a-tool","title":"6. Add a Tool","text":"<pre><code>curl -s -k -X POST $BASE_URL/tools \\\n  -H \"$AUTH_HEADER\" -H \"$JSON\" \\\n  -d '{\n        \"name\": \"clock_tool\",\n        \"url\": \"'\"$LOCAL_MCP_TOOL_URL\"'\",\n        \"description\": \"Returns current time\",\n        \"request_type\": \"POST\",\n        \"integration_type\": \"MCP\",\n        \"input_schema\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"timezone\": { \"type\": \"string\" }\n          }\n        }\n      }'\n</code></pre>"},{"location":"testing/basic/#7-create-a-virtual-server","title":"7. Create a Virtual Server","text":"<pre><code>curl -s -k -X POST $BASE_URL/servers/ \\\n  -H \"$AUTH_HEADER\" -H \"$JSON\" -H 'accept: application/json' \\\n  -d '{\n        \"name\": \"demo-server\",\n        \"description\": \"Smoke-test virtual server\",\n        \"icon\": \"https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png\",\n        \"associatedTools\": [\"1\"],\n        \"associatedResources\": [],\n        \"associatedPrompts\": []\n      }'\n</code></pre> <p>Expected:</p> <pre><code>{\n  \"id\": 2,\n  \"name\": \"demo-server\",\n  \"description\": \"Smoke-test virtual server\",\n  \"icon\": \"https://github.githubassets.com/assets/GitHub-Mark-ea2971cee799.png\",\n  \"createdAt\": \"2025-05-28T04:28:38.554558\",\n  \"updatedAt\": \"2025-05-28T04:28:38.554564\",\n  \"isActive\": true,\n  \"associatedTools\": [\n    1\n  ],\n  \"associatedResources\": [],\n  \"associatedPrompts\": [],\n  \"metrics\": {\n    \"totalExecutions\": 0,\n    \"successfulExecutions\": 0,\n    \"failedExecutions\": 0,\n    \"failureRate\": 0,\n    \"minResponseTime\": null,\n    \"maxResponseTime\": null,\n    \"avgResponseTime\": null,\n    \"lastExecutionTime\": null\n  }\n}\n</code></pre> <p>Check:</p> <pre><code>curl -s -k -H \"$AUTH_HEADER\" $BASE_URL/servers | jq\n</code></pre>"},{"location":"testing/basic/#8-open-an-sse-stream","title":"8. Open an SSE stream","text":"<pre><code>curl -s -k -N -H \"$AUTH_HEADER\" $BASE_URL/servers/1/sse\n</code></pre> <p>Leave running - real-time events appear here.</p>"},{"location":"testing/basic/#9-invoke-the-tool-via-rpc","title":"9. Invoke the Tool via RPC","text":"<pre><code>curl -s -k -X POST $BASE_URL/rpc \\\n  -H \"$AUTH_HEADER\" -H \"$JSON\" \\\n  -d '{\n        \"jsonrpc\": \"2.0\",\n        \"id\": 99,\n        \"method\": \"get_current_time\",\n        \"params\": {\n          \"timezone\": \"Europe/Dublin\"\n        }\n      }'\n</code></pre> <p>Expected:</p> <pre><code>{\n  \"content\": [\n    {\n      \"type\": \"text\",\n      \"text\": \"{\\n  \\\"timezone\\\": \\\"Europe/Dublin\\\",\\n  \\\"datetime\\\": \\\"2025-05-28T05:24:13+01:00\\\",\\n  \\\"is_dst\\\": true\\n}\"\n    }\n  ],\n  \"is_error\": false\n}\n</code></pre>"},{"location":"testing/basic/#10-connect-to-github-mcp-tools-via-supergateway","title":"10. Connect to GitHub MCP Tools via SuperGateway","text":"<p>You can test the Gateway against GitHub's official <code>mcp-server-git</code> tool using <code>supergateway</code>.</p> <p>Start a temporary SSE wrapper around the GitHub MCP server:</p> <pre><code>npx -y supergateway --stdio \"uvx run mcp-server-git\"\n</code></pre> <p>This starts:</p> <ul> <li>SSE endpoint: <code>http://localhost:8000/sse</code></li> <li>Message POST: <code>http://localhost:8000/message</code></li> </ul> <p>To register it with the MCP Gateway:</p> <pre><code>export MY_MCP_TOKEN=\"optional-auth-header-if-needed\"\n\ncurl -s -k -X POST $BASE_URL/gateways \\\n  -H \"$AUTH_HEADER\" -H \"$JSON\" \\\n  -d '{\n        \"name\": \"github-mcp\",\n        \"url\": \"http://localhost:8000/sse\",\n        \"description\": \"GitHub MCP Tools via SuperGateway\",\n        \"auth_type\": \"none\"\n      }'\n</code></pre> <p>This gives you access to GitHub's MCP tools like <code>get_repo_issues</code>, <code>get_pull_requests</code>, etc.</p>"},{"location":"testing/basic/#11-development-testing-with-mcp-inspector","title":"11. Development Testing with MCP Inspector","text":"<p>Launch a visual inspector to interactively test your Gateway:</p> <pre><code>npx @modelcontextprotocol/inspector\n</code></pre> <p>Once launched at http://localhost:5173:</p> <ol> <li>Click \"Add Server\"</li> <li>Use the URL for your virtual server's SSE stream:</li> </ol> <pre><code>http://localhost:4444/servers/1/sse\n</code></pre> <ol> <li>Add this header:</li> </ol> <pre><code>{\n  \"Authorization\": \"Bearer &lt;your-jwt-token&gt;\"\n}\n</code></pre> <ol> <li>Save and test tool invocations by selecting a tool and sending sample input:</li> </ol> <pre><code>{ \"timezone\": \"Europe/Dublin\" }\n</code></pre>"},{"location":"testing/basic/#cleanup","title":"\ud83e\uddf9 Cleanup","text":"<pre><code>curl -s -k -X DELETE -H \"$AUTH_HEADER\" $BASE_URL/servers/1\ncurl -s -k -X DELETE -H \"$AUTH_HEADER\" $BASE_URL/tools/1\ncurl -s -k -X DELETE -H \"$AUTH_HEADER\" $BASE_URL/gateways/1\n</code></pre>"},{"location":"testing/basic/#summary","title":"\u2705 Summary","text":"<p>This smoke test validates:</p> <ul> <li>\u2705 Gateway JWT auth</li> <li>\u2705 Peer Gateway registration with remote bearer</li> <li>\u2705 Tool registration and RPC wiring</li> <li>\u2705 Virtual server creation</li> <li>\u2705 SSE subscription and live messaging</li> <li>\u2705 JSON-RPC invocation flow</li> <li>\u2705 Connecting MCP Inspector to the MCP Gateway</li> <li>\u2705 Connecting the official GitHub MCP server to the Gateway</li> </ul>"},{"location":"testing/performance/","title":"Performance Testing","text":"<p>Use this guide to benchmark MCP Gateway under load, validate performance improvements, and identify bottlenecks before production deployment.</p>"},{"location":"testing/performance/#tooling-hey","title":"\u2699\ufe0f Tooling: <code>hey</code>","text":"<p><code>hey</code> is a CLI-based HTTP load generator. Install it with:</p> <pre><code>brew install hey            # macOS\nsudo apt install hey        # Debian/Ubuntu\ngo install github.com/rakyll/hey@latest  # From source\n</code></pre>"},{"location":"testing/performance/#establishing-a-baseline","title":"\ud83c\udfaf Establishing a Baseline","text":"<p>Before benchmarking the full MCP Gateway stack, run tests against the MCP server directly (if applicable) to establish baseline latency and throughput. This helps isolate issues related to gateway overhead, authentication, or network I/O.</p> <p>If your backend service exposes a direct HTTP interface or gRPC gateway, target it with <code>hey</code> using the same payload and concurrency settings.</p> <pre><code>hey -n 5000 -c 100 \\\n  -m POST \\\n  -T application/json \\\n  -D tests/hey/payload.json \\\n  http://localhost:5000/your-backend-endpoint\n</code></pre> <p>Compare the 95/99<sup>th</sup> percentile latencies and error rates with and without the gateway in front. Any significant increase can guide you toward:</p> <ul> <li>Bottlenecks in auth middleware</li> <li>Overhead from JSON-RPC wrapping/unwrapping</li> <li>Improper worker/thread config in Gunicorn</li> </ul>"},{"location":"testing/performance/#scripted-load-tests-testsheyheysh","title":"\ud83d\ude80 Scripted Load Tests: <code>tests/hey/hey.sh</code>","text":"<p>A wrapper script exists at:</p> <pre><code>tests/hey/hey.sh\n</code></pre> <p>This script provides:</p> <ul> <li>Strict error handling (<code>set -euo pipefail</code>)</li> <li>Helpful CLI interface (<code>-n</code>, <code>-c</code>, <code>-d</code>, etc.)</li> <li>Required dependency checks</li> <li>Optional dry-run mode</li> <li>Timestamped logging</li> </ul> <p>Example usage:</p> <pre><code>./hey.sh -n 10000 -c 200 \\\n  -X POST \\\n  -T application/json \\\n  -H \"Authorization: Bearer $JWT\" \\\n  -d payload.json \\\n  -u http://localhost:4444/rpc\n</code></pre> <p>The <code>payload.json</code> file is expected to be a valid JSON-RPC request payload.</p> <p>Sample payload (<code>tests/hey/payload.json</code>):</p> <pre><code>{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"method\": \"convert_time\",\n  \"params\": {\n    \"source_timezone\": \"Europe/Berlin\",\n    \"target_timezone\": \"Europe/Dublin\",\n    \"time\": \"09:00\"\n  }\n}\n</code></pre> <p>Logs are saved automatically (e.g. <code>hey-20250610_120000.log</code>).</p>"},{"location":"testing/performance/#interpreting-results","title":"\ud83d\udcca Interpreting Results","text":"<p>When the test completes, look at:</p> Metric Interpretation Requests/sec (RPS) Raw throughput capability 95/99<sup>th</sup> percentile Tail latency \u2014 tune <code>timeout</code>, workers, or DB pooling Non-2xx responses Failures under load \u2014 common with CPU/memory starvation"},{"location":"testing/performance/#tips-best-practices","title":"\ud83e\uddea Tips &amp; Best Practices","text":"<ul> <li>Always test against a realistic endpoint (e.g. <code>POST /rpc</code> with auth and payload).</li> <li>Use the same JWT and payload structure your clients would.</li> <li>Run from a dedicated machine to avoid local CPU skewing results.</li> <li>Use <code>make run</code> or <code>make serve</code> to launch the app for local testing.</li> </ul> <p>For runtime tuning details, see Gateway Tuning Guide.</p>"},{"location":"using/","title":"Using MCP Gateway","text":"<p>This section focuses on how to use MCP Gateway effectively as a developer, integrator, or end user.</p>"},{"location":"using/#typical-use-cases","title":"\ud83d\udc68\u200d\ud83d\udcbb Typical Use Cases","text":"<ul> <li>You want to expose tools, prompts, or resources via MCP.</li> <li>You want to use <code>mcpgateway-wrapper</code> to connect to any MCP Gateway service using <code>stdio</code>, while still supporting authentication to the gateway.</li> <li>You're building a client or agent framework that speaks the MCP protocol.</li> <li>You want to consume Gateway APIs from an LLM agent, browser app, or CLI tool.</li> </ul>"},{"location":"using/#what-youll-find-in-this-section","title":"\ud83d\udcda What You'll Find in This Section","text":"Page Description mcpgateway-wrapper Wrap CLI tools or subprocesses to expose them via SSE/stdio Clients Compatible UIs and developer tools Agents LangChain, LangGraph, CrewAI, and other frameworks"},{"location":"using/#authentication-reminder","title":"\ud83d\udd11 Authentication Reminder","text":"<p>All Gateway usage requires authentication unless <code>AUTH_REQUIRED=false</code>. Refer to:</p> <pre><code>curl -H \"Authorization: Bearer $TOKEN\" http://localhost:4444/tools\n</code></pre> <p>Or use Basic Auth for the Admin UI and <code>/admin</code> routes.</p>"},{"location":"using/mcpgateway-wrapper/","title":"\ud83d\udee0 STDIO Wrapper (<code>mcpgateway.wrapper</code>)","text":"<p><code>mcpgateway.wrapper</code> ships inside the main PyPI package and re-publishes your Gateway's tools / prompts / resources over <code>stdin \u2194 stdout</code>, while connecting securely to the gateway using <code>SSE</code> + <code>JWT</code>.</p> <p>Perfect for clients that can't open SSE streams or attach JWT headers (e.g. Claude Desktop, Cline, Continue, custom CLI scripts).</p>"},{"location":"using/mcpgateway-wrapper/#key-highlights","title":"\ud83d\udd11 Key Highlights","text":"<ul> <li>Dynamic catalog \u2013 auto-syncs from one or more <code>\u2026/servers/{id}</code> Virtual Server endpoints</li> <li>Full MCP protocol \u2013 <code>initialize</code>, <code>ping</code>, <code>tools/call</code>, streaming content, resources and prompts/template rendering</li> <li>Transparent proxy \u2013 stdio \u2192 Gateway \u2192 tool, results stream back to stdout</li> <li>Secure \u2013 wrapper keeps using your JWT to talk to the Gateway</li> </ul>"},{"location":"using/mcpgateway-wrapper/#launch-options","title":"\ud83d\ude80 Launch Options","text":"<p>Ensure you have a valid JWT tokens:</p> <pre><code>export MCP_BEARER_TOKEN=$(python -m mcpgateway.utils.create_jwt_token \\\n      --username admin --exp 10080 --secret my-test-key)\n</code></pre> <p>Configure the wrapper via ENV variables:</p> <pre><code>export MCP_AUTH_TOKEN=${MCPGATEWAY_BEARER_TOKEN}\nexport MCP_SERVER_CATALOG_URLS='http://localhost:4444/servers/1'  # select a virtual server\nexport MCP_TOOL_CALL_TIMEOUT=120          # tool call timeout in seconds (optional \u2013 default 90)\nexport MCP_WRAPPER_LOG_LEVEL=INFO         # DEBUG | INFO | OFF\n</code></pre> <p>Configure via Pip or Docker. Note that lauching the wrapper should be done from an MCP Client (ex: via the JSON configuration).</p> <p>Launching it in your terminal (ex: <code>python -m mcpgateway.wrapper</code>) is useful for testing.</p> Local shell (venv)Docker / Podmanpipx (one-liner)uv / uvenv (ultra-fast) <pre><code>pip install mcp-contextforge-gateway\npython -m mcpgateway.wrapper\n</code></pre> <pre><code>docker run -i --rm --network=host \\\n  -e MCP_SERVER_CATALOG_URLS=$MCP_SERVER_CATALOG_URLS \\\n  -e MCP_AUTH_TOKEN=$MCP_AUTH_TOKEN \\\n  ghcr.io/ibm/mcp-context-forge:latest \\\n  python -m mcpgateway.wrapper\n</code></pre> <pre><code>pipx install --include-deps mcp-contextforge-gateway\nMCP_AUTH_TOKEN=$MCP_AUTH_TOKEN \\\nMCP_SERVER_CATALOG_URLS=$MCP_SERVER_CATALOG_URLS \\\npython -m mcpgateway.wrapper\n</code></pre> <pre><code>curl -Ls https://astral.sh/uv/install.sh | sh\nuv venv ~/.venv/mcpgw &amp;&amp; source ~/.venv/mcpgw/bin/activate\nuv pip install mcp-contextforge-gateway\nuv python -m mcpgateway.wrapper\n</code></pre> <p>The wrapper now waits for JSON-RPC on stdin and emits replies on stdout.</p>"},{"location":"using/mcpgateway-wrapper/#environment-variables","title":"\u2705 Environment Variables","text":"Variable Purpose Default <code>MCP_SERVER_CATALOG_URLS</code> Comma-sep list of <code>/servers/{id}</code> endpoints \u2014 <code>MCP_AUTH_TOKEN</code> Bearer token the wrapper forwards to Gateway \u2014 <code>MCP_TOOL_CALL_TIMEOUT</code> Per-tool timeout (seconds) <code>90</code> <code>MCP_WRAPPER_LOG_LEVEL</code> <code>OFF</code>, <code>INFO</code>, <code>DEBUG</code>, \u2026 <code>INFO</code>"},{"location":"using/mcpgateway-wrapper/#gui-client-config-json-snippets","title":"\ud83d\udda5 GUI Client Config JSON Snippets","text":"<p>You can run <code>mcpgateway.wrapper</code> from any MCP client, using either <code>python3</code>, <code>uv</code>, <code>uvenv</code>, <code>uvx</code>, <code>pipx</code>, <code>docker</code>, or <code>podman</code> entrypoints.</p> <p>The MCP Client calls the entrypoint, which needs to have the <code>mcp-contextforge-gateway</code> module installed, able to call <code>mcpgateway.wrapper</code> and the right <code>env</code> settings exported (<code>MCP_SERVER_CATALOG_URLS</code> and <code>MCP_AUTH_TOKEN</code> at a minimum).</p> Claude Desktop (venv)Claude Desktop (uvenv)Continue (python3)Cline (uv) <pre><code>{\n  \"mcpServers\": {\n    \"mcpgateway-wrapper\": {\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"mcpgateway.wrapper\"],\n      \"env\": {\n        \"MCP_AUTH_TOKEN\": \"&lt;paste-token&gt;\",\n        \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/1\"\n      }\n    }\n  }\n}\n</code></pre> <p>Use your venv's Python</p> <p>Replace <code>/path/to/python</code> with the exact interpreter in your venv (e.g. <code>$HOME/.venv/mcpgateway/bin/python3</code>) - where the <code>mcp-contextforge-gateway</code> module is installed.</p> <pre><code>{\n  \"mcpServers\": {\n    \"mcpgateway-wrapper\": {\n      \"command\": \"uvenv\",\n      \"args\": [\n        \"run\",\n        \"--\",\n        \"python\",\n        \"-m\",\n        \"mcpgateway.wrapper\"\n      ],\n      \"env\": {\n        \"MCP_AUTH_TOKEN\": \"&lt;paste-token&gt;\",\n        \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/1\"\n      }\n    }\n  }\n}\n</code></pre> <p>Add to Settings \u2192 Continue: MCP Servers:</p> <pre><code>{\n  \"mcpgateway-wrapper\": {\n    \"command\": \"/path/to/python\",\n    \"args\": [\"-m\", \"mcpgateway.wrapper\"],\n    \"env\": {\n      \"MCP_AUTH_TOKEN\": \"&lt;token&gt;\",\n      \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/1\"\n    }\n  }\n}\n</code></pre> <p>(Replace <code>/path/to/python</code> with your venv interpreter.)</p> <pre><code>{\n  \"mcpServers\": {\n    \"mcpgateway-wrapper\": {\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"type\": \"stdio\",\n      \"command\": \"uv\",\n      \"args\": [\n        \"run\",\n        \"--directory\",\n        \"REPLACE_WITH_PATH_TO_REPO\",\n        \"-m\",\n        \"mcpgateway.wrapper\"\n      ],\n      \"env\": {\n        \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/1\",\n        \"MCP_AUTH_TOKEN\": \"REPLACE_WITH_MCPGATEWAY_BEARER_TOKEN\",\n        \"MCP_WRAPPER_LOG_LEVEL\": \"OFF\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"using/mcpgateway-wrapper/#local-development","title":"\ud83d\udc0d Local Development","text":"<pre><code># Hot-reload wrapper code while hacking\nuv --dev run python -m mcpgateway.wrapper\n</code></pre>"},{"location":"using/mcpgateway-wrapper/#mcp-inspector","title":"\ud83d\udd0e MCP Inspector","text":"<pre><code>npx @modelcontextprotocol/inspector \\\n     python -m mcpgateway.wrapper -- \\\n     --log-level DEBUG\n</code></pre>"},{"location":"using/mcpgateway-wrapper/#example-call-flow","title":"\ud83d\udcdd Example call flow","text":"<pre><code>{\n  \"method\": \"get_current_time\",\n  \"params\": { \"timezone\": \"Europe/Dublin\" }\n}\n</code></pre> <ol> <li>Wrapper maps <code>get_current_time</code> \u2192 tool ID 123 in the catalog.</li> <li>Sends RPC to the Gateway with your JWT token.</li> <li>Gateway executes the tool and returns JSON \u2192 wrapper \u2192 stdout.</li> </ol>"},{"location":"using/mcpgateway-wrapper/#manual-json-rpc-smoke-test","title":"\ud83e\uddea Manual JSON-RPC Smoke-test","text":"<p>The wrapper speaks plain JSON-RPC over stdin/stdout, so you can exercise it from any terminal\u2014no GUI required. Open two shells or use a tool like <code>jq -c | nc -U</code> to pipe messages in and view replies.</p> Step-by-step request sequence <pre><code># 1\ufe0f\u20e3 Initialize session\n{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"initialize\",\"params\":{\"protocolVersion\":\"2025-03-26\",\"capabilities\":{},\n  \"clientInfo\":{\"name\":\"demo\",\"version\":\"0.0.1\"}\n}}\n\n# 2\ufe0f\u20e3 Ack initialisation (required by MCP)\n{\"jsonrpc\":\"2.0\",\"method\":\"notifications/initialized\",\"params\":{}}\n\n# 3\ufe0f\u20e3 Prompts\n{\"jsonrpc\":\"2.0\",\"id\":4,\"method\":\"prompts/list\"}\n{\"jsonrpc\":\"2.0\",\"id\":5,\"method\":\"prompts/get\",\n \"params\":{\"name\":\"greeting\",\"arguments\":{\"user\":\"Bob\"}}}\n\n# 4\ufe0f\u20e3 Resources\n{\"jsonrpc\":\"2.0\",\"id\":6,\"method\":\"resources/list\"}\n{\"jsonrpc\":\"2.0\",\"id\":7,\"method\":\"resources/read\",\n \"params\":{\"uri\":\"https://example.com/some.txt\"}}\n\n# 5\ufe0f\u20e3 Tools (list / call)\n{\"jsonrpc\":\"2.0\",\"id\":2,\"method\":\"tools/list\"}\n{\"jsonrpc\":\"2.0\",\"id\":3,\"method\":\"tools/call\",\n \"params\":{\"name\":\"get_current_time\",\"arguments\":{\"timezone\":\"Europe/Dublin\"}}}\n</code></pre> Sample responses you should see <pre><code># Initialise\n{\"jsonrpc\":\"2.0\",\"id\":1,\"result\":{\n  \"protocolVersion\":\"2025-03-26\",\n  \"capabilities\":{\n    \"experimental\":{},\n    \"prompts\":{\"listChanged\":false},\n    \"resources\":{\"subscribe\":false,\"listChanged\":false},\n    \"tools\":{\"listChanged\":false}\n  },\n  \"serverInfo\":{\"name\":\"mcpgateway-wrapper\",\"version\":\"0.1.1\"}\n}}\n\n# Empty tool list\n{\"jsonrpc\":\"2.0\",\"id\":2,\"result\":{\"tools\":[]}}\n\n# \u2026after adding tools (example)\n{\"jsonrpc\":\"2.0\",\"id\":2,\"result\":{\n  \"tools\":[\n    {\n      \"name\":\"get_current_time\",\n      \"description\":\"Get current time in a specific timezone\",\n      \"inputSchema\":{\n        \"type\":\"object\",\n        \"properties\":{\n          \"timezone\":{\n            \"type\":\"string\",\n            \"description\":\"IANA timezone name (e.g. 'Europe/London').\"\n          }\n        },\n        \"required\":[\"timezone\"]\n      }\n    }\n  ]\n}}\n\n# Tool invocation\n{\"jsonrpc\":\"2.0\",\"id\":3,\"result\":{\n  \"content\":[\n    {\n      \"type\":\"text\",\n      \"text\":\"{ \\\"timezone\\\": \\\"Europe/Dublin\\\", \\\"datetime\\\": \\\"2025-06-08T21:47:07+01:00\\\", \\\"is_dst\\\": true }\"\n    }\n  ],\n  \"isError\":false\n}}\n</code></pre>"},{"location":"using/agents/","title":"Agent Integrations","text":"<p>This section provides guidance on integrating various AI agent frameworks with the Model Context Protocol (MCP) Gateway. MCP enables agents to dynamically discover and utilize tools across multiple servers, enhancing their capabilities and flexibility.</p>"},{"location":"using/agents/#supported-agent-frameworks","title":"\ud83e\udde0 Supported Agent Frameworks","text":"<ul> <li>LangChain: Utilize MCP tools within LangChain agents using the <code>langchain-mcp-adapters</code> package.</li> <li>LangGraph: Integrate MCP tools into LangGraph agents for advanced workflow orchestration.</li> <li>CrewAI: Connect CrewAI agents to MCP servers using the <code>crewai-tools</code> library.</li> <li>Bee Agent Framework: Leverage MCP tools within the Bee Agent Framework for scalable agent deployments.</li> <li>AutoGen: Integrate MCP tools with AutoGen agents using the <code>autogen-ext-mcp</code> package.</li> <li>LlamaIndex: Incorporate MCP tools into LlamaIndex workflows for enhanced data retrieval and question answering.</li> <li>OpenAI Agents SDK: Utilize MCP tools within OpenAI's Agents SDK for building AI agents with standardized tool access.</li> <li>Semantic Kernel: Connect Semantic Kernel agents to MCP servers for enriched context and tool integration.</li> </ul>"},{"location":"using/agents/#overview","title":"\ud83d\udd0d Overview","text":"<p>Each integration guide includes:</p> <ul> <li>Installation Instructions: Step-by-step setup for the respective agent framework.</li> <li>Configuration Details: How to connect the agent to the MCP Gateway, including authentication and transport options.</li> <li>Usage Examples: Sample code demonstrating how to invoke MCP tools within the agent's workflow.</li> <li>Additional Resources: Links to official documentation and repositories for further reference.</li> </ul>"},{"location":"using/agents/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>Model Context Protocol Overview</li> <li>MCP Gateway Documentation</li> </ul>"},{"location":"using/agents/autogen/","title":"AutoGen Integration with MCP Gateway","text":"<p>AutoGen is an open-source framework from Microsoft for building multi-agent systems. It supports tool calling and dynamic agent coordination.</p>"},{"location":"using/agents/autogen/#mcp-support","title":"\ud83d\udd27 MCP Support","text":"<p>Experimental support for MCP integration is available via custom <code>ToolAgent</code> wrappers that call MCP tools via HTTP or <code>mcpgateway-wrapper</code>.</p> <p>A full guide is coming soon. For now, you can use <code>requests</code> or <code>httpx</code> to call MCP Gateway endpoints from AutoGen agents.</p>"},{"location":"using/agents/autogen/#resources","title":"\ud83d\udd17 Resources","text":"<ul> <li>AutoGen GitHub</li> <li>AutoGen Docs</li> </ul>"},{"location":"using/agents/bee/","title":"Bee Agent Framework Integration with MCP Gateway","text":"<p>The Bee Agent Framework is an open-source platform developed by IBM for building, deploying, and managing AI agents at scale. Integrating Bee with the Model Context Protocol (MCP) allows agents to dynamically discover and utilize tools hosted on MCP servers, enhancing their capabilities and flexibility.</p>"},{"location":"using/agents/bee/#key-features","title":"\ud83e\uddf0 Key Features","text":"<ul> <li>Dynamic Tool Discovery: Agents can fetch available tools from MCP servers in real-time.</li> <li>Standardized Communication: Utilizes the open MCP standard for consistent tool integration.</li> <li>Multi-Server Support: Interact with tools defined on multiple MCP servers simultaneously.</li> <li>Human-in-the-Loop: Incorporate human feedback into agent workflows for improved decision-making.</li> </ul>"},{"location":"using/agents/bee/#installation","title":"\ud83d\udee0 Installation","text":"<p>To use MCP tools in the Bee Agent Framework, follow these steps:</p> <ol> <li>Clone the Bee Agent Framework Repository:</li> </ol> <p><code>bash    git clone https://github.com/i-am-bee/bee-agent-framework.git    cd bee-agent-framework</code></p> <ol> <li>Install Dependencies:</li> </ol> <pre><code>yarn install\n</code></pre> <ol> <li>Set Up the Environment:</li> </ol> <p>Ensure you have Node.js and Yarn installed. You may also need to set environment variables for your MCP server:</p> <pre><code>export MCP_GATEWAY_BASE_URL=http://localhost:4444\nexport MCP_AUTH_TOKEN=\"your_bearer_token\"\n</code></pre>"},{"location":"using/agents/bee/#connecting-to-mcp-gateway","title":"\ud83d\udd17 Connecting to MCP Gateway","text":"<p>Bee provides a native <code>MCPTool</code> class to simplify integration with MCP servers. Here's how to set it up:</p> <ol> <li>Import the MCPTool Class:</li> </ol> <pre><code>import { MCPTool } from 'bee-agent-framework/tools/mcp';\n</code></pre> <ol> <li>Configure the MCPTool:</li> </ol> <pre><code>const mcpTool = new MCPTool({\n  baseUrl: process.env.MCP_GATEWAY_BASE_URL,\n  auth: {\n    username: process.env.MCP_AUTH_USER,\n    password: process.env.MCP_AUTH_PASS,\n  },\n});\n</code></pre> <ol> <li>Register the Tool with Your Agent:</li> </ol> <pre><code>agent.registerTool(mcpTool);\n</code></pre> <p>This setup allows your Bee agent to discover and invoke tools from the specified MCP server dynamically.</p>"},{"location":"using/agents/bee/#creating-an-agent","title":"\ud83e\udd16 Creating an Agent","text":"<p>After setting up the MCPTool, you can create a Bee agent:</p> <pre><code>import { Agent } from 'bee-agent-framework';\n\nconst agent = new Agent({\n  name: 'Data Analyst',\n  tools: [mcpTool],\n});\n</code></pre>"},{"location":"using/agents/bee/#using-the-agent","title":"\ud83e\uddea Using the Agent","text":"<p>Once the agent is created, you can assign tasks and execute them:</p> <pre><code>agent.runTask('Generate a sales report for Q1 2025');\n</code></pre> <p>The agent will utilize tools from the MCP server to accomplish the task.</p>"},{"location":"using/agents/bee/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>Bee Agent Framework Documentation</li> <li>Bee Agent Framework GitHub Repository</li> <li>Model Context Protocol Overview</li> </ul>"},{"location":"using/agents/crewai/","title":"CrewAI Integration with MCP Gateway","text":"<p>CrewAI is a multi-agent orchestration framework that enables AI agents to collaborate on complex tasks. Integrating CrewAI with the Model Context Protocol (MCP) allows agents to dynamically discover and utilize tools hosted on MCP servers, enhancing their capabilities and flexibility.</p>"},{"location":"using/agents/crewai/#key-features","title":"\ud83e\uddf0 Key Features","text":"<ul> <li>Dynamic Tool Discovery: Agents can fetch available tools from MCP servers in real-time.</li> <li>Standardized Communication: Utilizes the open MCP standard for consistent tool integration.</li> <li>Multi-Server Support: Interact with tools defined on multiple MCP servers simultaneously.</li> </ul>"},{"location":"using/agents/crewai/#installation","title":"\ud83d\udee0 Installation","text":"<p>To use MCP tools in CrewAI, install the <code>crewai-tools</code> package with MCP support:</p> <p>```bash pip install \"crewai-tools[mcp]\"</p>"},{"location":"using/agents/langchain/","title":"LangChain Integration with MCP Gateway","text":"<p>LangChain is a framework for developing applications powered by language models. Integrating LangChain with the Model Context Protocol (MCP) allows agents to utilize tools defined across one or more MCP servers, enabling seamless interaction with external data sources and services.</p>"},{"location":"using/agents/langchain/#key-features","title":"\ud83e\uddf0 Key Features","text":"<ul> <li>Dynamic Tool Access: Connects to MCP servers to fetch available tools in real time.</li> <li>Multi-Server Support: Interact with tools defined on multiple MCP servers simultaneously.</li> <li>Standardized Communication: Utilizes the open MCP standard for consistent tool integration.</li> </ul>"},{"location":"using/agents/langchain/#installation","title":"\ud83d\udee0 Installation","text":"<p>To use MCP tools in LangChain, install the <code>langchain-mcp-adapters</code> package:</p> <pre><code>pip install langchain-mcp-adapters\n</code></pre>"},{"location":"using/agents/langchain/#connecting-to-mcp-gateway","title":"\ud83d\udd17 Connecting to MCP Gateway","text":"<p>Here's how to set up a connection to your MCP Gateway:</p> <pre><code>from langchain_mcp_adapters.client import MultiServerMCPClient\nfrom langgraph.prebuilt import create_react_agent\n\nclient = MultiServerMCPClient(\n    {\n        \"gateway\": {\n            \"url\": \"http://localhost:4444/mcp\",\n            \"transport\": \"streamable_http\",\n        }\n    }\n)\n</code></pre> <p>Replace <code>\"http://localhost:4444/mcp\"</code> with the URL of your MCP Gateway.</p>"},{"location":"using/agents/langchain/#creating-an-agent","title":"\ud83e\udd16 Creating an Agent","text":"<p>After setting up the client, you can create a LangChain agent:</p> <pre><code>agent = create_react_agent(\n    tools=client.get_tools(),\n    llm=your_language_model,\n)\n</code></pre> <p>Replace <code>your_language_model</code> with your configured language model instance.</p>"},{"location":"using/agents/langchain/#using-the-agent","title":"\ud83e\uddea Using the Agent","text":"<p>Once the agent is created, you can use it to perform tasks:</p> <pre><code>response = agent.run(\"Use the 'weather' tool to get the forecast for Dublin.\")\nprint(response)\n</code></pre>"},{"location":"using/agents/langchain/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>LangChain MCP Adapters Documentation</li> <li>LangChain GitHub Repository</li> <li>Model Context Protocol Overview</li> </ul>"},{"location":"using/agents/langgraph/","title":"LangGraph Integration with MCP Gateway","text":"<p>LangGraph is a framework for developing applications powered by language models. Integrating LangGraph with the Model Context Protocol (MCP) allows agents to utilize tools defined across one or more MCP servers, enabling seamless interaction with external data sources and services.</p>"},{"location":"using/agents/langgraph/#key-features","title":"\ud83e\uddf0 Key Features","text":"<ul> <li>Dynamic Tool Access: Connects to MCP servers to fetch available tools in real time.</li> <li>Multi-Server Support: Interact with tools defined on multiple MCP servers simultaneously.</li> <li>Standardized Communication: Utilizes the open MCP standard for consistent tool integration.</li> </ul>"},{"location":"using/agents/langgraph/#installation","title":"\ud83d\udee0 Installation","text":"<p>To use MCP tools in LangGraph, install the <code>langchain-mcp-adapters</code> package:</p> <pre><code>pip install langchain-mcp-adapters\n</code></pre>"},{"location":"using/agents/langgraph/#connecting-to-mcp-gateway","title":"\ud83d\udd17 Connecting to MCP Gateway","text":"<p>Here's how to set up a connection to your MCP Gateway:</p> <pre><code>from langchain_mcp_adapters.client import MultiServerMCPClient\nfrom langgraph.prebuilt import create_react_agent\n\nclient = MultiServerMCPClient(\n    {\n        \"gateway\": {\n            \"url\": \"http://localhost:4444/mcp\",\n            \"transport\": \"streamable_http\",\n        }\n    }\n)\n</code></pre> <p>Replace <code>\"http://localhost:4444/mcp\"</code> with the URL of your MCP Gateway.</p>"},{"location":"using/agents/langgraph/#creating-an-agent","title":"\ud83e\udd16 Creating an Agent","text":"<p>After setting up the client, you can create a LangGraph agent:</p> <pre><code>agent = create_react_agent(\n    tools=client.get_tools(),\n    llm=your_language_model,\n)\n</code></pre> <p>Replace <code>your_language_model</code> with your configured language model instance.</p>"},{"location":"using/agents/langgraph/#using-the-agent","title":"\ud83e\uddea Using the Agent","text":"<p>Once the agent is created, you can use it to perform tasks:</p> <pre><code>response = agent.run(\"Use the 'weather' tool to get the forecast for Dublin.\")\nprint(response)\n</code></pre>"},{"location":"using/agents/langgraph/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>LangGraph MCP Integration Documentation</li> <li>LangChain MCP Adapters GitHub Repository</li> <li>Model Context Protocol Overview</li> </ul>"},{"location":"using/agents/llamaindex/","title":"LlamaIndex Integration with MCP Gateway","text":"<p>LlamaIndex is a framework for building retrieval-augmented generation (RAG) pipelines.</p>"},{"location":"using/agents/llamaindex/#mcp-support","title":"\ud83d\udd27 MCP Support","text":"<p>You can wrap tool calls from MCP Gateway as query engines, retrievers, or tool nodes inside LlamaIndex.</p> <p>A dedicated <code>ToolRetriever</code> adapter is under development to support direct MCP tool discovery.</p>"},{"location":"using/agents/openai-sdk/","title":"OpenAI Agents SDK + MCP Gateway","text":"<p>OpenAI's Agents SDK supports structured tool use and multi-modal workflows. MCP Gateway can serve as a unified tool registry for OpenAI agents.</p>"},{"location":"using/agents/openai-sdk/#integration","title":"\ud83d\udd27 Integration","text":"<p>OpenAI SDK has native support for MCP.</p>"},{"location":"using/agents/openai-sdk/#resources","title":"\ud83d\udd17 Resources","text":"<ul> <li>OpenAI Agents SDK</li> <li>MCP Tool Protocol</li> </ul>"},{"location":"using/agents/semantic-kernel/","title":"Semantic Kernel Integration with MCP Gateway","text":"<p>Semantic Kernel is a Microsoft OSS framework for building AI-first apps.</p>"},{"location":"using/agents/semantic-kernel/#mcp-integration","title":"\ud83d\udd27 MCP Integration","text":"<p>Support for external tools via REST allows you to call MCP tools from SK plugins using <code>HttpFunction</code>.</p> <p>Define a plugin that points to MCP Gateway's <code>/tools/invoke</code> and pass arguments as JSON.</p>"},{"location":"using/agents/semantic-kernel/#resources","title":"\ud83d\udd17 Resources","text":"<ul> <li>Semantic Kernel GitHub</li> <li>Using REST APIs in SK</li> </ul>"},{"location":"using/clients/","title":"MCP Clients","text":"<p>MCP Gateway is compatible with any client that speaks the Model Context Protocol (MCP). This section documents tested clients, their configuration, and any integration tips.</p>"},{"location":"using/clients/#client-types","title":"\ud83d\udd0c Client Types","text":"<p>There are two ways clients typically connect:</p> <ul> <li>Direct to Gateway (HTTP/SSE/WS)</li> <li>Via <code>mcpgateway-wrapper</code> (stdio transport, especially for LLM apps)</li> </ul>"},{"location":"using/clients/#compatible-clients","title":"\u2705 Compatible Clients","text":"Client Type Notes Claude Desktop UI Configure to launch <code>mcpgateway.wrapper</code> via JSON Cline CLI Supports stdio or direct MCP over HTTP Continue VSCode plugin MCP plugin support MCP Inspector Web debugger Great for manual testing and exploring protocol features <p>Each of these tools can consume the MCP protocol and dynamically detect tools from the Gateway.</p>"},{"location":"using/clients/#whats-in-this-section","title":"\ud83d\udcc1 What's in This Section","text":"Page Description Claude Desktop How to connect Claude to MCP Gateway via wrapper Cline Using the CLI tool for invoking tools or prompts Continue Integrating with the VSCode plugin MCP Inspector Launch and test the Gateway or wrapper via a web debugger"},{"location":"using/clients/claude-desktop/","title":"Claude Desktop \u00d7 MCP Gateway","text":"<p>Claude Desktop can launch a local stdio process for every chat \"backend\". By pointing it at <code>mcpgateway.wrapper</code> you give Claude instant access to every tool, prompt and resource registered in your Gateway.</p>"},{"location":"using/clients/claude-desktop/#where-to-edit-the-config","title":"\ud83d\udcc2 Where to edit the config","text":"OS Path macOS <code>~/Library/Application Support/Claude/claude_desktop_config.json</code> Windows <code>%APPDATA%\\Claude\\claude_desktop_config.json</code> Linux (Flatpak / AppImage) <code>$HOME/.config/Claude/claude_desktop_config.json</code>"},{"location":"using/clients/claude-desktop/#minimal-json-block","title":"\u2699\ufe0f Minimal JSON block","text":"<pre><code>{\n  \"mcpServers\": {\n    \"mcpgateway-wrapper\": {\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"mcpgateway.wrapper\"],\n      \"env\": {\n        \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/1\",\n        \"MCP_AUTH_TOKEN\": \"&lt;YOUR_JWT_TOKEN&gt;\",\n        \"MCP_TOOL_CALL_TIMEOUT\": \"120\"\n      }\n    }\n  }\n}\n</code></pre> <p>Use the real server ID instead of <code>1</code> and paste your bearer token.</p>"},{"location":"using/clients/claude-desktop/#docker-alternative","title":"\ud83d\udc33 Docker alternative","text":"<pre><code>{\n  \"command\": \"docker\",\n  \"args\": [\n    \"run\", \"--rm\", \"--network=host\", \"-i\",\n    \"-e\", \"MCP_SERVER_CATALOG_URLS=http://localhost:4444/servers/1\",\n    \"-e\", \"MCP_AUTH_TOKEN=&lt;YOUR_JWT_TOKEN&gt;\",\n    \"ghcr.io/ibm/mcp-context-forge:latest\",\n    \"python3\", \"-m\", \"mcpgateway.wrapper\"\n  ]\n}\n</code></pre> <p>(Mac / Windows users should replace <code>localhost</code> with <code>host.docker.internal</code>.)</p>"},{"location":"using/clients/claude-desktop/#pipx-uvx-one-liner-wrapper-already-installed","title":"\u26a1 pipx / uvx one-liner (wrapper already installed)","text":"<p>If you installed the package globally:</p> <pre><code>{\n  \"command\": \"pipx\",\n  \"args\": [\"run\", \"python3\", \"-m\", \"mcpgateway.wrapper\"],\n  \"env\": {\n    \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/1\",\n    \"MCP_AUTH_TOKEN\": \"&lt;YOUR_JWT_TOKEN&gt;\"\n  }\n}\n</code></pre>"},{"location":"using/clients/claude-desktop/#smoke-test-inside-claude","title":"\ud83e\uddea Smoke-test inside Claude","text":"<ol> <li>Restart Claude Desktop (quit from system-tray).</li> <li>Select \"mcpgateway-wrapper\" in the chat dropdown.</li> <li>Type:</li> </ol> <p><pre><code>#get_current_time { \"timezone\": \"Europe/Dublin\" }\n</code></pre> 4. The wrapper should proxy the call \u2192 Gateway \u2192 tool \u2192 chat reply.</p> <p>If tools don't appear, open File \u25b8 Settings \u25b8 Developer \u25b8 View Logs to see wrapper output.</p>"},{"location":"using/clients/claude-desktop/#environment-variables-recap","title":"\ud83d\udd11 Environment variables recap","text":"Var Purpose <code>MCP_SERVER_CATALOG_URLS</code> One or more <code>/servers/{id}</code> endpoints (comma-sep) <code>MCP_AUTH_TOKEN</code> JWT bearer for Gateway auth <code>MCP_TOOL_CALL_TIMEOUT</code> Per-tool timeout (seconds, optional) <code>MCP_WRAPPER_LOG_LEVEL</code> <code>DEBUG</code>, <code>INFO</code>, <code>OFF</code> (optional) <p>You can place them:</p> <ul> <li>under <code>\"env\"</code> in the mcpServers block (preferred)</li> <li>in your user/environment shell before launching Claude.</li> </ul>"},{"location":"using/clients/cline/","title":"Cline (VS Code Extension)","text":"<p>Cline is a Visual Studio Code extension that brings AI-powered coding assistance directly into your editor. It supports the Model Context Protocol (MCP), enabling seamless integration with MCP-compatible servers like MCP Gateway.</p>"},{"location":"using/clients/cline/#key-features","title":"\ud83e\uddf0 Key Features","text":"<ul> <li>AI-Powered Coding: Leverages advanced AI models (e.g., Claude 3.5 Sonnet, DeepSeek Chat) for code generation, editing, and debugging.</li> <li>MCP Integration: Connects to MCP servers to discover and utilize tools dynamically.</li> <li>Terminal and Browser Access: Executes terminal commands and performs browser operations with user permission.</li> <li>Custom Tools: Supports adding custom tools via MCP for extended functionality.</li> </ul>"},{"location":"using/clients/cline/#installation","title":"\ud83d\udee0 Installation","text":"<ol> <li>Install Cline Extension:</li> <li>Open VS Code.</li> <li>Navigate to the Extensions view (<code>Ctrl+Shift+X</code> or <code>Cmd+Shift+X</code>).</li> <li> <p>Search for \"Cline\" and click \"Install\".</p> </li> <li> <p>Sign In to Cline:</p> </li> <li>Click the Cline icon in the Activity Bar.</li> <li>Follow the prompts to sign in or create a new account at app.cline.bot.</li> <li>New users receive free credits; no credit card required.</li> </ol>"},{"location":"using/clients/cline/#connecting-to-mcp-gateway","title":"\ud83d\udd17 Connecting to MCP Gateway","text":"<p>To integrate Cline with your MCP Gateway:</p> <ol> <li>Configure MCP Server:</li> <li>Open the Cline settings in VS Code.</li> <li>Navigate to the MCP Servers section.</li> <li> <p>Add a new MCP server with the following configuration under mcpServers as shown below:</p> <pre><code>\"mcpServers\": {\n    \"mcpgateway-wrapper\": {\n       \"disabled\": true,\n       \"timeout\": 60,\n       \"type\": \"stdio\",\n       \"command\": \"uv\",\n       \"args\": [\n       \"run\",\n       \"--directory\",\n       \"REPLACE_WITH_PATH_TO_REPO\",\n       \"-m\",\n       \"mcpgateway.wrapper\"\n       ],\n       \"env\": {\n          \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444\",\n          \"MCP_AUTH_TOKEN\": \"REPLACE_WITH_MCPGATEWAY_BEARER_TOKEN\",\n          \"MCP_WRAPPER_LOG_LEVEL\": \"OFF\"\n       }\n    }\n }\n</code></pre> </li> <li> <p>Enable the MCP Server:</p> </li> <li> <p>Ensure the newly added MCP server is enabled in the Cline settings.</p> </li> <li> <p>Verify Connection:</p> </li> <li>In the Cline interface, navigate to the MCP Servers section.</li> <li>Confirm that the MCP Gateway server is listed and shows a green status indicator.</li> </ol>"},{"location":"using/clients/cline/#using-mcp-tools-in-cline","title":"\ud83e\uddea Using MCP Tools in Cline","text":"<p>Once connected:</p> <ul> <li>Discover Tools: Cline will automatically fetch and list available tools from the MCP Gateway.</li> <li>Invoke Tools: Use natural language prompts in Cline to invoke tools. For example:</li> <li>\"Run the <code>hello_world</code> tool with the argument <code>name: Alice</code>.\"</li> <li>Monitor Responses: Cline will display the tool's output directly within the chat interface.</li> </ul>"},{"location":"using/clients/cline/#tips-for-effective-use","title":"\ud83d\udcdd Tips for Effective Use","text":"<ul> <li>.clinerules File: Create a <code>.clinerules</code> file in your project root to define project-specific behaviors and instructions for Cline.</li> <li>Custom Instructions: Utilize Cline's Custom Instructions feature to tailor its behavior across all projects.</li> <li>Model Selection: Choose the AI model that best fits your project's needs within the Cline settings.</li> </ul>"},{"location":"using/clients/cline/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>Cline Official Website</li> <li>Cline Documentation</li> </ul>"},{"location":"using/clients/continue/","title":"Continue (VS Code Extension)","text":"<p>Continue is an open-source AI code assistant for Visual Studio Code. Because it speaks the Model Context Protocol (MCP), Continue can discover and call the tools you publish through MCP Gateway \u2013 no plug-in code required.</p>"},{"location":"using/clients/continue/#key-features","title":"\ud83e\uddf0 Key Features","text":"<ul> <li>\u2728 AI-powered completions, edits &amp; chat</li> <li>\ud83d\udd0c MCP integration \u2013 dynamic tool list pulled from your gateway</li> <li>\ud83c\udfd7 Bring-your-own model \u2013 local Ollama, OpenAI, Anthropic, etc.</li> <li>\ud83e\udde0 Context-aware \u2013 reads your workspace to craft better replies</li> </ul>"},{"location":"using/clients/continue/#installation","title":"\ud83d\udee0 Installation","text":"<ol> <li>Install \"Continue\": <code>Ctrl \u21e7 X</code> \u2192 search Continue \u2192 Install</li> <li>Open config: <code>Ctrl \u21e7 P</code> \u2192 \"Continue: Open Config\"    \u2192 edits <code>~/.continue/config.json</code></li> </ol>"},{"location":"using/clients/continue/#connecting-continue-to-mcp-gateway","title":"\ud83d\udd17 Connecting Continue to MCP Gateway","text":"<p>There are two ways to attach Continue to a gateway:</p> Transport When to use Snippet SSE (HTTP) Remote / SSL / no local process <code>&lt;-- see Option A&gt;</code> Stdio wrapper Local dev, no SSE, or auth-header issues <code>&lt;-- see Option B&gt;</code> <p>For both options you still need a JWT or Basic auth if the gateway is protected.</p>"},{"location":"using/clients/continue/#option-a-direct-sse","title":"Option A \u00b7 Direct SSE","text":"<pre><code>// ~/.continue/config.json\n{\n  \"experimental\": {\n    \"modelContextProtocolServer\": {\n      \"transport\": {\n        \"type\": \"sse\",\n        \"url\": \"http://localhost:4444/servers/1/sse\",\n        \"headers\": {\n          \"Authorization\": \"Bearer ${env:MCP_AUTH_TOKEN}\"\n        }\n      }\n    }\n  }\n}\n</code></pre> <p>Generate a token:</p> <pre><code>export MCP_AUTH_TOKEN=$(python -m mcpgateway.utils.create_jwt_token -u admin --secret my-test-key)\n</code></pre>"},{"location":"using/clients/continue/#option-b-local-stdio-bridge-mcpgatewaywrapper","title":"Option B \u00b7 Local stdio bridge (<code>mcpgateway.wrapper</code>)","text":"<ol> <li>Install the wrapper (pipx keeps it isolated):</li> </ol> <pre><code>pipx install --include-deps mcp-contextforge-gateway\n</code></pre> <ol> <li>Config in Continue:</li> </ol> <pre><code>{\n  \"experimental\": {\n    \"modelContextProtocolServer\": {\n      \"transport\": {\n        \"type\": \"stdio\",\n        \"command\": \"python3\",\n        \"args\": [\"-m\", \"mcpgateway.wrapper\"],\n        \"env\": {\n          \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/1\",\n          \"MCP_AUTH_TOKEN\": \"${env:MCP_AUTH_TOKEN}\",\n          \"MCP_TOOL_CALL_TIMEOUT\": \"120\"\n        }\n      }\n    }\n  }\n}\n</code></pre> <p>If you prefer Docker: replace <code>\"command\": \"python3\"</code> with <code>\"command\": \"docker\"</code> and use the same container arguments shown in the Copilot docs.</p>"},{"location":"using/clients/continue/#using-gateway-tools","title":"\ud83e\uddea Using Gateway Tools","text":"<p>Once VS Code restarts:</p> <ol> <li>Open Continue Chat (<code>\u2325 C</code> on macOS / <code>Alt C</code> on Windows/Linux)</li> <li>Click Tools \u2013 your gateway's tools should appear</li> <li>Chat naturally:</li> </ol> <pre><code>Run hello_world with name = \"Alice\"\n</code></pre> <p>The wrapper/Gateway executes and streams the JSON result back to Continue.</p>"},{"location":"using/clients/continue/#tips","title":"\ud83d\udcdd Tips","text":"<ul> <li>SSE vs stdio \u2013 SSE is simpler in prod, stdio is great for offline or   header-free environments.</li> <li>Multiple servers \u2013 add more blocks under <code>\"servers\"</code> if you run staging vs prod.</li> <li>Custom instructions \u2013 Continue's Custom Instructions pane lets you steer tool use.</li> </ul>"},{"location":"using/clients/continue/#resources","title":"\ud83d\udcda Resources","text":"<ul> <li>\ud83c\udf10 Continue docs</li> <li>\ud83d\udcd6 MCP Spec</li> <li>\ud83d\udee0 MCP Gateway GitHub</li> </ul>"},{"location":"using/clients/copilot/","title":"\ud83e\udde0 GitHub Copilot + MCP Gateway","text":"<p>Super-charge Copilot (or any VS Code chat agent that speaks MCP) with tools, prompts and resources from your own MCP Gateway.</p> <p>With Copilot \u2192 MCP you can:</p> <ul> <li>\ud83d\udd27 call custom / enterprise tools from chat</li> <li>\ud83d\udcc2 pull live resources (configs, docs, snippets)</li> <li>\ud83e\udde9 render prompts or templates directly inside the IDE</li> </ul> <p>Copilot supports SSE streams out-of-the-box; for environments that forbid long-lived HTTP or require local stdio, you can insert the bundled <code>mcpgateway.wrapper</code> bridge.</p>"},{"location":"using/clients/copilot/#prerequisites","title":"\ud83d\udee0 Prerequisites","text":"<ul> <li>VS Code \u2265 1.99</li> <li><code>\"chat.mcp.enabled\": true</code> in your settings.json</li> <li>An MCP Gateway running (<code>make serve</code>, Docker, or container image)</li> <li>A JWT or Basic credentials (<code>admin</code> / <code>changeme</code> in dev)</li> </ul>"},{"location":"using/clients/copilot/#option-1-direct-sse-best-for-prod-remote","title":"\ud83d\udd17 Option 1 \u00b7 Direct SSE (best for prod / remote)","text":""},{"location":"using/clients/copilot/#1-create-vscodemcpjson","title":"1 \u00b7 Create <code>.vscode/mcp.json</code>","text":"<pre><code>{\n  \"servers\": {\n    \"mcp-gateway\": {\n      \"type\": \"sse\",\n      \"url\": \"https://mcpgateway.example.com/servers/1/sse\",\n      \"headers\": {\n        \"Authorization\": \"Bearer &lt;YOUR_JWT_TOKEN&gt;\"\n      }\n    }\n  }\n}\n</code></pre> <p>Tip \u2013 generate a token</p> <pre><code>python -m mcpgateway.utils.create_jwt_token -u admin --exp 10080 --secret my-test-key\n</code></pre>"},{"location":"using/clients/copilot/#option-2-local-stdio-bridge-mcpgatewaywrapper","title":"\ud83d\udd17 Option 2 \u00b7 Local stdio bridge (<code>mcpgateway.wrapper</code>)","text":"<p>Perfect when:</p> <ul> <li>the IDE cannot add HTTP headers, or</li> <li>you're offline / behind a corp proxy.</li> </ul>"},{"location":"using/clients/copilot/#1-install-the-wrapper-one-liner","title":"1 \u00b7 Install the wrapper (one-liner)","text":"<pre><code>pipx install --include-deps mcp-contextforge-gateway          # isolates in ~/.local/pipx/venvs\n#   - or -\nuv pip install mcp-contextforge-gateway                       # inside any uv/venv you like\n</code></pre>"},{"location":"using/clients/copilot/#2-create-vscodemcpjson","title":"2 \u00b7 Create <code>.vscode/mcp.json</code>","text":"<pre><code>{\n  \"servers\": {\n    \"mcp-wrapper\": {\n      \"type\": \"stdio\",\n      \"command\": \"python3\",\n      \"args\": [\"-m\", \"mcpgateway.wrapper\"],\n      \"env\": {\n        \"MCP_SERVER_CATALOG_URLS\": \"http://localhost:4444/servers/1\",\n        \"MCP_AUTH_TOKEN\": \"&lt;YOUR_JWT_TOKEN&gt;\",\n        \"MCP_TOOL_CALL_TIMEOUT\": \"120\"\n      }\n    }\n  }\n}\n</code></pre> <p>That's it \u2013 VS Code spawns the stdio process, pipes JSON-RPC, and you're ready to roll.</p> \ud83d\udc33 Docker alternative <pre><code>{\n  \"command\": \"docker\",\n  \"args\": [\n    \"run\", \"--rm\", \"--network=host\", \"-i\",\n    \"-e\", \"MCP_SERVER_CATALOG_URLS=http://localhost:4444/servers/1\",\n    \"-e\", \"MCP_AUTH_TOKEN=&lt;YOUR_JWT_TOKEN&gt;\",\n    \"ghcr.io/ibm/mcp-context-forge:latest\",\n    \"python3\", \"-m\", \"mcpgateway.wrapper\"\n  ]\n}\n</code></pre>"},{"location":"using/clients/copilot/#verify-inside-copilot","title":"\ud83e\uddea Verify inside Copilot","text":"<ol> <li>Open Copilot Chat \u2192 switch to Agent mode.</li> <li>Click Tools \u2013 your Gateway tools should list.</li> <li>Try:</li> </ol> <pre><code>#echo { \"message\": \"Hello from VS Code\" }\n</code></pre> <p>Copilot routes the call \u2192 Gateway \u2192 tool, and prints the reply.</p>"},{"location":"using/clients/copilot/#good-to-know","title":"\ud83d\udcdd Good to know","text":"<ul> <li>Use SSE for production, stdio for local/offline.</li> <li>You can manage servers, tools and prompts from the Gateway Admin UI (<code>/admin</code>).</li> <li>Need a bearer quickly?   <code>export MCP_AUTH_TOKEN=$(python -m mcpgateway.utils.create_jwt_token -u admin --secret my-test-key)</code></li> </ul>"},{"location":"using/clients/copilot/#further-reading","title":"\ud83d\udcda Further Reading","text":"<ul> <li>Gateway GitHub \u2192 ibm/mcp-context-forge</li> <li>MCP Spec \u2192 https://modelcontextprotocol.io/</li> <li>Copilot docs \u2192 features/copilot</li> </ul>"},{"location":"using/clients/mcp-inspector/","title":"MCP Inspector","text":"<p>MCP Inspector is a visual debugging GUI for the Model Context Protocol. Point it at any MCP-compliant endpoint \u2014 a live Gateway SSE stream or a local <code>mcpgateway.wrapper</code> stdio server \u2014 and you can:</p> <ul> <li>\ud83d\udd0d Browse tools, prompts and resources in real time</li> <li>\ud83d\udee0 Invoke tools with JSON params and inspect raw results</li> <li>\ud83d\udcdc Watch the full bidirectional JSON-RPC / MCP traffic live</li> <li>\ud83d\udd04 Replay or edit previous requests</li> <li>\ud83d\udcac Stream sampling messages (where supported)</li> </ul>"},{"location":"using/clients/mcp-inspector/#quick-launch-recipes","title":"\ud83d\ude80 Quick launch recipes","text":"<p>All commands use npx (bundled with Node \u2265 14). Feel free to <code>npm install -g @modelcontextprotocol/inspector</code> for a global binary.</p> Use-case One-liner What happens Connect to Gateway (SSE) <code>bash&lt;br/&gt;npx @modelcontextprotocol/inspector \\\\&lt;br/&gt;  --url http://localhost:4444/servers/1/sse \\\\&lt;br/&gt;  --header \"Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN\"&lt;br/&gt;</code> Inspector opens <code>http://localhost:5173</code> and attaches directly to the gateway stream. 2 \u00b7 Spin up the stdio wrapper in-process <code>bash&lt;br/&gt;export MCP_AUTH_TOKEN=$MCPGATEWAY_BEARER_TOKEN&lt;br/&gt;export MCP_SERVER_CATALOG_URLS=http://localhost:4444/servers/1&lt;br/&gt;&lt;br/&gt;npx @modelcontextprotocol/inspector \\\\&lt;br/&gt;  python -m mcpgateway.wrapper&lt;br/&gt;</code> Inspector forks <code>python -m mcpgateway.wrapper</code>, then connects to its stdio port automatically. 3 \u00b7 Same, but via uv / uvenv <code>bash&lt;br/&gt;npx @modelcontextprotocol/inspector \\\\&lt;br/&gt;  uvenv run python -m mcpgateway.wrapper&lt;br/&gt;</code> Uses the super-fast uv virtual-env if you prefer. 4 \u00b7 Wrapper already running Launch the wrapper in another shell, then:<code>bash&lt;br/&gt;npx @modelcontextprotocol/inspector --stdio&lt;br/&gt;</code> Inspector only opens the GUI and binds to the running stdio server on stdin/stdout."},{"location":"using/clients/mcp-inspector/#environment-variables","title":"\ud83d\udd10 Environment variables","text":"<p>Most wrappers / servers will need at least:</p> <pre><code>export MCP_SERVER_CATALOG_URLS=http://localhost:4444/servers/1   # one or many\nexport MCP_AUTH_TOKEN=$(python -m mcpgateway.utils.create_jwt_token -u admin --secret my-test-key)\n</code></pre> <p>If you point Inspector directly at a Gateway SSE stream, pass the header:</p> <pre><code>--header \"Authorization: Bearer $MCP_AUTH_TOKEN\"\n</code></pre>"},{"location":"using/clients/mcp-inspector/#inspector-highlights","title":"\ud83d\udd27 Inspector Highlights","text":"<ul> <li>Real-time catalogue \u2013 tools/prompts/resources update as soon as the Gateway sends <code>*Changed</code> notifications.</li> <li>Request builder \u2013 JSON editor with schema hints (if the tool exposes an <code>inputSchema</code>).</li> <li>Traffic console \u2013 colour-coded view of every request &amp; reply; copy as cURL.</li> <li>Replay &amp; edit \u2013 click any previous call, tweak parameters, re-send.</li> <li>Streaming \u2013 see <code>sampling/createMessage</code> chunks scroll by live (MCP 2025-03-26 spec).</li> </ul>"},{"location":"using/clients/mcp-inspector/#connecting-through-supergateway-stdio-sse-bridge","title":"\ud83d\udef0 Connecting through SuperGateway (stdio \u2192 SSE bridge)","text":"<p>Want to test a stdio-only MCP server inside Inspector?</p> <pre><code># Example: expose mcp-server-git over SSE on :8000\nnpx -y supergateway --stdio \"uvx run mcp-server-git\"\n#   SSE stream:  http://localhost:8000/sse\n#   POST back-channel: http://localhost:8000/message\n</code></pre> <p>Then simply start Inspector:</p> <pre><code>npx @modelcontextprotocol/inspector \\\n  --url http://localhost:8000/sse\n</code></pre> <p>SuperGateway handles the bridging; Inspector thinks it is speaking native SSE.</p>"},{"location":"using/clients/openwebui/","title":"OpenWebUI Integration with MCP Gateway","text":"<p>OpenWebUI is a self-hosted, extensible interface for interacting with large language models (LLMs). Integrating OpenWebUI with the Model Context Protocol (MCP) allows you to enhance your AI workflows by leveraging tools and resources provided by MCP servers.</p>"},{"location":"using/clients/openwebui/#integration-overview","title":"\ud83d\udd0c Integration Overview","text":"<p>OpenWebUI supports integration with external tools via OpenAPI specifications. MCP Gateway exposes its tools through OpenAPI-compatible endpoints, enabling seamless integration with OpenWebUI.</p>"},{"location":"using/clients/openwebui/#prerequisites","title":"\ud83d\udee0\ufe0f Prerequisites","text":"<ul> <li>OpenWebUI: Ensure you have OpenWebUI installed and running. Refer to the OpenWebUI documentation for installation instructions.</li> <li>MCP Gateway: Set up and run the MCP Gateway. Detailed setup instructions can be found in the MCP Gateway documentation.</li> </ul>"},{"location":"using/clients/openwebui/#connecting-mcp-tools-to-openwebui","title":"\ud83d\udd17 Connecting MCP Tools to OpenWebUI","text":""},{"location":"using/clients/openwebui/#1-launch-mcp-gateway","title":"1. Launch MCP Gateway","text":"<p>Start the MCP Gateway to expose its tools via OpenAPI endpoints. For example:</p> <pre><code>uv run mcpgateway\n</code></pre> <p>Ensure that the MCP Gateway is accessible at a known URL, such as <code>http://localhost:4444</code>.</p>"},{"location":"using/clients/openwebui/#2-identify-mcp-tool-endpoints","title":"2. Identify MCP Tool Endpoints","text":"<p>Determine the specific tool endpoints provided by the MCP Gateway. These endpoints follow the OpenAPI specification and are typically accessible at URLs like:</p> <pre><code>http://localhost:4444/tools/&lt;tool-name&gt;\n</code></pre> <p>Replace <code>&lt;tool-name&gt;</code> with the actual name of the tool you wish to integrate.</p>"},{"location":"using/clients/openwebui/#3-add-mcp-tools-to-openwebui","title":"3. Add MCP Tools to OpenWebUI","text":""},{"location":"using/clients/openwebui/#a-access-openwebui-settings","title":"a. Access OpenWebUI Settings","text":"<ul> <li>Navigate to the OpenWebUI interface in your browser.</li> <li>Click on the \u2699\ufe0f Settings icon.</li> </ul>"},{"location":"using/clients/openwebui/#b-add-a-new-tool-server","title":"b. Add a New Tool Server","text":"<ul> <li>In the Settings menu, locate the Tools section.</li> <li>Click on the \u2795 Add Tool Server button.</li> <li>Enter the URL of the MCP tool endpoint (e.g., <code>http://localhost:4444/tools/&lt;tool-name&gt;</code>).</li> <li>Click Save to register the tool.</li> </ul> <p>Repeat this process for each MCP tool you wish to integrate.</p>"},{"location":"using/clients/openwebui/#using-mcp-tools-in-openwebui","title":"\ud83e\uddea Using MCP Tools in OpenWebUI","text":"<p>Once the MCP tools are registered:</p> <ul> <li>Enable Tools in Chat: In the chat interface, click on the \u2795 icon to view available tools. Toggle the desired MCP tools to enable them for the current session.</li> <li>Invoke Tools: Interact with the AI model as usual. When appropriate, the model will utilize the enabled MCP tools to fulfill your requests.</li> </ul>"},{"location":"using/clients/openwebui/#advanced-configuration","title":"\u2699\ufe0f Advanced Configuration","text":""},{"location":"using/clients/openwebui/#global-tool-servers","title":"Global Tool Servers","text":"<p>To make MCP tools available to all users:</p> <ul> <li>Navigate to Admin Settings &gt; Tools.</li> <li>Add the MCP tool endpoints as described above.</li> <li>These tools will now be accessible to all users, subject to individual activation in their chat sessions.</li> </ul>"},{"location":"using/clients/openwebui/#native-function-calling","title":"Native Function Calling","text":"<p>OpenWebUI supports native function calling for tools:</p> <ul> <li>In the chat interface, go to Chat Controls &gt; Advanced Params.</li> <li>Set the Function Calling parameter to <code>Native</code>.</li> <li>This enables more structured interactions between the AI model and the tools.</li> </ul>"},{"location":"using/clients/openwebui/#additional-resources","title":"\ud83e\uddf0 Additional Resources","text":"<ul> <li>OpenWebUI Documentation</li> <li>MCP Gateway Documentation</li> <li>OpenWebUI GitHub Repository</li> <li>MCP Gateway GitHub Repository</li> </ul> <p>By integrating MCP tools into OpenWebUI, you can enhance your AI assistant's capabilities, enabling it to perform a wider range of tasks by leveraging the diverse tools provided by the MCP ecosystem.</p>"}]}